{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc37b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| IPO                        | Category   | GMP_InvestorGain | GMP_IPOWatch | Issue_Price | Open_Date   | Close_Date  | GMP_Diff |\n",
      "|----------------------------|------------|------------------|--------------|-------------|-------------|-------------|----------|\n",
      "| Tata Technologies          | Mainboard  | 400              | 412          | 500         | 2023-11-22  | 2023-11-24  | -12      |\n",
      "| Gandhar Oil Refinery       | Mainboard  | 78               | 82           | 169         | 2023-11-22  | 2023-11-24  | -4       |\n",
      "| Flair Writing Industries   | Mainboard  | 75               | 76           | 304         | 2023-11-22  | 2023-11-24  | -1       |\n",
      "| Fedbank Financial Services | Mainboard  | 6                | 7            | 140         | 2023-11-22  | 2023-11-24  | -1       |\n",
      "| Indian Renewable Energy    | SME        | 10               | 12           | 60          | 2023-11-21  | 2023-11-23  | -2       |\n",
      "| Accent Microcell           | SME        | 110              | 120          | 140         | 2023-11-08  | 2023-11-10  | -10      |\n",
      "| ASK Automotive             | Mainboard  | 30               | 32           | 282         | 2023-11-07  | 2023-11-09  | -2       |\n",
      "| Protean eGov Technologies  | Mainboard  | 110              | 115          | 792         | 2023-11-06  | 2023-11-08  | -5       |\n",
      "| ESAF Small Finance Bank    | Mainboard  | 22               | 23           | 60          | 2023-11-03  | 2023-11-07  | -1       |\n",
      "| Cello World                | Mainboard  | 140              | 145          | 648         | 2023-10-30  | 2023-11-01  | -5       |\n",
      "\n",
      "‚úÖ Markdown table saved to ipo_comparison_table.md\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "# URLs for live data\n",
    "ipowatch_url = 'https://ipowatch.in/ipo-grey-market-premium-latest-ipo-gmp/'\n",
    "investorgain_url = 'https://www.investorgain.com/report/live-ipo-gmp/331/'\n",
    "\n",
    "# --- STEP 1: Fetch HTML content (truncate to stay within LLM context) ---\n",
    "def fetch_html(url, limit=20000):\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=20)\n",
    "        resp.raise_for_status()\n",
    "        text = re.sub(r'\\s+', ' ', resp.text)  # collapse extra whitespace\n",
    "        return text[:limit]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to fetch {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "ipowatch_html = fetch_html(ipowatch_url)\n",
    "investorgain_html = fetch_html(investorgain_url)\n",
    "\n",
    "# --- STEP 2: Build the LLM prompt ---\n",
    "prompt = f\"\"\"\n",
    "You are a financial data parser.\n",
    "\n",
    "You will be given two HTML snippets from different IPO tracking websites.\n",
    "Extract and compare the IPO listings into a **Markdown table** with these exact columns:\n",
    "\n",
    "| IPO | Category | GMP_InvestorGain | GMP_IPOWatch | Issue_Price | Open_Date | Close_Date | GMP_Diff |\n",
    "\n",
    "- GMP_Diff = GMP_InvestorGain - GMP_IPOWatch\n",
    "- Treat missing GMP as 0.\n",
    "- The table must start with a header row and pipes (|).\n",
    "- Do not include any explanations, disclaimers, or text outside the table.\n",
    "\n",
    "### HTML from IPOWatch:\n",
    "{ipowatch_html}\n",
    "\n",
    "### HTML from InvestorGain:\n",
    "{investorgain_html}\n",
    "\"\"\"\n",
    "\n",
    "# --- STEP 3: Send to Perplexity API ---\n",
    "api_url = \"https://api.perplexity.ai/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer your pplx key\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "payload = {\n",
    "    \"model\": \"sonar-pro\",          # model used\n",
    "    \"temperature\": 0.1,            # low temp for consistency\n",
    "    \"max_tokens\": 2500,            # more room for large tables\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a structured data extraction assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# --- STEP 4: Send request ---\n",
    "try:\n",
    "    response = requests.post(api_url, headers=headers, json=payload, timeout=60)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "\n",
    "    # Extract model output safely\n",
    "    content = result.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "\n",
    "    # --- STEP 5: Sanitize output (only keep markdown table) ---\n",
    "    match = re.search(r\"(\\|.+\\|[\\s\\S]*)\", content)\n",
    "    if match:\n",
    "        table = match.group(1).strip()\n",
    "        print(table)\n",
    "        # Optionally save\n",
    "        with open(\"ipo_comparison_table.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(table)\n",
    "        print(\"\\n‚úÖ Markdown table saved to ipo_comparison_table.md\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No valid table found in response.\\nRaw content:\")\n",
    "        print(content)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"HTTP Error: {e}\")\n",
    "except (KeyError, json.JSONDecodeError) as e:\n",
    "    print(\"‚ö†Ô∏è Parsing Error:\", e)\n",
    "    print(\"Raw response:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232aebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| IPO                       | Category   | GMP_InvestorGain | GMP_IPOWatch | Issue_Price      | Open_Date   | Close_Date  | GMP_Diff |\n",
      "|---------------------------|------------|------------------|--------------|------------------|-------------|-------------|----------|\n",
      "| Mahamaya Lifesciences     | SME        | 18               | 15           | ‚Çπ108 ‚Äì ‚Çπ114      | 2025-11-11  | 2025-11-13  | 3        |\n",
      "| Workmates Core2Cloud      | SME        | 22               | 20           | ‚Çπ200 ‚Äì ‚Çπ204      | 2025-11-11  | 2025-11-13  | 2        |\n",
      "| PhysicsWallah             | Mainboard  | 35               | 30           | ‚Çπ103 ‚Äì ‚Çπ109      | 2025-11-11  | 2025-11-13  | 5        |\n",
      "| Emmvee Photovoltaic Power | Mainboard  | 40               | 38           | ‚Çπ206 ‚Äì ‚Çπ217      | 2025-11-11  | 2025-11-13  | 2        |\n",
      "| Tenneco Clean Air         | Mainboard  | 45               | 42           | ‚Çπ378 ‚Äì ‚Çπ397      | 2025-11-12  | 2025-11-14  | 3        |\n",
      "| Shining Tools             | SME        | 12               | 10           | ‚Çπ114             | 2025-11-07  | 2025-11-11  | 2        |\n",
      "| Curis Lifesciences        | SME        | 0                | 0            | ‚Çπ120 ‚Äì ‚Çπ128      | 2025-11-07  | 2025-11-11  | 0        |\n",
      "| Finbud Financial          | SME        | 0                | 0            | ‚Çπ140 ‚Äì ‚Çπ142      | 2025-11-06  | 2025-11-10  | 0        |\n",
      "| Shreeji Global FMCG       | SME        | 8                | 7            | ‚Çπ120 ‚Äì ‚Çπ125      | 2025-11-04  | 2025-11-07  | 1        |\n",
      "\n",
      "‚úÖ Saved latest IPOs to latest_ipo_comparison.md\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "# URLs\n",
    "ipowatch_url = 'https://ipowatch.in/ipo-grey-market-premium-latest-ipo-gmp/'\n",
    "investorgain_url = 'https://www.investorgain.com/report/live-ipo-gmp/331/'\n",
    "\n",
    "# --- Fetch HTML ---\n",
    "def fetch_html(url, limit=15000):  # smaller limit -> top section only (latest IPOs)\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=20)\n",
    "        resp.raise_for_status()\n",
    "        html = re.sub(r'\\s+', ' ', resp.text)\n",
    "        return html[:limit]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to fetch {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "ipowatch_html = fetch_html(ipowatch_url)\n",
    "investorgain_html = fetch_html(investorgain_url)\n",
    "\n",
    "# --- Enhanced Prompt ---\n",
    "prompt = f\"\"\"\n",
    "You are a financial data extractor.\n",
    "\n",
    "Extract **only the current and upcoming IPOs** (ignore old or archived ones) from the two HTML pages below.\n",
    "Focus on IPOs mentioned near the top of the page (recent issues).\n",
    "\n",
    "Output a **Markdown table** with the exact columns:\n",
    "\n",
    "| IPO | Category | GMP_InvestorGain | GMP_IPOWatch | Issue_Price | Open_Date | Close_Date | GMP_Diff |\n",
    "\n",
    "Rules:\n",
    "- GMP_Diff = GMP_InvestorGain - GMP_IPOWatch\n",
    "- If GMP is missing, assume 0.\n",
    "- Only include IPOs that are currently open, recently closed, or upcoming.\n",
    "- Ignore historical performance tables or 2023 data.\n",
    "- Sort IPOs by **Open_Date descending (newest first)**.\n",
    "- Output table only. No explanations, notes, or extra text.\n",
    "\n",
    "### IPOWatch HTML (latest section only):\n",
    "{ipowatch_html}\n",
    "\n",
    "### InvestorGain HTML (latest section only):\n",
    "{investorgain_html}\n",
    "\"\"\"\n",
    "\n",
    "# --- Send to Perplexity API ---\n",
    "api_url = \"https://api.perplexity.ai/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer your pplx key\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "payload = {\n",
    "    \"model\": \"sonar-pro\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"max_tokens\": 3000,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a precise data extraction agent.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# --- Handle Request ---\n",
    "try:\n",
    "    response = requests.post(api_url, headers=headers, json=payload, timeout=60)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    content = result.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "\n",
    "    # Extract table safely\n",
    "    match = re.search(r\"(\\|.+\\|[\\s\\S]*)\", content)\n",
    "    if match:\n",
    "        table = match.group(1).strip()\n",
    "        with open(\"latest_ipo_comparison.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(table)\n",
    "        print(table)\n",
    "        print(\"\\n‚úÖ Saved latest IPOs to latest_ipo_comparison.md\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No table found. Raw output:\")\n",
    "        print(content)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e41ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dateutil import parser as dateparse\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from transformers import pipeline\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "COL_SENT = \"ipo_sentiment\"\n",
    "\n",
    "# Sentiment model: CPU-friendly\n",
    "SENTIMENT_MODEL = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "# --------------------------------\n",
    "\n",
    "# ---------- helper parsers ----------\n",
    "def markdown_table_to_df(table_md: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts a GitHub-style markdown table string into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Remove leading/trailing whitespace\n",
    "    table_md = table_md.strip()\n",
    "    # Find header divider (---) and split\n",
    "    lines = [ln.strip() for ln in table_md.splitlines() if ln.strip()]\n",
    "    # Keep only lines starting with '|'\n",
    "    lines = [ln for ln in lines if ln.startswith(\"|\")]\n",
    "    if len(lines) < 2:\n",
    "        raise ValueError(\"Not a valid markdown table.\")\n",
    "    header = [h.strip() for h in lines[0].strip(\"|\").split(\"|\")]\n",
    "    rows = []\n",
    "    for ln in lines[2:]:  # skip header and separator\n",
    "        cols = [c.strip() for c in ln.strip(\"|\").split(\"|\")]\n",
    "        # pad if missing\n",
    "        if len(cols) < len(header):\n",
    "            cols += [\"\"] * (len(header) - len(cols))\n",
    "        rows.append(cols)\n",
    "    df = pd.DataFrame(rows, columns=header)\n",
    "    return df\n",
    "\n",
    "def clean_money(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip()\n",
    "    s = s.replace(\"‚Çπ\", \"\").replace(\",\", \"\").replace(\" \", \"\")\n",
    "    if s in [\"\", \"-\", \"‚Äî\", \"nan\", \"None\"]:\n",
    "        return None\n",
    "    # handle ranges like 206-217 or 206-217 or 206-217\n",
    "    if \"-\" in s:\n",
    "        parts = [p for p in s.split(\"-\") if p != \"\"]\n",
    "        try:\n",
    "            nums = [float(re.sub(r\"[^\\d.]\", \"\", p)) for p in parts]\n",
    "            return {\"min\": min(nums), \"max\": max(nums), \"mid\": sum(nums)/len(nums)}\n",
    "        except:\n",
    "            return s\n",
    "    # single number\n",
    "    try:\n",
    "        return {\"min\": float(s), \"max\": float(s), \"mid\": float(s)}\n",
    "    except:\n",
    "        # maybe has percent or extra chars\n",
    "        m = re.search(r\"(-?\\d+(\\.\\d+)?)\", s)\n",
    "        if m:\n",
    "            return {\"min\": float(m.group(1)), \"max\": float(m.group(1)), \"mid\": float(m.group(1))}\n",
    "    return None\n",
    "\n",
    "def parse_gmp(x):\n",
    "    # allow strings like '65', '0', '‚Çπ65', '65 (16.62%)'\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in [\"nan\", \"-\"]:\n",
    "        return None\n",
    "    # find first number (allow negative)\n",
    "    m = re.search(r\"(-?\\d+(\\.\\d+)?)\", s.replace(\",\", \"\"))\n",
    "    if m:\n",
    "        return float(m.group(1))\n",
    "    return None\n",
    "\n",
    "def parse_date(x):\n",
    "    if x is None or x == \"\":\n",
    "        return None\n",
    "    try:\n",
    "        # some dates are like 2025-11-12; others can be textual\n",
    "        d = dateparse.parse(x, dayfirst=False, fuzzy=True)\n",
    "        return d.date().isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ---------- Mongo utilities ----------\n",
    "def get_mongo_col(uri=MONGO_URI, dbname=DB_NAME, colname=COL_IPOS):\n",
    "    client = MongoClient(uri, serverSelectionTimeoutMS=5000)\n",
    "    db = client[dbname]\n",
    "    col = db[colname]\n",
    "    return col\n",
    "\n",
    "# ---------- Step A: Read markdown table (from file or string) ----------\n",
    "def load_table_from_file(path=\"latest_ipo_comparison.md\"):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"{path} not found\")\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "# ---------- Step B: Convert -> normalized DataFrame ----------\n",
    "def normalize_ipos(table_md: str) -> pd.DataFrame:\n",
    "    df = markdown_table_to_df(table_md)\n",
    "\n",
    "    # Standardize column names (strip spaces)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # Ensure all expected columns exist\n",
    "    expected = [\"IPO\",\"Category\",\"GMP_InvestorGain\",\"GMP_IPOWatch\",\"Issue_Price\",\"Open_Date\",\"Close_Date\",\"GMP_Diff\"]\n",
    "    for e in expected:\n",
    "        if e not in df.columns:\n",
    "            df[e] = None\n",
    "\n",
    "    # Parse numeric GMPs\n",
    "    df[\"GMP_InvestorGain_num\"] = df[\"GMP_InvestorGain\"].apply(parse_gmp)\n",
    "    df[\"GMP_IPOWatch_num\"] = df[\"GMP_IPOWatch\"].apply(parse_gmp)\n",
    "\n",
    "    # If GMP_Diff absent or zero, recompute\n",
    "    def compute_diff(row):\n",
    "        a = row[\"GMP_InvestorGain_num\"]\n",
    "        b = row[\"GMP_IPOWatch_num\"]\n",
    "        if pd.isna(a) and pd.isna(b):\n",
    "            return None\n",
    "        a = 0.0 if a is None else float(a)\n",
    "        b = 0.0 if b is None else float(b)\n",
    "        return a - b\n",
    "\n",
    "    df[\"GMP_Diff_num\"] = df.apply(lambda r: compute_diff(r) if (str(r.get(\"GMP_Diff\")).strip() in [\"\", \"None\", \"0\"]) else float(re.search(r\"(-?\\d+(\\.\\d+)?)\", str(r[\"GMP_Diff\"])).group(1)), axis=1)\n",
    "\n",
    "    # Normalize Issue_Price into structured fields\n",
    "    df[\"Issue_Price_struct\"] = df[\"Issue_Price\"].apply(clean_money)\n",
    "\n",
    "    # Normalize dates\n",
    "    df[\"Open_Date_iso\"] = df[\"Open_Date\"].apply(parse_date)\n",
    "    df[\"Close_Date_iso\"] = df[\"Close_Date\"].apply(parse_date)\n",
    "\n",
    "    # Build final payload per IPO (dict)\n",
    "    records = []\n",
    "    for _, r in df.iterrows():\n",
    "        rec = {\n",
    "            \"ipo\": r[\"IPO\"],\n",
    "            \"category\": r[\"Category\"],\n",
    "            \"gmp_investorgain\": None if pd.isna(r[\"GMP_InvestorGain\"]) else r[\"GMP_InvestorGain\"],\n",
    "            \"gmp_investorgain_num\": r[\"GMP_InvestorGain_num\"],\n",
    "            \"gmp_ipowatch\": None if pd.isna(r[\"GMP_IPOWatch\"]) else r[\"GMP_IPOWatch\"],\n",
    "            \"gmp_ipowatch_num\": r[\"GMP_IPOWatch_num\"],\n",
    "            \"gmp_diff\": r[\"GMP_Diff_num\"],\n",
    "            \"issue_price_raw\": r[\"Issue_Price\"],\n",
    "            \"issue_price\": r[\"Issue_Price_struct\"],\n",
    "            \"open_date\": r[\"Open_Date_iso\"],\n",
    "            \"close_date\": r[\"Close_Date_iso\"],\n",
    "            \"source_created_at\": datetime.utcnow().isoformat()\n",
    "        }\n",
    "        records.append(rec)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# ---------- Step C: Insert into MongoDB (upsert by IPO + open_date) ----------\n",
    "def upsert_ipos_to_mongo(df_norm: pd.DataFrame, uri=MONGO_URI):\n",
    "    col = get_mongo_col(uri, DB_NAME, COL_IPOS)\n",
    "    inserted = 0\n",
    "    for _, row in df_norm.iterrows():\n",
    "        key = {\"ipo\": row[\"ipo\"], \"open_date\": row[\"open_date\"]}\n",
    "        doc = dict(row.dropna().to_dict())\n",
    "        # Upsert: update existing doc or insert new\n",
    "        col.update_one(key, {\"$set\": doc, \"$setOnInsert\": {\"created_at\": datetime.utcnow()}}, upsert=True)\n",
    "        inserted += 1\n",
    "    print(f\"Upserted {inserted} IPO records to MongoDB collection '{COL_IPOS}'.\")\n",
    "\n",
    "# ---------- Step D: Sentiment pipeline (bootstrap) ----------\n",
    "def init_sentiment_pipeline(model_name=SENTIMENT_MODEL):\n",
    "    # device=-1 ensures CPU usage\n",
    "    nlp = pipeline(\"sentiment-analysis\", model=model_name, device=-1)\n",
    "    return nlp\n",
    "\n",
    "def analyze_and_store_sentiment(ipo_name: str, texts: list, nlp, uri=MONGO_URI):\n",
    "    \"\"\"\n",
    "    texts: list of textual snippets (news headlines, tweets, etc.) about the IPO\n",
    "    performs sentiment analysis (per snippet), aggregates, and stores result in mongo.\n",
    "    \"\"\"\n",
    "    col_sent = get_mongo_col(uri, DB_NAME, COL_SENT)\n",
    "    # run model in batches\n",
    "    outs = nlp(texts, truncation=True)\n",
    "    # outs is list of dicts with 'label' (POSITIVE/NEGATIVE) and 'score'\n",
    "    # Convert to numeric sentiment: positive -> +score, negative -> -score\n",
    "    scores = []\n",
    "    for o in outs:\n",
    "        label = o[\"label\"].upper()\n",
    "        s = float(o[\"score\"])\n",
    "        val = s if label == \"POSITIVE\" else -s\n",
    "        scores.append(val)\n",
    "    # Aggregations\n",
    "    avg_sent = sum(scores) / len(scores) if scores else 0.0\n",
    "    weighted_sent = avg_sent  # placeholder - you can add weights by source, recency, etc.\n",
    "    doc = {\n",
    "        \"ipo\": ipo_name,\n",
    "        \"samples_count\": len(texts),\n",
    "        \"avg_sentiment\": avg_sent,\n",
    "        \"weighted_sentiment\": weighted_sent,\n",
    "        \"per_sample\": list(zip(texts, scores)),\n",
    "        \"analyzed_at\": datetime.utcnow().isoformat()\n",
    "    }\n",
    "    # Upsert by ipo\n",
    "    col_sent.update_one({\"ipo\": ipo_name}, {\"$set\": doc}, upsert=True)\n",
    "    return doc\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Load markdown table output produced earlier\n",
    "    mdpath = \"latest_ipo_comparison.md\"\n",
    "    md = load_table_from_file(mdpath)\n",
    "    # 2) Normalize into structured DataFrame\n",
    "    df_norm = normalize_ipos(md)\n",
    "    print(\"Normalized rows:\", len(df_norm))\n",
    "    # 3) Upsert IPOs to MongoDB\n",
    "    upsert_ipos_to_mongo(df_norm)\n",
    "    # 4) Initialize sentiment model (CPU)\n",
    "    nlp = init_sentiment_pipeline()\n",
    "    print(\"Sentiment model loaded (CPU).\")\n",
    "    # 5) Example: analyze sample texts per IPO (replace with real scrapes later)\n",
    "    # Here we just show a scaffold: you will replace the texts list with real headlines/tweets/news.\n",
    "    example_texts = [\n",
    "        \"Investors bullish on Tenneco Clean Air IPO after strong subscription.\",\n",
    "        \"Some analysts warn valuation high for Tenneco listing.\"\n",
    "    ]\n",
    "    # Analyze only first IPO for demo\n",
    "    if not df_norm.empty:\n",
    "        first_ipo = df_norm.iloc[0][\"ipo\"]\n",
    "        res = analyze_and_store_sentiment(first_ipo, example_texts, nlp)\n",
    "        print(\"Sentiment stored for\", first_ipo, \":\", res[\"avg_sentiment\"])\n",
    "    else:\n",
    "        print(\"No IPO rows to analyze.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "525c0c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Normalized IPO entries: 9\n",
      "‚úÖ Inserted 0, Updated 9 IPO records in MongoDB.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import parser as dateparse\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "# -----------------------------\n",
    "\n",
    "# ---------- Utility Functions ----------\n",
    "def markdown_table_to_df(table_md: str) -> pd.DataFrame:\n",
    "    \"\"\"Convert a GitHub-style Markdown table into a pandas DataFrame.\"\"\"\n",
    "    lines = [ln.strip() for ln in table_md.splitlines() if ln.strip()]\n",
    "    lines = [ln for ln in lines if ln.startswith(\"|\")]\n",
    "    if len(lines) < 2:\n",
    "        raise ValueError(\"Invalid markdown table format.\")\n",
    "    header = [h.strip() for h in lines[0].strip(\"|\").split(\"|\")]\n",
    "    rows = []\n",
    "    for ln in lines[2:]:\n",
    "        cols = [c.strip() for c in ln.strip(\"|\").split(\"|\")]\n",
    "        if len(cols) < len(header):\n",
    "            cols += [\"\"] * (len(header) - len(cols))\n",
    "        rows.append(cols)\n",
    "    df = pd.DataFrame(rows, columns=header)\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_float(value):\n",
    "    \"\"\"Extract first numeric float value from a string like ‚Çπ123 or '5.5%'.\"\"\"\n",
    "    if not value or str(value).strip() in [\"-\", \"‚Äî\", \"None\"]:\n",
    "        return None\n",
    "    try:\n",
    "        match = re.search(r\"(-?\\d+(\\.\\d+)?)\", str(value).replace(\",\", \"\"))\n",
    "        return float(match.group(1)) if match else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_issue_price(price_str):\n",
    "    \"\"\"Extract range or single numeric price.\"\"\"\n",
    "    if not price_str:\n",
    "        return None\n",
    "    s = str(price_str).replace(\"‚Çπ\", \"\").replace(\",\", \"\").strip()\n",
    "    if \"-\" in s:\n",
    "        parts = re.findall(r\"\\d+\\.?\\d*\", s)\n",
    "        if len(parts) >= 2:\n",
    "            low, high = float(parts[0]), float(parts[1])\n",
    "            return {\"min\": low, \"max\": high, \"avg\": (low + high) / 2}\n",
    "    num = parse_float(s)\n",
    "    if num is not None:\n",
    "        return {\"min\": num, \"max\": num, \"avg\": num}\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Normalize dates to ISO format (YYYY-MM-DD).\"\"\"\n",
    "    if not date_str or date_str.strip() == \"\":\n",
    "        return None\n",
    "    try:\n",
    "        d = dateparse.parse(date_str, fuzzy=True)\n",
    "        return d.date().isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_mongo_collection(uri, db_name, collection):\n",
    "    client = MongoClient(uri, serverSelectionTimeoutMS=5000)\n",
    "    db = client[db_name]\n",
    "    return db[collection]\n",
    "\n",
    "\n",
    "# ---------- Core Processing ----------\n",
    "def normalize_ipo_table(table_md: str) -> pd.DataFrame:\n",
    "    \"\"\"Parse markdown table, clean and normalize IPO data.\"\"\"\n",
    "    df = markdown_table_to_df(table_md)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # Ensure all expected columns exist\n",
    "    expected_cols = [\n",
    "        \"IPO\", \"Category\", \"GMP_InvestorGain\", \"GMP_IPOWatch\",\n",
    "        \"Issue_Price\", \"Open_Date\", \"Close_Date\", \"GMP_Diff\"\n",
    "    ]\n",
    "    for col in expected_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "    # Clean numeric and date columns\n",
    "    df[\"GMP_InvestorGain_num\"] = df[\"GMP_InvestorGain\"].apply(parse_float)\n",
    "    df[\"GMP_IPOWatch_num\"] = df[\"GMP_IPOWatch\"].apply(parse_float)\n",
    "\n",
    "    # If GMP_Diff missing or invalid, recompute it\n",
    "    def compute_diff(row):\n",
    "        a, b = row[\"GMP_InvestorGain_num\"], row[\"GMP_IPOWatch_num\"]\n",
    "        return (a or 0) - (b or 0)\n",
    "\n",
    "    df[\"GMP_Diff_num\"] = [\n",
    "        parse_float(x) if parse_float(x) is not None else compute_diff(r)\n",
    "        for x, r in zip(df[\"GMP_Diff\"], df.to_dict(orient=\"records\"))\n",
    "    ]\n",
    "\n",
    "    df[\"Issue_Price_struct\"] = df[\"Issue_Price\"].apply(clean_issue_price)\n",
    "    df[\"Open_Date_iso\"] = df[\"Open_Date\"].apply(parse_date)\n",
    "    df[\"Close_Date_iso\"] = df[\"Close_Date\"].apply(parse_date)\n",
    "\n",
    "    # Construct normalized structure\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        rec = {\n",
    "            \"ipo\": row[\"IPO\"],\n",
    "            \"category\": row[\"Category\"],\n",
    "            \"gmp_investorgain\": row[\"GMP_InvestorGain_num\"],\n",
    "            \"gmp_ipowatch\": row[\"GMP_IPOWatch_num\"],\n",
    "            \"gmp_diff\": row[\"GMP_Diff_num\"],\n",
    "            \"issue_price\": row[\"Issue_Price_struct\"],\n",
    "            \"open_date\": row[\"Open_Date_iso\"],\n",
    "            \"close_date\": row[\"Close_Date_iso\"],\n",
    "            \"raw\": {\n",
    "                \"GMP_InvestorGain\": row[\"GMP_InvestorGain\"],\n",
    "                \"GMP_IPOWatch\": row[\"GMP_IPOWatch\"],\n",
    "                \"Issue_Price\": row[\"Issue_Price\"],\n",
    "                \"GMP_Diff\": row[\"GMP_Diff\"],\n",
    "            },\n",
    "            \"inserted_at\": datetime.utcnow().isoformat()\n",
    "        }\n",
    "        records.append(rec)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "def insert_to_mongodb(df: pd.DataFrame):\n",
    "    \"\"\"Insert or update IPO records in MongoDB.\"\"\"\n",
    "    collection = get_mongo_collection(MONGO_URI, DB_NAME, COL_IPOS)\n",
    "    inserted, updated = 0, 0\n",
    "    for _, row in df.iterrows():\n",
    "        key = {\"ipo\": row[\"ipo\"], \"open_date\": row[\"open_date\"]}\n",
    "        existing = collection.find_one(key)\n",
    "        if existing:\n",
    "            collection.update_one(key, {\"$set\": row.to_dict()})\n",
    "            updated += 1\n",
    "        else:\n",
    "            collection.insert_one(row.to_dict())\n",
    "            inserted += 1\n",
    "    print(f\"‚úÖ Inserted {inserted}, Updated {updated} IPO records in MongoDB.\")\n",
    "\n",
    "\n",
    "# ---------- Main Entry ----------\n",
    "if __name__ == \"__main__\":\n",
    "    md_path = \"latest_ipo_comparison.md\"\n",
    "    if not os.path.exists(md_path):\n",
    "        raise FileNotFoundError(\"‚ö†Ô∏è File latest_ipo_comparison.md not found. Run your LLM extractor first.\")\n",
    "    with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        md_content = f.read()\n",
    "\n",
    "    df_norm = normalize_ipo_table(md_content)\n",
    "    print(\"üßæ Normalized IPO entries:\", len(df_norm))\n",
    "    insert_to_mongodb(df_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1748d594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Found 10 IPO records in MongoDB\n",
      "\n",
      "üîç Processing: PhysicsWallah\n",
      "üåê https://ipowatch.in/physicswallah-ipo-date-review-price-allotment-details/\n",
      "‚úÖ Saved extracted data for PhysicsWallah ‚Üí ipo_details\\physicswallah_details.md\n",
      "\n",
      "üîç Processing: Emmvee Photovoltaic Power\n",
      "üåê https://ipowatch.in/emmvee-photovoltaic-power-ipo-date-review-price-allotment-details/\n",
      "‚ö†Ô∏è Failed to fetch https://ipowatch.in/emmvee-photovoltaic-power-ipo-date-review-price-allotment-details/: 404 Client Error: Not Found for url: https://ipowatch.in/emmvee-photovoltaic-power-ipo-date-review-price-allotment-details/\n",
      "\n",
      "üîç Processing: Tenneco Clean Air India\n",
      "üåê https://ipowatch.in/tenneco-clean-air-india-ipo-date-review-price-allotment-details/\n",
      "‚ö†Ô∏è Failed to fetch https://ipowatch.in/tenneco-clean-air-india-ipo-date-review-price-allotment-details/: 404 Client Error: Not Found for url: https://ipowatch.in/tenneco-clean-air-india-ipo-date-review-price-allotment-details/\n",
      "\n",
      "üîç Processing: Mahamaya Lifesciences\n",
      "üåê https://ipowatch.in/mahamaya-lifesciences-ipo-date-review-price-allotment-details/\n",
      "‚úÖ Saved extracted data for Mahamaya Lifesciences ‚Üí ipo_details\\mahamaya-lifesciences_details.md\n",
      "\n",
      "üîç Processing: Workmates Core2Cloud\n",
      "üåê https://ipowatch.in/workmates-core2cloud-ipo-date-review-price-allotment-details/\n",
      "‚úÖ Saved extracted data for Workmates Core2Cloud ‚Üí ipo_details\\workmates-core2cloud_details.md\n",
      "\n",
      "üîç Processing: Tenneco Clean Air\n",
      "üåê https://ipowatch.in/tenneco-clean-air-ipo-date-review-price-allotment-details/\n",
      "‚ö†Ô∏è Failed to fetch https://ipowatch.in/tenneco-clean-air-ipo-date-review-price-allotment-details/: 404 Client Error: Not Found for url: https://ipowatch.in/tenneco-clean-air-ipo-date-review-price-allotment-details/\n",
      "\n",
      "üîç Processing: Shining Tools\n",
      "üåê https://ipowatch.in/shining-tools-ipo-date-review-price-allotment-details/\n",
      "‚úÖ Saved extracted data for Shining Tools ‚Üí ipo_details\\shining-tools_details.md\n",
      "\n",
      "üîç Processing: Curis Lifesciences\n",
      "üåê https://ipowatch.in/curis-lifesciences-ipo-date-review-price-allotment-details/\n",
      "‚úÖ Saved extracted data for Curis Lifesciences ‚Üí ipo_details\\curis-lifesciences_details.md\n",
      "\n",
      "üîç Processing: Finbud Financial\n",
      "üåê https://ipowatch.in/finbud-financial-ipo-date-review-price-allotment-details/\n",
      "‚ö†Ô∏è Failed to fetch https://ipowatch.in/finbud-financial-ipo-date-review-price-allotment-details/: 404 Client Error: Not Found for url: https://ipowatch.in/finbud-financial-ipo-date-review-price-allotment-details/\n",
      "\n",
      "üîç Processing: Shreeji Global FMCG\n",
      "üåê https://ipowatch.in/shreeji-global-fmcg-ipo-date-review-price-allotment-details/\n",
      "‚úÖ Saved extracted data for Shreeji Global FMCG ‚Üí ipo_details\\shreeji-global-fmcg_details.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from time import sleep\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "OUTPUT_DIR = \"ipo_details\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Perplexity API Config\n",
    "PPLX_API_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "PPLX_API_KEY = os.getenv(\"PPLX_API_KEY\", \"your pplx key\")  # <-- put your key here\n",
    "MODEL_NAME = \"sonar-pro\"\n",
    "# -------------------------------------------\n",
    "\n",
    "\n",
    "def get_mongo_collection(uri, db_name, collection):\n",
    "    client = MongoClient(uri, serverSelectionTimeoutMS=5000)\n",
    "    db = client[db_name]\n",
    "    return db[collection]\n",
    "\n",
    "\n",
    "def fetch_html(url, limit=80000):\n",
    "    \"\"\"Fetch the IPO HTML page with truncation.\"\"\"\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=30, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        resp.raise_for_status()\n",
    "        html = re.sub(r\"\\s+\", \" \", resp.text)\n",
    "        return html[:limit]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to fetch {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def generate_prompt(ipo_name, html):\n",
    "    \"\"\"Construct prompt for Perplexity extraction.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a financial data extraction model.\n",
    "\n",
    "Extract the following 13 fields from the IPO details page HTML provided below.\n",
    "\n",
    "Output as a **Markdown table** with these exact columns (one row only):\n",
    "\n",
    "| IPO | Price Band | Issue Size | Issue Type | Listing Exchanges | IPO Dates | Market Lot & Amounts | Investor Quota Split | Anchor Details | Promoter Holdings (Pre/Post) | Financial Performance (FY23‚ÄìFY25) | Valuation Ratios (EPS, ROE, ROCE, D/E, NAV) | Lead Managers & Registrar | Company Overview | Peer Comparison |\n",
    "\n",
    "Rules:\n",
    "- Extract exact numeric and date values from the HTML.\n",
    "- Keep it concise and clean (no commentary).\n",
    "- If a value is missing, leave the cell blank.\n",
    "- All data must come from the provided HTML only.\n",
    "\n",
    "### HTML for {ipo_name}:\n",
    "{html}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def call_perplexity(prompt):\n",
    "    \"\"\"Send HTML prompt to Perplexity API.\"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PPLX_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 4000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise structured data extractor for IPO information.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        resp = requests.post(PPLX_API_URL, headers=headers, json=payload, timeout=90)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        content = data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "        return content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def extract_table(markdown_text):\n",
    "    \"\"\"Extract table markdown only.\"\"\"\n",
    "    match = re.search(r\"(\\|.+\\|[\\s\\S]*)\", markdown_text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def process_all_ipos():\n",
    "    \"\"\"Iterate through MongoDB IPOs, fetch IPOWatch page, call Perplexity.\"\"\"\n",
    "    collection = get_mongo_collection(MONGO_URI, DB_NAME, COL_IPOS)\n",
    "    ipos = list(collection.find({}))\n",
    "    print(f\"üìä Found {len(ipos)} IPO records in MongoDB\")\n",
    "\n",
    "    for ipo in ipos:\n",
    "        name = ipo.get(\"ipo\", \"\").strip()\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        # Create IPOWatch URL (format-safe)\n",
    "        slug = name.lower().replace(\" \", \"-\")\n",
    "        url = f\"https://ipowatch.in/{slug}-ipo-date-review-price-allotment-details/\"\n",
    "        print(f\"\\nüîç Processing: {name}\")\n",
    "        print(f\"üåê {url}\")\n",
    "\n",
    "        html = fetch_html(url)\n",
    "        if not html:\n",
    "            continue\n",
    "\n",
    "        prompt = generate_prompt(name, html)\n",
    "        result = call_perplexity(prompt)\n",
    "        table = extract_table(result)\n",
    "\n",
    "        if table:\n",
    "            out_path = os.path.join(OUTPUT_DIR, f\"{slug}_details.md\")\n",
    "            with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(table)\n",
    "            print(f\"‚úÖ Saved extracted data for {name} ‚Üí {out_path}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No table extracted for {name}\")\n",
    "\n",
    "        # Sleep between API calls (to respect rate limits)\n",
    "        sleep(3)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_ipos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5b6eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Processing IPOs in parallel: ['PhysicsWallah', 'Emmvee Photovoltaic Power']\n",
      "\n",
      "üîç Processing: PhysicsWallah\n",
      "üåê https://ipowatch.in/physicswallah-ipo-date-review-price-allotment-details/\n",
      "\n",
      "üîç Processing: Emmvee Photovoltaic Power\n",
      "üåê https://ipowatch.in/emmvee-photovoltaic-ipo-date-review-price-allotment-details/\n",
      "‚úÖ Extracted & saved for Emmvee Photovoltaic Power\n",
      "‚û°Ô∏è Emmvee Photovoltaic Power: ok\n",
      "‚úÖ Extracted & saved for PhysicsWallah\n",
      "‚û°Ô∏è PhysicsWallah: ok\n",
      "\n",
      "üèÅ Done ‚Äî extracted info for up to 2 IPOs in parallel.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "\n",
    "PPLX_API_KEY = os.getenv(\"PPLX_API_KEY\", \"your pplx key\")  # üëà put your key here\n",
    "PPLX_API_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "MODEL_NAME = \"sonar-pro\"\n",
    "\n",
    "MAX_WORKERS = 2   # number of IPOs to run in parallel\n",
    "# -------------------------------------------\n",
    "\n",
    "\n",
    "# ---------- UTILITIES ----------\n",
    "def make_two_word_slug(name: str) -> str:\n",
    "    \"\"\"Create IPOWatch slug using first two words of IPO name.\"\"\"\n",
    "    tokens = re.findall(r\"[A-Za-z0-9]+\", name)\n",
    "    return \"-\".join(t.lower() for t in tokens[:2]) if tokens else \"\"\n",
    "\n",
    "\n",
    "def fetch_html(url: str, limit: int = 70000) -> str:\n",
    "    \"\"\"Fetch IPOWatch HTML page.\"\"\"\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=25, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        resp.raise_for_status()\n",
    "        html = re.sub(r\"\\s+\", \" \", resp.text)\n",
    "        return html[:limit]\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Fetch failed: {e}\"\n",
    "\n",
    "\n",
    "def generate_prompt(ipo_name: str, html: str) -> str:\n",
    "    \"\"\"Generate extraction prompt for Perplexity.\"\"\"\n",
    "    return f\"\"\"\n",
    "You are a financial data extraction model.\n",
    "\n",
    "Extract the following 13 fields from the IPO details page HTML provided below.\n",
    "\n",
    "Output a Markdown table with these exact columns (one row only):\n",
    "\n",
    "| IPO | Price Band | Issue Size | Issue Type | Listing Exchanges | IPO Dates | Market Lot & Amounts | Investor Quota Split | Anchor Details | Promoter Holdings (Pre/Post) | Financial Performance (FY23‚ÄìFY25) | Valuation Ratios (EPS, ROE, ROCE, D/E, NAV) | Lead Managers & Registrar | Company Overview | Peer Comparison |\n",
    "\n",
    "Rules:\n",
    "- If a value is missing, leave it blank.\n",
    "- Use only the data present in the HTML.\n",
    "- Keep it concise.\n",
    "- Output only the Markdown table, nothing else.\n",
    "\n",
    "### HTML for {ipo_name}:\n",
    "{html}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def call_perplexity(prompt: str) -> str:\n",
    "    \"\"\"Send the HTML to Perplexity API.\"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PPLX_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 2000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise IPO data extractor.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.post(PPLX_API_URL, headers=headers, json=payload, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        return data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è API error: {e}\"\n",
    "\n",
    "\n",
    "def extract_table(text: str) -> str:\n",
    "    \"\"\"Extract Markdown table.\"\"\"\n",
    "    match = re.search(r\"(\\|.+\\|[\\s\\S]*)\", text)\n",
    "    return match.group(1).strip() if match else \"\"\n",
    "\n",
    "\n",
    "def parse_markdown_table(md_text: str) -> dict:\n",
    "    \"\"\"Convert one-row markdown table into dict.\"\"\"\n",
    "    lines = [ln.strip() for ln in md_text.splitlines() if ln.strip()]\n",
    "    if len(lines) < 3:\n",
    "        return {}\n",
    "    headers = [h.strip() for h in lines[0].strip(\"|\").split(\"|\")]\n",
    "    values = [v.strip() for v in lines[2].strip(\"|\").split(\"|\")]\n",
    "    return dict(zip(headers, values))\n",
    "# ------------------------------------------------------\n",
    "\n",
    "\n",
    "# ---------- MAIN PROCESS ----------\n",
    "def process_ipo(name: str):\n",
    "    \"\"\"Fetch HTML, call Perplexity, store in Mongo.\"\"\"\n",
    "    slug = make_two_word_slug(name)\n",
    "    url = f\"https://ipowatch.in/{slug}-ipo-date-review-price-allotment-details/\"\n",
    "    print(f\"\\nüîç Processing: {name}\\nüåê {url}\")\n",
    "\n",
    "    html = fetch_html(url)\n",
    "    if \"‚ö†Ô∏è Fetch failed\" in html:\n",
    "        return {\"ipo\": name, \"status\": \"fetch_failed\", \"url\": url}\n",
    "\n",
    "    prompt = generate_prompt(name, html)\n",
    "    result = call_perplexity(prompt)\n",
    "\n",
    "    if \"‚ö†Ô∏è API error\" in result or not result:\n",
    "        return {\"ipo\": name, \"status\": \"api_failed\", \"url\": url}\n",
    "\n",
    "    table_md = extract_table(result)\n",
    "    if not table_md:\n",
    "        return {\"ipo\": name, \"status\": \"no_table\", \"url\": url, \"raw\": result[:300]}\n",
    "\n",
    "    parsed = parse_markdown_table(table_md)\n",
    "    parsed[\"ipo\"] = name\n",
    "    parsed[\"url\"] = url\n",
    "    parsed[\"raw_markdown\"] = table_md\n",
    "    parsed[\"extracted_at\"] = datetime.utcnow().isoformat()\n",
    "\n",
    "    # Save to Mongo\n",
    "    try:\n",
    "        client = MongoClient(MONGO_URI)\n",
    "        coll = client[DB_NAME][COL_IPOS]\n",
    "        coll.update_one({\"ipo\": name}, {\"$set\": {\"extracted_fields\": parsed}}, upsert=True)\n",
    "        client.close()\n",
    "    except Exception as e:\n",
    "        return {\"ipo\": name, \"status\": f\"mongo_error: {e}\"}\n",
    "\n",
    "    print(f\"‚úÖ Extracted & saved for {name}\")\n",
    "    return {\"ipo\": name, \"status\": \"ok\", \"url\": url}\n",
    "\n",
    "\n",
    "def get_unprocessed_ipos(limit=2):\n",
    "    \"\"\"Fetch IPO names from MongoDB where extracted_fields missing.\"\"\"\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    coll = client[DB_NAME][COL_IPOS]\n",
    "    ipos = coll.find({\"extracted_fields\": {\"$exists\": False}}, {\"ipo\": 1}).limit(limit)\n",
    "    names = [x[\"ipo\"] for x in ipos if \"ipo\" in x]\n",
    "    client.close()\n",
    "    return names\n",
    "# ------------------------------------------------------\n",
    "\n",
    "\n",
    "# ---------- ENTRY POINT ----------\n",
    "if __name__ == \"__main__\":\n",
    "    ipo_names = get_unprocessed_ipos(limit=MAX_WORKERS)\n",
    "    if not ipo_names:\n",
    "        print(\"‚úÖ All IPOs already processed.\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"üì° Processing IPOs in parallel: {ipo_names}\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = {executor.submit(process_ipo, name): name for name in ipo_names}\n",
    "        for fut in as_completed(futures):\n",
    "            res = fut.result()\n",
    "            print(f\"‚û°Ô∏è {res['ipo']}: {res['status']}\")\n",
    "\n",
    "    print(\"\\nüèÅ Done ‚Äî extracted info for up to 2 IPOs in parallel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8447f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Running Spark parallel extraction for: ['Shining Tools', 'Curis Lifesciences']\n",
      "\n",
      "üìä Extraction Summary:\n",
      "‚û°Ô∏è Shining Tools: ok\n",
      "‚û°Ô∏è Curis Lifesciences: ok\n",
      "\n",
      "üèÅ SparkContext stopped ‚Äî Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import findspark\n",
    "\n",
    "# ---------- ENVIRONMENT ----------\n",
    "findspark.init()\n",
    "\n",
    "python_path = r\"C:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = python_path\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = python_path\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"C:/spark-temp\"\n",
    "os.makedirs(\"C:/spark-temp\", exist_ok=True)\n",
    "\n",
    "# Stop any old context\n",
    "if SparkContext._active_spark_context:\n",
    "    SparkContext._active_spark_context.stop()\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "\n",
    "PPLX_API_KEY = os.getenv(\"PPLX_API_KEY\", \"your pplx key\")\n",
    "PPLX_API_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "MODEL_NAME = \"sonar-pro\"\n",
    "\n",
    "PROCESS_N = 2   # only 2 IPOs parallel for now\n",
    "\n",
    "# ---------- HELPER FUNCTIONS ----------\n",
    "def make_two_word_slug(name: str) -> str:\n",
    "    tokens = re.findall(r\"[A-Za-z0-9]+\", name)\n",
    "    return \"-\".join(t.lower() for t in tokens[:2]) if tokens else \"\"\n",
    "\n",
    "def fetch_html(url: str, limit: int = 70000) -> str:\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=25, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        resp.raise_for_status()\n",
    "        html = re.sub(r\"\\s+\", \" \", resp.text)\n",
    "        return html[:limit]\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Fetch failed: {e}\"\n",
    "\n",
    "def generate_prompt(ipo_name: str, html: str) -> str:\n",
    "    return f\"\"\"\n",
    "You are a financial data extraction model.\n",
    "\n",
    "Extract the following 13 fields from the IPO details page HTML below.\n",
    "Output one Markdown table with these exact columns:\n",
    "\n",
    "| IPO | Price Band | Issue Size | Issue Type | Listing Exchanges | IPO Dates | Market Lot & Amounts | Investor Quota Split | Anchor Details | Promoter Holdings (Pre/Post) | Financial Performance (FY23‚ÄìFY25) | Valuation Ratios (EPS, ROE, ROCE, D/E, NAV) | Lead Managers & Registrar | Company Overview | Peer Comparison |\n",
    "\n",
    "Rules:\n",
    "- If a value is missing, leave it blank.\n",
    "- Output only the Markdown table, nothing else.\n",
    "\n",
    "### HTML for {ipo_name}:\n",
    "{html}\n",
    "\"\"\"\n",
    "\n",
    "def call_perplexity(prompt: str) -> str:\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PPLX_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 2000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise IPO data extractor.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.post(PPLX_API_URL, headers=headers, json=payload, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        return data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è API error: {e}\"\n",
    "\n",
    "def extract_table(text: str) -> str:\n",
    "    match = re.search(r\"(\\|.+\\|[\\s\\S]*)\", text)\n",
    "    return match.group(1).strip() if match else \"\"\n",
    "\n",
    "def parse_markdown_table(md_text: str) -> dict:\n",
    "    lines = [ln.strip() for ln in md_text.splitlines() if ln.strip()]\n",
    "    if len(lines) < 3:\n",
    "        return {}\n",
    "    headers = [h.strip() for h in lines[0].strip(\"|\").split(\"|\")]\n",
    "    values = [v.strip() for v in lines[2].strip(\"|\").split(\"|\")]\n",
    "    return dict(zip(headers, values))\n",
    "\n",
    "# ---------- MAIN TASK ----------\n",
    "def process_ipo(name: str):\n",
    "    slug = make_two_word_slug(name)\n",
    "    url = f\"https://ipowatch.in/{slug}-ipo-date-review-price-allotment-details/\"\n",
    "    print(f\"\\nüîç Processing: {name}\\nüåê {url}\")\n",
    "\n",
    "    html = fetch_html(url)\n",
    "    if \"‚ö†Ô∏è Fetch failed\" in html:\n",
    "        return {\"ipo\": name, \"status\": \"fetch_failed\", \"url\": url}\n",
    "\n",
    "    prompt = generate_prompt(name, html)\n",
    "    result = call_perplexity(prompt)\n",
    "\n",
    "    if \"‚ö†Ô∏è API error\" in result or not result:\n",
    "        return {\"ipo\": name, \"status\": \"api_failed\", \"url\": url}\n",
    "\n",
    "    table_md = extract_table(result)\n",
    "    if not table_md:\n",
    "        return {\"ipo\": name, \"status\": \"no_table\", \"url\": url, \"raw\": result[:300]}\n",
    "\n",
    "    parsed = parse_markdown_table(table_md)\n",
    "    parsed[\"ipo\"] = name\n",
    "    parsed[\"url\"] = url\n",
    "    parsed[\"raw_markdown\"] = table_md\n",
    "    parsed[\"extracted_at\"] = datetime.utcnow().isoformat()\n",
    "\n",
    "    try:\n",
    "        client = MongoClient(MONGO_URI)\n",
    "        coll = client[DB_NAME][COL_IPOS]\n",
    "        coll.update_one({\"ipo\": name}, {\"$set\": {\"extracted_fields\": parsed}}, upsert=True)\n",
    "        client.close()\n",
    "    except Exception as e:\n",
    "        return {\"ipo\": name, \"status\": f\"mongo_error: {e}\"}\n",
    "\n",
    "    print(f\"‚úÖ Extracted & saved for {name}\")\n",
    "    return {\"ipo\": name, \"status\": \"ok\"}\n",
    "\n",
    "# ---------- MONGO FETCH ----------\n",
    "def get_unprocessed_ipos(limit=2):\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    coll = client[DB_NAME][COL_IPOS]\n",
    "    ipos = coll.find({\"extracted_fields\": {\"$exists\": False}}, {\"ipo\": 1}).limit(limit)\n",
    "    names = [x[\"ipo\"] for x in ipos if \"ipo\" in x]\n",
    "    client.close()\n",
    "    return names\n",
    "\n",
    "# ---------- SPARK SETUP ----------\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .setMaster(\"local[2]\")\n",
    "    .setAppName(\"IPO-Parallel-RDD\")\n",
    "    .set(\"spark.python.worker.reuse\", \"false\")\n",
    "    .set(\"spark.local.dir\", \"C:/spark-temp\")\n",
    ")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# ---------- DRIVER ----------\n",
    "if __name__ == \"__main__\":\n",
    "    ipo_names = get_unprocessed_ipos(limit=PROCESS_N)\n",
    "    if not ipo_names:\n",
    "        print(\"‚úÖ All IPOs already processed.\")\n",
    "        sc.stop()\n",
    "        exit()\n",
    "\n",
    "    print(f\"üì° Running Spark parallel extraction for: {ipo_names}\")\n",
    "    rdd = sc.parallelize(ipo_names, len(ipo_names))\n",
    "\n",
    "    results = rdd.map(process_ipo).collect()\n",
    "\n",
    "    print(\"\\nüìä Extraction Summary:\")\n",
    "    for res in results:\n",
    "        print(f\"‚û°Ô∏è {res['ipo']}: {res['status']}\")\n",
    "\n",
    "    sc.stop()\n",
    "    print(\"\\nüèÅ SparkContext stopped ‚Äî Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb866d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Need to re-extract/enrich 10 IPOs ‚Äî running with 4 workers...\n",
      "\n",
      "üìä Extraction Summary:\n",
      "‚û°Ô∏è Finbud Financial: ok\n",
      "‚û°Ô∏è Shreeji Global FMCG: ok\n",
      "‚û°Ô∏è Tenneco Clean Air India: ok\n",
      "‚û°Ô∏è Mahamaya Lifesciences: ok\n",
      "‚û°Ô∏è Tenneco Clean Air: ok\n",
      "‚û°Ô∏è Curis Lifesciences: ok\n",
      "‚û°Ô∏è PhysicsWallah: ok\n",
      "‚û°Ô∏è Emmvee Photovoltaic Power: ok\n",
      "‚û°Ô∏è Shining Tools: ok\n",
      "‚û°Ô∏è Workmates Core2Cloud: ok\n",
      "\n",
      "üèÅ Done ‚Äî Spark stopped.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import findspark\n",
    "from typing import Optional\n",
    "\n",
    "# ---------- ENV ----------\n",
    "findspark.init()\n",
    "python_path = r\"C:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = python_path\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = python_path\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"C:/spark-temp\"\n",
    "os.makedirs(\"C:/spark-temp\", exist_ok=True)\n",
    "\n",
    "if SparkContext._active_spark_context:\n",
    "    SparkContext._active_spark_context.stop()\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "\n",
    "PPLX_API_KEY = os.getenv(\"PPLX_API_KEY\", \"your pplx key\")\n",
    "PPLX_API_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "MODEL_NAME = \"sonar-pro\"\n",
    "\n",
    "SPARK_PARALLELISM = int(os.getenv(\"SPARK_PARALLELISM\", \"4\"))\n",
    "API_DELAY = float(os.getenv(\"API_DELAY\", \"1.5\"))  # throttle to avoid rate limits\n",
    "FETCH_RETRIES = 3\n",
    "FETCH_DELAY = 2  # seconds backoff\n",
    "\n",
    "# Which fields must be present (your 15 fields + metadata)\n",
    "REQUIRED_FIELDS = [\n",
    "    \"Price Band\", \"Issue Size\", \"Issue Type\", \"Listing Exchanges\", \"IPO Dates\",\n",
    "    \"Market Lot & Amounts\", \"Investor Quota Split\", \"Anchor Details\",\n",
    "    \"Promoter Holdings (Pre/Post)\", \"Financial Performance (FY23‚ÄìFY25)\",\n",
    "    \"Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)\", \"Lead Managers & Registrar\",\n",
    "    \"Company Overview\", \"Peer Comparison\", \"ipo\"\n",
    "]\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def make_slug_candidates(name: str):\n",
    "    \"\"\"Return multiple slug variants to try on IPOWatch.\"\"\"\n",
    "    toks = re.findall(r\"[A-Za-z0-9]+\", name.lower())\n",
    "    candidates = []\n",
    "    if toks:\n",
    "        # first two words\n",
    "        candidates.append(\"-\".join(toks[:2]))\n",
    "        # first three words\n",
    "        if len(toks) >= 3:\n",
    "            candidates.append(\"-\".join(toks[:3]))\n",
    "        # entire name as slug (trim to first 6)\n",
    "        candidates.append(\"-\".join(toks[:6]))\n",
    "    # add safe fallback: name with hyphens\n",
    "    candidates.append(\"-\".join(toks))\n",
    "    return list(dict.fromkeys([c for c in candidates if c]))  # unique preserve order\n",
    "\n",
    "def fetch_html_try(url: str, retries=FETCH_RETRIES, delay=FETCH_DELAY) -> Optional[str]:\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (compatible; IPOBot/1.0)\"}\n",
    "    for attempt in range(1, retries+1):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=25, headers=headers, allow_redirects=True)\n",
    "            status = r.status_code\n",
    "            if status == 200 and r.text:\n",
    "                return re.sub(r\"\\s+\", \" \", r.text)[:120000]  # keep top content\n",
    "            else:\n",
    "                # non-200 often means not found; don't retry too many times but still backoff a little\n",
    "                time.sleep(delay * attempt)\n",
    "        except Exception as e:\n",
    "            time.sleep(delay * attempt)\n",
    "    return None\n",
    "\n",
    "def fetch_ipowatch_html_for(ipo_name: str):\n",
    "    \"\"\"Try several URL patterns and site search to get the IPOWatch HTML.\"\"\"\n",
    "    base = \"https://ipowatch.in\"\n",
    "    # Try candidate slugs\n",
    "    for slug in make_slug_candidates(ipo_name):\n",
    "        url1 = f\"{base}/{slug}-ipo-date-review-price-allotment-details/\"\n",
    "        html = fetch_html_try(url1)\n",
    "        if html:\n",
    "            return html, url1\n",
    "        # try simple slug\n",
    "        url2 = f\"{base}/{slug}/\"\n",
    "        html = fetch_html_try(url2)\n",
    "        if html:\n",
    "            return html, url2\n",
    "    # fallback: site search (ipowatch uses ?s=)\n",
    "    try:\n",
    "        search_url = f\"{base}/?s={requests.utils.quote(ipo_name)}\"\n",
    "        html = fetch_html_try(search_url)\n",
    "        if html:\n",
    "            return html, search_url\n",
    "    except:\n",
    "        pass\n",
    "    return None, None\n",
    "\n",
    "def call_perplexity(prompt: str) -> Optional[str]:\n",
    "    headers = {\"Authorization\": f\"Bearer {PPLX_API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 3000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise IPO data extraction assistant. Output only a single-row Markdown table with the requested columns.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(PPLX_API_URL, headers=headers, json=payload, timeout=90)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        return data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def extract_table(text: str) -> Optional[str]:\n",
    "    if not text:\n",
    "        return None\n",
    "    m = re.search(r\"(\\|.+\\|[\\s\\S]*)\", text)\n",
    "    return m.group(1).strip() if m else None\n",
    "\n",
    "def parse_markdown_table(md_text: str) -> dict:\n",
    "    \"\"\"Parse a single-row markdown table into a dict.\"\"\"\n",
    "    lines = [ln.strip() for ln in md_text.splitlines() if ln.strip()]\n",
    "    if len(lines) < 3:\n",
    "        return {}\n",
    "    headers = [h.strip() for h in lines[0].strip(\"|\").split(\"|\")]\n",
    "    values = [v.strip() for v in lines[2].strip(\"|\").split(\"|\")]\n",
    "    # pad values if shorter\n",
    "    if len(values) < len(headers):\n",
    "        values += [\"\"] * (len(headers) - len(values))\n",
    "    return dict(zip(headers, values))\n",
    "\n",
    "def count_present_fields(extracted: dict):\n",
    "    \"\"\"Count how many required fields are present and non-empty.\"\"\"\n",
    "    if not extracted:\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for k in REQUIRED_FIELDS:\n",
    "        if k == \"ipo\":\n",
    "            # 'ipo' mandatory as a sanity check\n",
    "            if extracted.get(\"ipo\"):\n",
    "                cnt += 1\n",
    "        else:\n",
    "            v = extracted.get(k)\n",
    "            if v is not None and str(v).strip() != \"\":\n",
    "                cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def mongo_get_all_ipos():\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    coll = client[DB_NAME][COL_IPOS]\n",
    "    docs = list(coll.find({}, {\"ipo\": 1, \"extracted_fields\": 1}))\n",
    "    client.close()\n",
    "    return docs\n",
    "\n",
    "def mongo_update_partial(ipo_name: str, new_fields: dict, source_url: str, raw_md: str):\n",
    "    \"\"\"Merge new_fields into existing document's 'extracted_fields' and append to history.\"\"\"\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    coll = client[DB_NAME][COL_IPOS]\n",
    "    doc = coll.find_one({\"ipo\": ipo_name}) or {}\n",
    "    existing = doc.get(\"extracted_fields\") or {}\n",
    "    # Merge: prefer existing non-empty value, otherwise take new\n",
    "    merged = existing.copy()\n",
    "    for k, v in new_fields.items():\n",
    "        # if existing missing or empty, replace\n",
    "        if (k not in merged) or (merged.get(k) in [None, \"\", [], {}]):\n",
    "            merged[k] = v\n",
    "    # metadata\n",
    "    history_entry = {\n",
    "        \"extracted_at\": datetime.utcnow().isoformat(),\n",
    "        \"source_url\": source_url,\n",
    "        \"raw_markdown\": raw_md,\n",
    "        \"fields_added\": {k: v for k, v in new_fields.items() if (existing.get(k) in [None, \"\", {}, []])}\n",
    "    }\n",
    "    # update doc\n",
    "    coll.update_one({\"ipo\": ipo_name}, {\"$set\": {\"extracted_fields\": merged, \"last_extracted_at\": history_entry[\"extracted_at\"]}, \"$push\": {\"extraction_history\": history_entry}}, upsert=True)\n",
    "    client.close()\n",
    "\n",
    "# ---------- PROCESS ONE IPO ----------\n",
    "def process_ipo(name: str):\n",
    "    print(f\"\\nüîç Starting: {name}\")\n",
    "    # 1) fetch HTML (try many patterns)\n",
    "    html, url = fetch_ipowatch_html_for(name)\n",
    "    if not html:\n",
    "        print(f\"‚ö†Ô∏è Fetch failed for {name} (tried multiple slugs/search).\")\n",
    "        return {\"ipo\": name, \"status\": \"fetch_failed\"}\n",
    "\n",
    "    # 2) load existing extracted_fields to include in prompt (so model only fills missing)\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    coll = client[DB_NAME][COL_IPOS]\n",
    "    doc = coll.find_one({\"ipo\": name}) or {}\n",
    "    client.close()\n",
    "    existing = doc.get(\"extracted_fields\") or {}\n",
    "\n",
    "    # 3) Build a focused prompt: include list of missing fields and existing values\n",
    "    missing = [f for f in REQUIRED_FIELDS if not existing.get(f)]\n",
    "    # always include 'ipo' field in the table header\n",
    "    header_cols = REQUIRED_FIELDS.copy()\n",
    "\n",
    "    prompt_lines = [\n",
    "        \"You are an expert IPO data extractor. You will be given an HTML snippet (IPOWatch) and a list of existing extracted fields (may be partial).\",\n",
    "        f\"IPO name: {name}\",\n",
    "        \"\",\n",
    "        \"Existing extracted fields (only show values already present):\"\n",
    "    ]\n",
    "    if existing:\n",
    "        for k, v in existing.items():\n",
    "            prompt_lines.append(f\"- {k}: {v}\")\n",
    "    else:\n",
    "        prompt_lines.append(\"- (none)\")\n",
    "\n",
    "    prompt_lines += [\n",
    "        \"\",\n",
    "        f\"Please extract the following missing fields (fill blanks). Missing fields: {missing}\",\n",
    "        \"Output a single-row Markdown table with this exact header (in this order):\",\n",
    "        \"| \" + \" | \".join(header_cols) + \" |\",\n",
    "        \"\",\n",
    "        \"Rules:\",\n",
    "        \"- If a value already exists in 'Existing extracted fields', preserve it in the output.\",\n",
    "        \"- Only output the table (no commentary).\",\n",
    "        \"- Leave values blank where you cannot find them.\",\n",
    "        \"\",\n",
    "        \"HTML:\",\n",
    "        html[:90000]  # keep prompt bounded\n",
    "    ]\n",
    "\n",
    "    prompt = \"\\n\".join(prompt_lines)\n",
    "\n",
    "    # 4) call Perplexity\n",
    "    result_text = call_perplexity(prompt)\n",
    "    time.sleep(API_DELAY)\n",
    "    if not result_text:\n",
    "        print(f\"‚ö†Ô∏è API failed for {name}\")\n",
    "        return {\"ipo\": name, \"status\": \"api_failed\"}\n",
    "\n",
    "    table_md = extract_table(result_text)\n",
    "    if not table_md:\n",
    "        print(f\"‚ö†Ô∏è No table parsed from LLM output for {name}. Raw start:\\n{result_text[:400]}\")\n",
    "        return {\"ipo\": name, \"status\": \"no_table\", \"raw_snippet\": result_text[:400]}\n",
    "\n",
    "    parsed = parse_markdown_table(table_md)\n",
    "    # ensure 'ipo' key present\n",
    "    parsed[\"ipo\"] = parsed.get(\"ipo\", name)\n",
    "    # merge into mongo\n",
    "    mongo_update_partial(name, parsed, url, table_md)\n",
    "    print(f\"‚úÖ Updated {name} (added {len(parsed)} fields, merged).\")\n",
    "    return {\"ipo\": name, \"status\": \"ok\"}\n",
    "\n",
    "# ---------- DRIVER ----------\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .setMaster(f\"local[{SPARK_PARALLELISM}]\")\n",
    "    .setAppName(\"IPO-Fill-Missing-Fields\")\n",
    "    .set(\"spark.python.worker.reuse\", \"false\")\n",
    "    .set(\"spark.local.dir\", \"C:/spark-temp\")\n",
    ")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # fetch all IPO docs and compute completeness\n",
    "    docs = mongo_get_all_ipos()\n",
    "    candidates = []\n",
    "    for d in docs:\n",
    "        name = d.get(\"ipo\")\n",
    "        existing = d.get(\"extracted_fields\") or {}\n",
    "        present = count_present_fields(existing)\n",
    "        completeness = present / len(REQUIRED_FIELDS)\n",
    "        if completeness < 1.0:\n",
    "            candidates.append((name, present, completeness))\n",
    "    # sort by least-complete first\n",
    "    candidates = sorted(candidates, key=lambda x: (x[2], -x[1]))\n",
    "    ipo_names = [c[0] for c in candidates]\n",
    "\n",
    "    if not ipo_names:\n",
    "        print(\"‚úÖ All IPOs already complete (100%). Nothing to do.\")\n",
    "        sc.stop()\n",
    "        exit()\n",
    "\n",
    "    print(f\"üì° Need to re-extract/enrich {len(ipo_names)} IPOs ‚Äî running with {SPARK_PARALLELISM} workers...\")\n",
    "    rdd = sc.parallelize(ipo_names, min(len(ipo_names), SPARK_PARALLELISM))\n",
    "    results = rdd.map(process_ipo).collect()\n",
    "\n",
    "    print(\"\\nüìä Extraction Summary:\")\n",
    "    for res in results:\n",
    "        print(f\"‚û°Ô∏è {res['ipo']}: {res['status']}\")\n",
    "\n",
    "    sc.stop()\n",
    "    print(\"\\nüèÅ Done ‚Äî Spark stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0508c983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Found 10 total IPO records\n",
      "\n",
      "üìä Top-level fields presence:\n",
      "_id: 10/10 records\n",
      "ipo: 10/10 records\n",
      "category: 10/10 records\n",
      "gmp_investorgain: 10/10 records\n",
      "gmp_ipowatch: 10/10 records\n",
      "gmp_diff: 10/10 records\n",
      "issue_price: 10/10 records\n",
      "open_date: 10/10 records\n",
      "close_date: 10/10 records\n",
      "raw: 10/10 records\n",
      "inserted_at: 10/10 records\n",
      "extracted_fields: 10/10 records\n",
      "extraction_history: 10/10 records\n",
      "last_extracted_at: 10/10 records\n",
      "\n",
      "üìä Extracted fields presence:\n",
      "IPO: 4/10 records\n",
      "Price Band: 8/10 records\n",
      "Issue Size: 8/10 records\n",
      "Issue Type: 8/10 records\n",
      "Listing Exchanges: 8/10 records\n",
      "IPO Dates: 8/10 records\n",
      "Market Lot & Amounts: 8/10 records\n",
      "Investor Quota Split: 8/10 records\n",
      "Anchor Details: 8/10 records\n",
      "Promoter Holdings (Pre/Post): 8/10 records\n",
      "Financial Performance (FY23‚ÄìFY25): 8/10 records\n",
      "Valuation Ratios (EPS, ROE, ROCE, D/E, NAV): 8/10 records\n",
      "Lead Managers & Registrar: 8/10 records\n",
      "Company Overview: 8/10 records\n",
      "Peer Comparison: 8/10 records\n",
      "ipo: 10/10 records\n",
      "url: 8/10 records\n",
      "raw_markdown: 8/10 records\n",
      "extracted_at: 8/10 records\n",
      "\n",
      "üìù Sample IPO record with extracted fields:\n",
      "{'_id': ObjectId('690f5be67ebcab56b4d5097a'),\n",
      " 'category': 'Mainboard',\n",
      " 'close_date': '2025-11-13',\n",
      " 'extracted_fields': {'Anchor Details': 'Anchor bidding: Nov 10, 2025; '\n",
      "                                        'Lock-in: 50% till Dec 14, 2025, 50% '\n",
      "                                        'till Feb 12, 2026; Anchor list: '\n",
      "                                        '[PDF], Size: [.] Cr.',\n",
      "                      'Company Overview': 'Edtech company founded 2020, '\n",
      "                                          'online/offline learning, 3.5M+ '\n",
      "                                          'students, 8M+ YouTube subscribers, '\n",
      "                                          'strong hybrid model',\n",
      "                      'Financial Performance (FY23‚ÄìFY25)': 'FY24: ‚Çπ2,015.35 Cr '\n",
      "                                                           'revenue, ‚Çπ1,131.13 '\n",
      "                                                           'Cr loss; FY25: '\n",
      "                                                           '‚Çπ3,039.09 Cr '\n",
      "                                                           'revenue, ‚Çπ243.26 '\n",
      "                                                           'Cr loss',\n",
      "                      'IPO': 'PhysicsWallah Ltd.',\n",
      "                      'IPO Dates': 'Nov 11‚Äì13, 2025 (Listing: Nov 18, 2025)',\n",
      "                      'Investor Quota Split': 'QIB: 75%, NII: 15%, Retail: 10%',\n",
      "                      'Issue Size': '‚Çπ3,480 Crores',\n",
      "                      'Issue Type': 'Book Built Issue',\n",
      "                      'Lead Managers & Registrar': 'Lead Managers: Kotak '\n",
      "                                                   'Mahindra Capital Co. Ltd., '\n",
      "                                                   'JP Morgan India Pvt. Ltd, '\n",
      "                                                   'Goldman Sachs (India) '\n",
      "                                                   'Securities Pvt. Ltd., '\n",
      "                                                   'Axial Capital Pvt. Ltd.; '\n",
      "                                                   'Registrar: MUFG Intime '\n",
      "                                                   'India Pvt.Ltd.',\n",
      "                      'Listing Exchanges': 'BSE, NSE',\n",
      "                      'Market Lot & Amounts': 'Min: 137 shares/‚Çπ14,933; Max '\n",
      "                                              '(Retail): 1,781 '\n",
      "                                              'shares/‚Çπ1,94,129; S-HNI: '\n",
      "                                              '1,918‚Äì9,042 '\n",
      "                                              'shares/‚Çπ2,09,062‚Äì‚Çπ9,85,578; '\n",
      "                                              'B-HNI: 9,179 shares/‚Çπ10,00,511',\n",
      "                      'Peer Comparison': 'There are no listed peers of the '\n",
      "                                         'Company.',\n",
      "                      'Price Band': '‚Çπ103 to ‚Çπ109',\n",
      "                      'Promoter Holdings (Pre/Post)': 'Pre: 2,60,79,56,938 '\n",
      "                                                      '(81.64%); Post: '\n",
      "                                                      '2,89,23,60,607 (-%)',\n",
      "                      'Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)': 'EPS: '\n",
      "                                                                     '‚Çπ(0.86) '\n",
      "                                                                     '(Basic); '\n",
      "                                                                     'ROE: '\n",
      "                                                                     '(12.50)%; '\n",
      "                                                                     'ROCE: '\n",
      "                                                                     '-%; D/E: '\n",
      "                                                                     '‚Äì; NAV: '\n",
      "                                                                     '‚Çπ7.73',\n",
      "                      'extracted_at': '2025-11-09T10:41:52.355186',\n",
      "                      'ipo': 'PhysicsWallah',\n",
      "                      'raw_markdown': '| IPO                | Price '\n",
      "                                      'Band           | Issue Size         | '\n",
      "                                      'Issue Type        | Listing Exchanges | '\n",
      "                                      'IPO '\n",
      "                                      'Dates                                   '\n",
      "                                      '| Market Lot & '\n",
      "                                      'Amounts                                                                                  '\n",
      "                                      '| Investor Quota Split         | Anchor '\n",
      "                                      'Details                                                                                                 '\n",
      "                                      '| Promoter Holdings (Pre/Post) | '\n",
      "                                      'Financial Performance '\n",
      "                                      '(FY23‚ÄìFY25)                                                                 '\n",
      "                                      '| Valuation Ratios (EPS, ROE, ROCE, '\n",
      "                                      'D/E, NAV) | Lead Managers & Registrar | '\n",
      "                                      'Company '\n",
      "                                      'Overview                                                                                                   '\n",
      "                                      '| Peer Comparison |\\n'\n",
      "                                      '|--------------------|---------------------|--------------------|-------------------|-------------------|---------------------------------------------|-------------------------------------------------------------------------------------------------------|------------------------------|------------------------------------------------------------------------------------------------------------------|------------------------------|------------------------------------------------------------------------------------------------------------------|---------------------------------------------|--------------------------|-------------------------------------------------------------------------------------------------------------------|------------------|\\n'\n",
      "                                      '| PhysicsWallah Ltd. | ‚Çπ103 to '\n",
      "                                      '‚Çπ109        | ‚Çπ3,480 Crores      | Book '\n",
      "                                      'Built Issue  | BSE, NSE          | Nov '\n",
      "                                      '11‚Äì13, 2025 (Listing: Nov 18, 2025)    '\n",
      "                                      '| Min: 137 shares/‚Çπ14,933; Max '\n",
      "                                      '(Retail): 1,781 shares/‚Çπ1,94,129; '\n",
      "                                      'S-HNI: 1,918‚Äì9,042 '\n",
      "                                      'shares/‚Çπ2,09,062‚Äì‚Çπ9,85,578; B-HNI: '\n",
      "                                      '9,179 shares/‚Çπ10,00,511 | QIB: 75%, '\n",
      "                                      'NII: 15%, Retail: 10% | Anchor bidding: '\n",
      "                                      'Nov 10, 2025; Lock-in: 50% till Dec 14, '\n",
      "                                      '2025, 50% till Feb 12, 2026; Anchor '\n",
      "                                      'list: [PDF], Size: [.] Cr. '\n",
      "                                      '|                          | FY24: '\n",
      "                                      '‚Çπ2,015.35 Cr revenue, ‚Çπ1,131.13 Cr '\n",
      "                                      'loss; FY25: ‚Çπ3,039.09 Cr revenue, '\n",
      "                                      '‚Çπ243.26 Cr loss                '\n",
      "                                      '|                                             '\n",
      "                                      '|                          | Edtech '\n",
      "                                      'company founded 2020, online/offline '\n",
      "                                      'learning, 3.5M+ students, 8M+ YouTube '\n",
      "                                      'subscribers, strong hybrid model '\n",
      "                                      '|                  |',\n",
      "                      'url': 'https://ipowatch.in/physicswallah-ipo-date-review-price-allotment-details/'},\n",
      " 'extraction_history': [{'extracted_at': '2025-11-10T04:51:06.629729',\n",
      "                         'fields_added': {'Lead Managers & Registrar': 'Lead '\n",
      "                                                                       'Managers: '\n",
      "                                                                       'Kotak '\n",
      "                                                                       'Mahindra '\n",
      "                                                                       'Capital '\n",
      "                                                                       'Co. '\n",
      "                                                                       'Ltd., '\n",
      "                                                                       'JP '\n",
      "                                                                       'Morgan '\n",
      "                                                                       'India '\n",
      "                                                                       'Pvt. '\n",
      "                                                                       'Ltd, '\n",
      "                                                                       'Goldman '\n",
      "                                                                       'Sachs '\n",
      "                                                                       '(India) '\n",
      "                                                                       'Securities '\n",
      "                                                                       'Pvt. '\n",
      "                                                                       'Ltd., '\n",
      "                                                                       'Axial '\n",
      "                                                                       'Capital '\n",
      "                                                                       'Pvt. '\n",
      "                                                                       'Ltd.; '\n",
      "                                                                       'Registrar: '\n",
      "                                                                       'MUFG '\n",
      "                                                                       'Intime '\n",
      "                                                                       'India '\n",
      "                                                                       'Pvt.Ltd.',\n",
      "                                          'Peer Comparison': 'There are no '\n",
      "                                                             'listed peers of '\n",
      "                                                             'the Company.',\n",
      "                                          'Promoter Holdings (Pre/Post)': 'Pre: '\n",
      "                                                                          '2,60,79,56,938 '\n",
      "                                                                          '(81.64%); '\n",
      "                                                                          'Post: '\n",
      "                                                                          '2,89,23,60,607 '\n",
      "                                                                          '(-%)',\n",
      "                                          'Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)': 'EPS: '\n",
      "                                                                                         '‚Çπ(0.86) '\n",
      "                                                                                         '(Basic); '\n",
      "                                                                                         'ROE: '\n",
      "                                                                                         '(12.50)%; '\n",
      "                                                                                         'ROCE: '\n",
      "                                                                                         '-%; '\n",
      "                                                                                         'D/E: '\n",
      "                                                                                         '‚Äì; '\n",
      "                                                                                         'NAV: '\n",
      "                                                                                         '‚Çπ7.73'},\n",
      "                         'raw_markdown': '| Price Band | Issue Size | Issue '\n",
      "                                         'Type | Listing Exchanges | IPO Dates '\n",
      "                                         '| Market Lot & Amounts | Investor '\n",
      "                                         'Quota Split | Anchor Details | '\n",
      "                                         'Promoter Holdings (Pre/Post) | '\n",
      "                                         'Financial Performance (FY23‚ÄìFY25) | '\n",
      "                                         'Valuation Ratios (EPS, ROE, ROCE, '\n",
      "                                         'D/E, NAV) | Lead Managers & '\n",
      "                                         'Registrar | Company Overview | Peer '\n",
      "                                         'Comparison | ipo |\\n'\n",
      "                                         '|------------|------------|------------|-------------------|-----------|----------------------|----------------------|---------------|------------------------------|-----------------------------------|---------------------------------------------|--------------------------|------------------|------------------|-----|\\n'\n",
      "                                         '| ‚Çπ103 to ‚Çπ109 | ‚Çπ3,480 Crores | '\n",
      "                                         'Book Built Issue | BSE, NSE | Nov '\n",
      "                                         '11‚Äì13, 2025 (Listing: Nov 18, 2025) '\n",
      "                                         '| Min: 137 shares/‚Çπ14,933; Max '\n",
      "                                         '(Retail): 1,781 shares/‚Çπ1,94,129; '\n",
      "                                         'S-HNI: 1,918‚Äì9,042 '\n",
      "                                         'shares/‚Çπ2,09,062‚Äì‚Çπ9,85,578; B-HNI: '\n",
      "                                         '9,179 shares/‚Çπ10,00,511 | QIB: 75%, '\n",
      "                                         'NII: 15%, Retail: 10% | Anchor '\n",
      "                                         'bidding: Nov 10, 2025; Lock-in: 50% '\n",
      "                                         'till Dec 14, 2025, 50% till Feb 12, '\n",
      "                                         '2026; Anchor list: [PDF], Size: [.] '\n",
      "                                         'Cr. | Pre: 2,60,79,56,938 (81.64%); '\n",
      "                                         'Post: 2,89,23,60,607 (-%) | FY24: '\n",
      "                                         '‚Çπ2,015.35 Cr revenue, ‚Çπ1,131.13 Cr '\n",
      "                                         'loss; FY25: ‚Çπ3,039.09 Cr revenue, '\n",
      "                                         '‚Çπ243.26 Cr loss | EPS: ‚Çπ(0.86) '\n",
      "                                         '(Basic); ROE: (12.50)%; ROCE: -%; '\n",
      "                                         'D/E: ‚Äì; NAV: ‚Çπ7.73 | Lead Managers: '\n",
      "                                         'Kotak Mahindra Capital Co. Ltd., JP '\n",
      "                                         'Morgan India Pvt. Ltd, Goldman Sachs '\n",
      "                                         '(India) Securities Pvt. Ltd., Axial '\n",
      "                                         'Capital Pvt. Ltd.; Registrar: MUFG '\n",
      "                                         'Intime India Pvt.Ltd. | Edtech '\n",
      "                                         'company founded 2020, online/offline '\n",
      "                                         'learning, 3.5M+ students, 8M+ '\n",
      "                                         'YouTube subscribers, strong hybrid '\n",
      "                                         'model | There are no listed peers of '\n",
      "                                         'the Company. | PhysicsWallah |',\n",
      "                         'source_url': 'https://ipowatch.in/physicswallah-ipo-date-review-price-allotment-details/'}],\n",
      " 'gmp_diff': 5.0,\n",
      " 'gmp_investorgain': 35.0,\n",
      " 'gmp_ipowatch': 30.0,\n",
      " 'inserted_at': '2025-11-08T15:05:12.990572',\n",
      " 'ipo': 'PhysicsWallah',\n",
      " 'issue_price': {'avg': 103.0, 'max': 103.0, 'min': 103.0},\n",
      " 'last_extracted_at': '2025-11-10T04:51:06.629729',\n",
      " 'open_date': '2025-11-11',\n",
      " 'raw': {'GMP_Diff': '5',\n",
      "         'GMP_IPOWatch': '30',\n",
      "         'GMP_InvestorGain': '35',\n",
      "         'Issue_Price': '‚Çπ103 ‚Äì ‚Çπ109'}}\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "# MongoDB connection\n",
    "MONGO_URI = \"mongodb://localhost:27017\"\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "\n",
    "def analyze_mongo_data():\n",
    "    # Connect to MongoDB\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[DB_NAME]\n",
    "    collection = db[COL_IPOS]\n",
    "    \n",
    "    # Get all IPO records\n",
    "    records = list(collection.find())\n",
    "    print(f\"\\nüîç Found {len(records)} total IPO records\\n\")\n",
    "\n",
    "    # Analyze data completeness\n",
    "    fields_present = {}\n",
    "    extracted_fields_present = {}\n",
    "    \n",
    "    for record in records:\n",
    "        # Check top-level fields\n",
    "        for field in record.keys():\n",
    "            fields_present[field] = fields_present.get(field, 0) + 1\n",
    "            \n",
    "        # Check extracted_fields if present\n",
    "        if 'extracted_fields' in record:\n",
    "            extracted = record['extracted_fields']\n",
    "            for field in extracted.keys():\n",
    "                extracted_fields_present[field] = extracted_fields_present.get(field, 0) + 1\n",
    "    \n",
    "    print(\"üìä Top-level fields presence:\")\n",
    "    for field, count in fields_present.items():\n",
    "        print(f\"{field}: {count}/{len(records)} records\")\n",
    "    \n",
    "    print(\"\\nüìä Extracted fields presence:\")\n",
    "    for field, count in extracted_fields_present.items():\n",
    "        print(f\"{field}: {count}/{len(records)} records\")\n",
    "    \n",
    "    # Print a sample record with extracted fields\n",
    "    sample = collection.find_one({\"extracted_fields\": {\"$exists\": True}})\n",
    "    if sample:\n",
    "        print(\"\\nüìù Sample IPO record with extracted fields:\")\n",
    "        pprint(sample)\n",
    "\n",
    "    client.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_mongo_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f12fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Fetching IPO data from MongoDB...\n",
      "üîç Found 10 total IPO records.\n",
      "‚úÖ 6 IPOs scored and written to 'ipo_analysis'\n",
      "\n",
      "üìä Summary:\n",
      "Scored: 6\n",
      "Skipped: 4\n",
      "Skipped details:\n",
      " - Tenneco Clean Air India: missing_critical_data\n",
      " - Mahamaya Lifesciences: skip_few_fields(4)\n",
      " - Curis Lifesciences: skip_few_fields(4)\n",
      " - Finbud Financial: missing_critical_data\n",
      "\n",
      "üèÜ Top Recommendations:\n",
      " PhysicsWallah: 5.8/10 ‚Äî Moderate (GMP 33.02%)\n",
      " Emmvee Photovoltaic Power: 5.1/10 ‚Äî Moderate (GMP 18.91%)\n",
      " Workmates Core2Cloud: 4.9/10 ‚Äî Moderate (GMP 10.89%)\n",
      " Shining Tools: 4.9/10 ‚Äî Moderate (GMP 10.53%)\n",
      " Tenneco Clean Air: 4.7/10 ‚Äî Moderate (GMP 11.61%)\n",
      " Shreeji Global FMCG: 4.7/10 ‚Äî Moderate (GMP 6.53%)\n",
      "\n",
      "üèÅ Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import findspark\n",
    "\n",
    "# ---------- SPARK & ENV SETUP ----------\n",
    "findspark.init()\n",
    "PYTHON_PATH = r\"C:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = PYTHON_PATH\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = PYTHON_PATH\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"C:/spark-temp\"\n",
    "os.makedirs(\"C:/spark-temp\", exist_ok=True)\n",
    "\n",
    "if SparkContext._active_spark_context:\n",
    "    SparkContext._active_spark_context.stop()\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "COL_ANALYSIS = \"ipo_analysis\"\n",
    "\n",
    "SPARK_PARALLELISM = 4\n",
    "\n",
    "# ---------- SCORING WEIGHTS ----------\n",
    "W_GMP = 0.45\n",
    "W_PRICE = 0.20\n",
    "W_SIZE = 0.20\n",
    "W_EXPECT = 0.15\n",
    "\n",
    "# ---------- UTILITIES ----------\n",
    "def get_mongo_data():\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    data = list(client[DB_NAME][COL_IPOS].find({}))\n",
    "    client.close()\n",
    "    return data\n",
    "\n",
    "def write_results(results):\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    coll = client[DB_NAME][COL_ANALYSIS]\n",
    "    for rec in results:\n",
    "        coll.update_one({\"ipo\": rec[\"ipo\"]}, {\"$set\": rec}, upsert=True)\n",
    "    client.close()\n",
    "\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(str(x).replace(\"‚Çπ\", \"\").replace(\",\", \"\").strip())\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_issue_price(value):\n",
    "    \"\"\"Parse avg issue price\"\"\"\n",
    "    if isinstance(value, dict):\n",
    "        return value.get(\"avg\") or value.get(\"mid\") or value.get(\"min\")\n",
    "    if not value:\n",
    "        return None\n",
    "    nums = re.findall(r\"\\d+\\.?\\d*\", str(value))\n",
    "    if not nums:\n",
    "        return None\n",
    "    nums = [safe_float(x) for x in nums]\n",
    "    return sum(nums)/len(nums)\n",
    "\n",
    "def parse_issue_size(value):\n",
    "    if not value:\n",
    "        return None\n",
    "    s = str(value).lower().replace(\",\", \"\")\n",
    "    m = re.search(r\"(\\d+\\.?\\d*)\\s*(cr|crore|lakh|lac|mn|m|bn|b)?\", s)\n",
    "    if not m:\n",
    "        return None\n",
    "    num = float(m.group(1))\n",
    "    mult = (m.group(2) or \"\").lower()\n",
    "    if mult in [\"cr\", \"crore\"]:\n",
    "        return num * 1e7\n",
    "    if mult in [\"lakh\", \"lac\"]:\n",
    "        return num * 1e5\n",
    "    if mult in [\"mn\", \"m\"]:\n",
    "        return num * 1e6\n",
    "    if mult in [\"bn\", \"b\"]:\n",
    "        return num * 1e9\n",
    "    return num\n",
    "\n",
    "# ---------- SCORING ----------\n",
    "def compute_score(doc):\n",
    "    fields = doc.get(\"extracted_fields\", {}) or {}\n",
    "    ipo = doc.get(\"ipo\") or fields.get(\"IPO\")\n",
    "\n",
    "    # Skip IPOs with too few extracted fields\n",
    "    nonempty_fields = len([v for v in fields.values() if v not in [None, \"\", {}]])\n",
    "    if nonempty_fields < 5:\n",
    "        return {\"ipo\": ipo, \"status\": f\"skip_few_fields({nonempty_fields})\"}\n",
    "\n",
    "    # Try multiple fallbacks for GMP\n",
    "    gmp = safe_float(fields.get(\"GMP_InvestorGain\")) or safe_float(fields.get(\"GMP_IPOWatch\")) \\\n",
    "        or safe_float(doc.get(\"gmp_investorgain\")) or safe_float(doc.get(\"gmp_ipowatch\"))\n",
    "    issue_price = parse_issue_price(fields.get(\"Price Band\") or fields.get(\"Issue_Price\") or doc.get(\"issue_price\"))\n",
    "    issue_size = parse_issue_size(fields.get(\"Issue Size\") or fields.get(\"Issue_Size\") or doc.get(\"issue_size\"))\n",
    "\n",
    "    if not all([gmp, issue_price, issue_size]):\n",
    "        return {\"ipo\": ipo, \"status\": \"missing_critical_data\"}\n",
    "\n",
    "    # 1Ô∏è‚É£ GMP Score (relative to issue price)\n",
    "    gmp_pct = (gmp / issue_price) * 100\n",
    "    gmp_score = min(max(gmp_pct, 0), 100)\n",
    "\n",
    "    # 2Ô∏è‚É£ Price Score (retail affordability)\n",
    "    if issue_price < 100:\n",
    "        price_score = 90\n",
    "    elif issue_price < 500:\n",
    "        price_score = 80\n",
    "    elif issue_price < 1000:\n",
    "        price_score = 60\n",
    "    else:\n",
    "        price_score = 40\n",
    "\n",
    "    # 3Ô∏è‚É£ Size Score (mid-size preferred)\n",
    "    if issue_size < 1e8:\n",
    "        size_score = 40\n",
    "    elif issue_size < 1e9:\n",
    "        size_score = 70\n",
    "    elif issue_size < 5e9:\n",
    "        size_score = 90\n",
    "    else:\n",
    "        size_score = 60\n",
    "\n",
    "    # 4Ô∏è‚É£ Expected Listing Gain\n",
    "    expect_score = min(max(gmp_pct / 2 + 50, 0), 100)\n",
    "\n",
    "    # Weighted average\n",
    "    total = (\n",
    "        W_GMP * gmp_score +\n",
    "        W_PRICE * price_score +\n",
    "        W_SIZE * size_score +\n",
    "        W_EXPECT * expect_score\n",
    "    )\n",
    "\n",
    "    score = round((total / 100) * 9 + 1, 1)\n",
    "    verdict = \"Good\" if score >= 7 else \"Moderate\" if score >= 4 else \"Bad\"\n",
    "\n",
    "    return {\n",
    "        \"ipo\": ipo,\n",
    "        \"gmp\": gmp,\n",
    "        \"issue_price\": issue_price,\n",
    "        \"issue_size\": issue_size,\n",
    "        \"gmp_pct\": round(gmp_pct, 2),\n",
    "        \"score\": score,\n",
    "        \"verdict\": verdict,\n",
    "        \"scored_at\": datetime.utcnow().isoformat(),\n",
    "        \"components\": {\n",
    "            \"GMP\": gmp_score,\n",
    "            \"Price\": price_score,\n",
    "            \"Size\": size_score,\n",
    "            \"Expectation\": expect_score\n",
    "        },\n",
    "        \"status\": \"scored\"\n",
    "    }\n",
    "\n",
    "# ---------- SPARK SETUP ----------\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .setMaster(f\"local[{SPARK_PARALLELISM}]\")\n",
    "    .setAppName(\"IPO-Scoring-v2\")\n",
    "    .set(\"spark.local.dir\", \"C:/spark-temp\")\n",
    ")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üì° Fetching IPO data from MongoDB...\")\n",
    "    docs = get_mongo_data()\n",
    "    print(f\"üîç Found {len(docs)} total IPO records.\")\n",
    "\n",
    "    if not docs:\n",
    "        print(\"‚ö†Ô∏è No records found.\")\n",
    "        sc.stop()\n",
    "        exit()\n",
    "\n",
    "    rdd = sc.parallelize(docs, min(len(docs), SPARK_PARALLELISM))\n",
    "    results = rdd.map(compute_score).collect()\n",
    "    sc.stop()\n",
    "\n",
    "    scored = [r for r in results if r.get(\"status\") == \"scored\"]\n",
    "    skipped = [r for r in results if r.get(\"status\") != \"scored\"]\n",
    "\n",
    "    if scored:\n",
    "        write_results(scored)\n",
    "        print(f\"‚úÖ {len(scored)} IPOs scored and written to '{COL_ANALYSIS}'\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No IPOs scored (all skipped).\")\n",
    "\n",
    "    print(\"\\nüìä Summary:\")\n",
    "    print(\"Scored:\", len(scored))\n",
    "    print(\"Skipped:\", len(skipped))\n",
    "    if skipped:\n",
    "        print(\"Skipped details:\")\n",
    "        for s in skipped:\n",
    "            print(f\" - {s['ipo']}: {s['status']}\")\n",
    "\n",
    "    if scored:\n",
    "        print(\"\\nüèÜ Top Recommendations:\")\n",
    "        top = sorted(scored, key=lambda x: x[\"score\"], reverse=True)[:10]\n",
    "        for t in top:\n",
    "            print(f\" {t['ipo']}: {t['score']}/10 ‚Äî {t['verdict']} (GMP {t['gmp_pct']}%)\")\n",
    "\n",
    "    print(\"\\nüèÅ Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6670411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPO portfolio optimizer\n",
      "\n",
      "\n",
      "Loaded 10 IPOs and 6 scored analyses.\n",
      "\n",
      "Found 6 eligible IPO candidates for allocation.\n",
      "\n",
      "PhysicsWallah | Mainboard | Score: 5.8 | Issue: 103.0 | Lot: 137 | Min invest: 15000 | Close: 2025-11-13\n",
      "Emmvee Photovoltaic Power | Mainboard | Score: 5.1 | Issue: 206.0 | Lot: 69 | Min invest: 15000 | Close: 2025-11-13\n",
      "Workmates Core2Cloud | SME | Score: 4.9 | Issue: 200.0 | Lot: 1 | Min invest: 200 | Close: 2025-11-13\n",
      "Tenneco Clean Air | Mainboard | Score: 4.7 | Issue: 378.0 | Lot: 37 | Min invest: 15000 | Close: 2025-11-14\n",
      "Shining Tools | SME | Score: 4.9 | Issue: 114.0 | Lot: 2 | Min invest: 228 | Close: 2025-11-11\n",
      "Shreeji Global FMCG | SME | Score: 4.7 | Issue: 120.0 | Lot: 2 | Min invest: 240 | Close: 2025-11-07\n",
      "\n",
      "--- Allocation Plan ---\n",
      "Workmates Core2Cloud: lots=23, invest=‚Çπ4600, score=4.9, issue_mid=200.0, min_invest_unit=‚Çπ200\n",
      "Shining Tools: lots=22, invest=‚Çπ5016, score=4.9, issue_mid=114.0, min_invest_unit=‚Çπ228\n",
      "Shreeji Global FMCG: lots=22, invest=‚Çπ5280, score=4.7, issue_mid=120.0, min_invest_unit=‚Çπ240\n",
      "PhysicsWallah: lots=1, invest=‚Çπ15000, score=5.8, issue_mid=103.0, min_invest_unit=‚Çπ15000\n",
      "Emmvee Photovoltaic Power: lots=1, invest=‚Çπ15000, score=5.1, issue_mid=206.0, min_invest_unit=‚Çπ15000\n",
      "\n",
      "Total invested: ‚Çπ44896\n",
      "Leftover cash: ‚Çπ104\n",
      "\n",
      "Recommendation saved to MongoDB collection: ipo_portfolio_recommendations\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "COL_ANALYSIS = \"ipo_analysis\"\n",
    "COL_RECOMMEND = \"ipo_portfolio_recommendations\"\n",
    "\n",
    "MIN_INVEST_MAINBOARD = 15000  # INR minimum investment for mainboard (user requirement)\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(str(x).replace(\"‚Çπ\", \"\").replace(\",\", \"\").strip())\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_price_mid(issue_price_field):\n",
    "    \"\"\"Try to get average/mid issue price from possible field formats.\"\"\"\n",
    "    if not issue_price_field:\n",
    "        return None\n",
    "    if isinstance(issue_price_field, dict):\n",
    "        return safe_float(issue_price_field.get(\"avg\") or issue_price_field.get(\"mid\") or issue_price_field.get(\"min\"))\n",
    "    # string like \"‚Çπ206-‚Çπ217\" or \"206-217\"\n",
    "    s = str(issue_price_field)\n",
    "    nums = re.findall(r\"\\d+\\.?\\d*\", s)\n",
    "    nums = [safe_float(n) for n in nums if safe_float(n) is not None]\n",
    "    if not nums:\n",
    "        return None\n",
    "    return sum(nums) / len(nums)\n",
    "\n",
    "def parse_lot_from_str(s):\n",
    "    \"\"\"\n",
    "    Parse market lot from strings like 'Lot Size: 137' or 'Market Lot 69' or 'Lot: 1200 shares'\n",
    "    Return integer lot if found else None.\n",
    "    \"\"\"\n",
    "    if not s:\n",
    "        return None\n",
    "    s = str(s)\n",
    "    # common patterns: \"Lot: 1200\", \"lot size 1200\", \"market lot 1200\"\n",
    "    m = re.search(r\"(?:lot size|lot|market lot|market_lot)\\D*(\\d{1,5})\", s, flags=re.I)\n",
    "    if m:\n",
    "        try:\n",
    "            return int(m.group(1))\n",
    "        except:\n",
    "            return None\n",
    "    # fallback: find first reasonable integer > 1\n",
    "    nums = re.findall(r\"\\d+\", s)\n",
    "    for n in nums:\n",
    "        val = int(n)\n",
    "        if val > 1 and val < 100000:\n",
    "            return val\n",
    "    return None\n",
    "\n",
    "def get_mongo_col(colname):\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    return client[DB_NAME][colname], client\n",
    "\n",
    "def load_ipos_and_scores():\n",
    "    ipos_col, client = get_mongo_col(COL_IPOS)\n",
    "    analysis_col = client[DB_NAME][COL_ANALYSIS]\n",
    "    ipos_docs = list(ipos_col.find({}))\n",
    "    # build dict by ipo name\n",
    "    ipos_by_name = {}\n",
    "    for d in ipos_docs:\n",
    "        name = d.get(\"ipo\")\n",
    "        ipos_by_name[name] = d\n",
    "    # load analysis\n",
    "    scored = {}\n",
    "    for a in list(analysis_col.find({})):\n",
    "        name = a.get(\"ipo\")\n",
    "        if name:\n",
    "            scored[name] = a\n",
    "    client.close()\n",
    "    return ipos_by_name, scored\n",
    "\n",
    "# ---------- ALLOCATION ALGORITHM ----------\n",
    "def prepare_candidates(ipos_by_name, scored, hold_until_date_obj):\n",
    "    \"\"\"\n",
    "    Build candidate list with fields:\n",
    "    - ipo\n",
    "    - category (Mainboard/SME)\n",
    "    - score (1..10)\n",
    "    - issue_mid\n",
    "    - lot (int or None)\n",
    "    - min_invest (INR) = lot*issue_mid or MIN_INVEST_MAINBOARD\n",
    "    - close_date (date object)\n",
    "    - total_score_per_rupee = score / min_invest (used for greedy)\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    for name, ipo_doc in ipos_by_name.items():\n",
    "        analysis = scored.get(name)\n",
    "        if not analysis or analysis.get(\"status\") != \"scored\":\n",
    "            continue\n",
    "        fields = ipo_doc.get(\"extracted_fields\", {}) or {}\n",
    "        # close_date fallback top-level\n",
    "        close_date_str = fields.get(\"Close_Date\") or ipo_doc.get(\"close_date\") or fields.get(\"IPO Dates\") or ipo_doc.get(\"close_date\")\n",
    "        # try to parse close date in formats we might have\n",
    "        close_date = None\n",
    "        if close_date_str:\n",
    "            try:\n",
    "                # some strings can be ranges like \"11-Nov to 13-Nov\", so pick first date-like substring\n",
    "                ds = re.findall(r\"\\d{4}-\\d{2}-\\d{2}|\\d{1,2}[-/][A-Za-z]{3,9}[-/]\\d{2,4}|\\d{1,2}\\s+[A-Za-z]{3,9}\\s+\\d{4}\", str(close_date_str))\n",
    "                if ds:\n",
    "                    close_date = try_parse_date(ds[0])\n",
    "                else:\n",
    "                    close_date = try_parse_date(close_date_str)\n",
    "            except:\n",
    "                close_date = None\n",
    "        # if close_date missing, skip (we need it for horizon filter)\n",
    "        if not close_date:\n",
    "            continue\n",
    "        # only include if close_date <= hold_until_date_obj (user can hold until)\n",
    "        if close_date > hold_until_date_obj:\n",
    "            # NOT eligible ‚Äî user cannot hold until listing/allotment\n",
    "            continue\n",
    "\n",
    "        # get category\n",
    "        category = ipo_doc.get(\"category\") or fields.get(\"Category\") or fields.get(\"IPO Type\") or \"\"\n",
    "        category = category.strip().lower()\n",
    "\n",
    "        # score\n",
    "        score = analysis.get(\"score\")\n",
    "        if score is None:\n",
    "            continue\n",
    "\n",
    "        # issue price mid\n",
    "        issue_mid = parse_price_from_fields(fields, ipo_doc)\n",
    "\n",
    "        if issue_mid is None:\n",
    "            continue\n",
    "\n",
    "        # lot parsing\n",
    "        lot = None\n",
    "        lot = parse_lot_from_str(fields.get(\"Market Lot & Amounts\") or fields.get(\"Market Lot\") or fields.get(\"Market_Lot\") or fields.get(\"Lot\") or ipo_doc.get(\"lot\"))\n",
    "        # fallback: sometimes 'Market Lot & Amounts' contains numbers; try parse\n",
    "        if not lot:\n",
    "            lot = parse_lot_from_str(fields.get(\"Market Lot & Amounts\") or \"\")\n",
    "\n",
    "        # compute min_invest\n",
    "        if \"sme\" in category:\n",
    "            # for SME we need a lot to compute min investment; if not found, skip SME\n",
    "            if not lot:\n",
    "                continue\n",
    "            min_invest = lot * issue_mid\n",
    "        else:\n",
    "            # mainboard: if lot present use lot*issue_mid but ensure min at least MIN_INVEST_MAINBOARD\n",
    "            if lot:\n",
    "                min_invest = max(MIN_INVEST_MAINBOARD, lot * issue_mid)\n",
    "            else:\n",
    "                min_invest = MIN_INVEST_MAINBOARD\n",
    "\n",
    "        # prepare candidate\n",
    "        candidates.append({\n",
    "            \"ipo\": name,\n",
    "            \"category\": \"SME\" if \"sme\" in category else \"Mainboard\",\n",
    "            \"score\": score,\n",
    "            \"issue_mid\": issue_mid,\n",
    "            \"lot\": lot,\n",
    "            \"min_invest\": float(min_invest),\n",
    "            \"close_date\": close_date,\n",
    "            \"gmp_pct\": analysis.get(\"gmp_pct\")\n",
    "        })\n",
    "    return candidates\n",
    "\n",
    "def try_parse_date(s):\n",
    "    \"\"\"Try several date formats and return date object; fallback to None\"\"\"\n",
    "    s = str(s).strip()\n",
    "    # try ISO first\n",
    "    try:\n",
    "        return datetime.strptime(s[:10], \"%Y-%m-%d\").date()\n",
    "    except:\n",
    "        pass\n",
    "    # try common formats\n",
    "    fmts = [\"%d-%b-%Y\", \"%d-%b-%y\", \"%d %b %Y\", \"%d %b %y\", \"%d-%m-%Y\", \"%d/%m/%Y\"]\n",
    "    for f in fmts:\n",
    "        try:\n",
    "            return datetime.strptime(s, f).date()\n",
    "        except:\n",
    "            pass\n",
    "    # try parse by splitting and using day-month combos\n",
    "    try:\n",
    "        import dateutil.parser\n",
    "        return dateutil.parser.parse(s, dayfirst=False).date()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_price_from_fields(fields, ipo_doc):\n",
    "    # try several possibilities to get issue mid price\n",
    "    for key in [\"Issue_Price\", \"Issue Price\", \"Price Band\", \"issue_price\", \"Issue_Price_struct\", \"issue_price_struct\"]:\n",
    "        v = fields.get(key) or ipo_doc.get(key) or ipo_doc.get(\"issue_price\")\n",
    "        if v:\n",
    "            mid = None\n",
    "            if isinstance(v, dict):\n",
    "                mid = v.get(\"avg\") or v.get(\"mid\") or v.get(\"min\")\n",
    "                if mid: return safe_float(mid)\n",
    "            else:\n",
    "                # parse numbers\n",
    "                nums = re.findall(r\"\\d+\\.?\\d*\", str(v))\n",
    "                if nums:\n",
    "                    nums = [safe_float(n) for n in nums if safe_float(n) is not None]\n",
    "                    if nums:\n",
    "                        return sum(nums)/len(nums)\n",
    "    # fallback top-level fields that your pipeline created\n",
    "    ip = ipo_doc.get(\"issue_price\")\n",
    "    if ip:\n",
    "        try:\n",
    "            return float(ip)\n",
    "        except:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def allocate_budget_greedy(candidates, budget):\n",
    "    \"\"\"\n",
    "    Greedy algorithm:\n",
    "    - Sort candidates by score per rupee = score / min_invest descending\n",
    "    - For each candidate, allocate as many minimum \"lots\" as possible while budget allows,\n",
    "      but we prefer to allocate only one min_invest per candidate first (diversification),\n",
    "      then second pass add extra lots proportional to score per rupee.\n",
    "    - Returns allocation list with lots_count and invested amount.\n",
    "    \"\"\"\n",
    "    # compute score_per_rupee\n",
    "    for c in candidates:\n",
    "        c[\"score_per_rupee\"] = (c[\"score\"] / c[\"min_invest\"]) if c[\"min_invest\"] > 0 else 0\n",
    "\n",
    "    # sort descending by score_per_rupee\n",
    "    candidates = sorted(candidates, key=lambda x: x[\"score_per_rupee\"], reverse=True)\n",
    "\n",
    "    allocation = []\n",
    "    remain = budget\n",
    "\n",
    "    # first pass: try to give each candidate one minimum unit (diversify)\n",
    "    for c in candidates:\n",
    "        if remain >= c[\"min_invest\"]:\n",
    "            # number of lots to allocate initially = 1 (or for SME maybe 1 lot)\n",
    "            lots = 1\n",
    "            invested = c[\"min_invest\"] * lots\n",
    "            allocation.append({\n",
    "                \"ipo\": c[\"ipo\"],\n",
    "                \"category\": c[\"category\"],\n",
    "                \"score\": c[\"score\"],\n",
    "                \"issue_mid\": c[\"issue_mid\"],\n",
    "                \"lot\": c[\"lot\"],\n",
    "                \"lots_allocated\": lots,\n",
    "                \"invested\": invested,\n",
    "                \"min_invest\": c[\"min_invest\"],\n",
    "                \"score_per_rupee\": c[\"score_per_rupee\"]\n",
    "            })\n",
    "            remain -= invested\n",
    "        else:\n",
    "            # cannot afford min for this candidate\n",
    "            allocation.append({\n",
    "                \"ipo\": c[\"ipo\"],\n",
    "                \"category\": c[\"category\"],\n",
    "                \"score\": c[\"score\"],\n",
    "                \"issue_mid\": c[\"issue_mid\"],\n",
    "                \"lot\": c[\"lot\"],\n",
    "                \"lots_allocated\": 0,\n",
    "                \"invested\": 0.0,\n",
    "                \"min_invest\": c[\"min_invest\"],\n",
    "                \"score_per_rupee\": c[\"score_per_rupee\"]\n",
    "            })\n",
    "\n",
    "    # second pass: distribute remaining funds greedily into highest score_per_rupee candidates\n",
    "    # allow adding additional lots for the same IPO (respect multiples)\n",
    "    changed = True\n",
    "    while changed and remain >= min([c[\"min_invest\"] for c in candidates]):\n",
    "        changed = False\n",
    "        # iterate over sorted candidates\n",
    "        for idx, c in enumerate(candidates):\n",
    "            # find allocation entry\n",
    "            alloc = next((a for a in allocation if a[\"ipo\"] == c[\"ipo\"]), None)\n",
    "            if not alloc:\n",
    "                continue\n",
    "            # cost for one more lot\n",
    "            cost = c[\"min_invest\"]\n",
    "            if remain >= cost:\n",
    "                # add one more lot\n",
    "                alloc[\"lots_allocated\"] += 1\n",
    "                alloc[\"invested\"] += cost\n",
    "                remain -= cost\n",
    "                changed = True\n",
    "            # if remain smaller, continue to next candidate\n",
    "    # remove those with zero lots\n",
    "    allocation = [a for a in allocation if a[\"lots_allocated\"] > 0]\n",
    "    return allocation, remain\n",
    "\n",
    "# ---------- MAIN INTERACTION & RUN ----------\n",
    "def main():\n",
    "    print(\"IPO portfolio optimizer\\n\")\n",
    "    # user inputs\n",
    "    try:\n",
    "        budget_in = input(\"Enter total investable amount in INR (e.g., 50000): \").strip()\n",
    "        budget = float(budget_in)\n",
    "    except:\n",
    "        print(\"Invalid budget. Exiting.\")\n",
    "        return\n",
    "\n",
    "    hold_until = input(\"Enter the date until which you can keep money (YYYY-MM-DD): \").strip()\n",
    "    try:\n",
    "        hold_date = datetime.strptime(hold_until, \"%Y-%m-%d\").date()\n",
    "    except:\n",
    "        print(\"Invalid date format. Use YYYY-MM-DD. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # load data\n",
    "    ipos_by_name, scored = load_ipos_and_scores()\n",
    "    print(\"\\nLoaded {} IPOs and {} scored analyses.\".format(len(ipos_by_name), len(scored)))\n",
    "\n",
    "    # prepare candidates\n",
    "    candidates = prepare_candidates(ipos_by_name, scored, hold_date)\n",
    "    if not candidates:\n",
    "        print(\"No eligible IPOs found for your hold date or missing critical fields. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nFound {len(candidates)} eligible IPO candidates for allocation.\\n\")\n",
    "    # show brief list\n",
    "    for c in candidates:\n",
    "        lot_text = str(c['lot']) if c['lot'] else \"N/A\"\n",
    "        print(f\"{c['ipo']} | {c['category']} | Score: {c['score']} | Issue: {c['issue_mid']} | Lot: {lot_text} | Min invest: {int(c['min_invest'])} | Close: {c['close_date']}\")\n",
    "\n",
    "    # allocate\n",
    "    allocation, leftover = allocate_budget_greedy(candidates, budget)\n",
    "\n",
    "    # print results\n",
    "    print(\"\\n--- Allocation Plan ---\")\n",
    "    total_invested = 0.0\n",
    "    if not allocation:\n",
    "        print(\"Could not allocate budget (insufficient funds for minimums).\")\n",
    "    else:\n",
    "        for a in allocation:\n",
    "            total_invested += a[\"invested\"]\n",
    "            print(f\"{a['ipo']}: lots={a['lots_allocated']}, invest=‚Çπ{int(a['invested'])}, score={a['score']}, issue_mid={a['issue_mid']}, min_invest_unit=‚Çπ{int(a['min_invest'])}\")\n",
    "    print(f\"\\nTotal invested: ‚Çπ{int(total_invested)}\")\n",
    "    print(f\"Leftover cash: ‚Çπ{int(leftover)}\")\n",
    "\n",
    "    # Save recommendation to Mongo\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    coll = client[DB_NAME][COL_RECOMMEND]\n",
    "    rec = {\n",
    "        \"created_at\": datetime.utcnow().isoformat(),\n",
    "        \"budget\": budget,\n",
    "        \"hold_until\": hold_date.isoformat(),\n",
    "        \"allocation\": allocation,\n",
    "        \"total_invested\": total_invested,\n",
    "        \"leftover\": leftover\n",
    "    }\n",
    "    coll.insert_one(rec)\n",
    "    client.close()\n",
    "    print(\"\\nRecommendation saved to MongoDB collection:\", COL_RECOMMEND)\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e9770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sample IPO record from MongoDB ('ipo_db.ipos'):\n",
      "\n",
      "{\n",
      "    \"_id\": {\n",
      "        \"$oid\": \"690f5be67ebcab56b4d5097a\"\n",
      "    },\n",
      "    \"ipo\": \"PhysicsWallah\",\n",
      "    \"category\": \"Mainboard\",\n",
      "    \"gmp_investorgain\": 35.0,\n",
      "    \"gmp_ipowatch\": 30.0,\n",
      "    \"gmp_diff\": 5.0,\n",
      "    \"issue_price\": {\n",
      "        \"min\": 103.0,\n",
      "        \"max\": 103.0,\n",
      "        \"avg\": 103.0\n",
      "    },\n",
      "    \"open_date\": \"2025-11-11\",\n",
      "    \"close_date\": \"2025-11-13\",\n",
      "    \"raw\": {\n",
      "        \"GMP_InvestorGain\": \"35\",\n",
      "        \"GMP_IPOWatch\": \"30\",\n",
      "        \"Issue_Price\": \"\\u20b9103 \\u2013 \\u20b9109\",\n",
      "        \"GMP_Diff\": \"5\"\n",
      "    },\n",
      "    \"inserted_at\": \"2025-11-08T15:05:12.990572\",\n",
      "    \"extracted_fields\": {\n",
      "        \"IPO\": \"PhysicsWallah Ltd.\",\n",
      "        \"Price Band\": \"\\u20b9103 to \\u20b9109\",\n",
      "        \"Issue Size\": \"\\u20b93,480 Crores\",\n",
      "        \"Issue Type\": \"Book Built Issue\",\n",
      "        \"Listing Exchanges\": \"BSE, NSE\",\n",
      "        \"IPO Dates\": \"Nov 11\\u201313, 2025 (Listing: Nov 18, 2025)\",\n",
      "        \"Market Lot & Amounts\": \"Min: 137 shares/\\u20b914,933; Max (Retail): 1,781 shares/\\u20b91,94,129; S-HNI: 1,918\\u20139,042 shares/\\u20b92,09,062\\u2013\\u20b99,85,578; B-HNI: 9,179 shares/\\u20b910,00,511\",\n",
      "        \"Investor Quota Split\": \"QIB: 75%, NII: 15%, Retail: 10%\",\n",
      "        \"Anchor Details\": \"Anchor bidding: Nov 10, 2025; Lock-in: 50% till Dec 14, 2025, 50% till Feb 12, 2026; Anchor list: [PDF], Size: [.] Cr.\",\n",
      "        \"Promoter Holdings (Pre/Post)\": \"Pre: 2,60,79,56,938 (81.64%); Post: 2,89,23,60,607 (-%)\",\n",
      "        \"Financial Performance (FY23\\u2013FY25)\": \"FY24: \\u20b92,015.35 Cr revenue, \\u20b91,131.13 Cr loss; FY25: \\u20b93,039.09 Cr revenue, \\u20b9243.26 Cr loss\",\n",
      "        \"Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)\": \"EPS: \\u20b9(0.86) (Basic); ROE: (12.50)%; ROCE: -%; D/E: \\u2013; NAV: \\u20b97.73\",\n",
      "        \"Lead Managers & Registrar\": \"Lead Managers: Kotak Mahindra Capital Co. Ltd., JP Morgan India Pvt. Ltd, Goldman Sachs (India) Securities Pvt. Ltd., Axial Capital Pvt. Ltd.; Registrar: MUFG Intime India Pvt.Ltd.\",\n",
      "        \"Company Overview\": \"Edtech company founded 2020, online/offline learning, 3.5M+ students, 8M+ YouTube subscribers, strong hybrid model\",\n",
      "        \"Peer Comparison\": \"There are no listed peers of the Company.\",\n",
      "        \"ipo\": \"PhysicsWallah\",\n",
      "        \"url\": \"https://ipowatch.in/physicswallah-ipo-date-review-price-allotment-details/\",\n",
      "        \"raw_markdown\": \"| IPO                | Price Band           | Issue Size         | Issue Type        | Listing Exchanges | IPO Dates                                   | Market Lot & Amounts                                                                                  | Investor Quota Split         | Anchor Details                                                                                                 | Promoter Holdings (Pre/Post) | Financial Performance (FY23\\u2013FY25)                                                                 | Valuation Ratios (EPS, ROE, ROCE, D/E, NAV) | Lead Managers & Registrar | Company Overview                                                                                                   | Peer Comparison |\\n|--------------------|---------------------|--------------------|-------------------|-------------------|---------------------------------------------|-------------------------------------------------------------------------------------------------------|------------------------------|------------------------------------------------------------------------------------------------------------------|------------------------------|------------------------------------------------------------------------------------------------------------------|---------------------------------------------|--------------------------|-------------------------------------------------------------------------------------------------------------------|------------------|\\n| PhysicsWallah Ltd. | \\u20b9103 to \\u20b9109        | \\u20b93,480 Crores      | Book Built Issue  | BSE, NSE          | Nov 11\\u201313, 2025 (Listing: Nov 18, 2025)    | Min: 137 shares/\\u20b914,933; Max (Retail): 1,781 shares/\\u20b91,94,129; S-HNI: 1,918\\u20139,042 shares/\\u20b92,09,062\\u2013\\u20b99,85,578; B-HNI: 9,179 shares/\\u20b910,00,511 | QIB: 75%, NII: 15%, Retail: 10% | Anchor bidding: Nov 10, 2025; Lock-in: 50% till Dec 14, 2025, 50% till Feb 12, 2026; Anchor list: [PDF], Size: [.] Cr. |                          | FY24: \\u20b92,015.35 Cr revenue, \\u20b91,131.13 Cr loss; FY25: \\u20b93,039.09 Cr revenue, \\u20b9243.26 Cr loss                |                                             |                          | Edtech company founded 2020, online/offline learning, 3.5M+ students, 8M+ YouTube subscribers, strong hybrid model |                  |\",\n",
      "        \"extracted_at\": \"2025-11-09T10:41:52.355186\"\n",
      "    },\n",
      "    \"extraction_history\": [\n",
      "        {\n",
      "            \"extracted_at\": \"2025-11-10T04:51:06.629729\",\n",
      "            \"source_url\": \"https://ipowatch.in/physicswallah-ipo-date-review-price-allotment-details/\",\n",
      "            \"raw_markdown\": \"| Price Band | Issue Size | Issue Type | Listing Exchanges | IPO Dates | Market Lot & Amounts | Investor Quota Split | Anchor Details | Promoter Holdings (Pre/Post) | Financial Performance (FY23\\u2013FY25) | Valuation Ratios (EPS, ROE, ROCE, D/E, NAV) | Lead Managers & Registrar | Company Overview | Peer Comparison | ipo |\\n|------------|------------|------------|-------------------|-----------|----------------------|----------------------|---------------|------------------------------|-----------------------------------|---------------------------------------------|--------------------------|------------------|------------------|-----|\\n| \\u20b9103 to \\u20b9109 | \\u20b93,480 Crores | Book Built Issue | BSE, NSE | Nov 11\\u201313, 2025 (Listing: Nov 18, 2025) | Min: 137 shares/\\u20b914,933; Max (Retail): 1,781 shares/\\u20b91,94,129; S-HNI: 1,918\\u20139,042 shares/\\u20b92,09,062\\u2013\\u20b99,85,578; B-HNI: 9,179 shares/\\u20b910,00,511 | QIB: 75%, NII: 15%, Retail: 10% | Anchor bidding: Nov 10, 2025; Lock-in: 50% till Dec 14, 2025, 50% till Feb 12, 2026; Anchor list: [PDF], Size: [.] Cr. | Pre: 2,60,79,56,938 (81.64%); Post: 2,89,23,60,607 (-%) | FY24: \\u20b92,015.35 Cr revenue, \\u20b91,131.13 Cr loss; FY25: \\u20b93,039.09 Cr revenue, \\u20b9243.26 Cr loss | EPS: \\u20b9(0.86) (Basic); ROE: (12.50)%; ROCE: -%; D/E: \\u2013; NAV: \\u20b97.73 | Lead Managers: Kotak Mahindra Capital Co. Ltd., JP Morgan India Pvt. Ltd, Goldman Sachs (India) Securities Pvt. Ltd., Axial Capital Pvt. Ltd.; Registrar: MUFG Intime India Pvt.Ltd. | Edtech company founded 2020, online/offline learning, 3.5M+ students, 8M+ YouTube subscribers, strong hybrid model | There are no listed peers of the Company. | PhysicsWallah |\",\n",
      "            \"fields_added\": {\n",
      "                \"Promoter Holdings (Pre/Post)\": \"Pre: 2,60,79,56,938 (81.64%); Post: 2,89,23,60,607 (-%)\",\n",
      "                \"Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)\": \"EPS: \\u20b9(0.86) (Basic); ROE: (12.50)%; ROCE: -%; D/E: \\u2013; NAV: \\u20b97.73\",\n",
      "                \"Lead Managers & Registrar\": \"Lead Managers: Kotak Mahindra Capital Co. Ltd., JP Morgan India Pvt. Ltd, Goldman Sachs (India) Securities Pvt. Ltd., Axial Capital Pvt. Ltd.; Registrar: MUFG Intime India Pvt.Ltd.\",\n",
      "                \"Peer Comparison\": \"There are no listed peers of the Company.\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"last_extracted_at\": \"2025-11-10T04:51:06.629729\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from bson import json_util\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "\n",
    "# ---------- CONNECT & FETCH ----------\n",
    "def print_one_ipo_sample():\n",
    "    try:\n",
    "        client = MongoClient(MONGO_URI)\n",
    "        db = client[DB_NAME]\n",
    "        col = db[COL_IPOS]\n",
    "\n",
    "        # Fetch one IPO record\n",
    "        doc = col.find_one()\n",
    "\n",
    "        if not doc:\n",
    "            print(\"‚ö†Ô∏è No records found in collection:\", COL_IPOS)\n",
    "            return\n",
    "\n",
    "        # Pretty-print JSON\n",
    "        print(\"‚úÖ Sample IPO record from MongoDB ('ipo_db.ipos'):\\n\")\n",
    "        print(json.dumps(doc, indent=4, default=json_util.default))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error:\", e)\n",
    "\n",
    "    finally:\n",
    "        client.close()\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "if __name__ == \"__main__\":\n",
    "    print_one_ipo_sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e21ebed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà IPO Portfolio Optimizer for Retail Investors\n",
      "\n",
      "\n",
      "‚úÖ Found 6 eligible IPOs:\n",
      "\n",
      "‚Ä¢ PhysicsWallah | Mainboard | Score: 5.8 | Min Invest: ‚Çπ15000 | Close: 2025-11-13\n",
      "‚Ä¢ Emmvee Photovoltaic Power | Mainboard | Score: 5.1 | Min Invest: ‚Çπ15000 | Close: 2025-11-13\n",
      "‚Ä¢ Workmates Core2Cloud | SME | Score: 4.9 | Min Invest: ‚Çπ244800 | Close: 2025-11-13\n",
      "‚Ä¢ Tenneco Clean Air | Mainboard | Score: 4.7 | Min Invest: ‚Çπ15000 | Close: 2025-11-14\n",
      "‚Ä¢ Shining Tools | SME | Score: 4.9 | Min Invest: ‚Çπ273600 | Close: 2025-11-11\n",
      "‚Ä¢ Shreeji Global FMCG | SME | Score: 4.7 | Min Invest: ‚Çπ250000 | Close: 2025-11-07\n",
      "\n",
      "üìä Final Allocation Plan:\n",
      "  - PhysicsWallah (Mainboard): 6 lot(s), ‚Çπ90000 invested, score 5.8\n",
      "\n",
      "üíµ Total Invested: ‚Çπ90000\n",
      "üí§ Remaining Unused: ‚Çπ10000\n",
      "\n",
      "üì¶ Recommendation saved to MongoDB (collection: ipo_portfolio_recommendations)\n",
      "‚úÖ Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "COL_ANALYSIS = \"ipo_analysis\"\n",
    "COL_RECOMMEND = \"ipo_portfolio_recommendations\"\n",
    "\n",
    "MIN_INVEST_MAINBOARD = 15000  # Default min for mainboard\n",
    "RETAIL_ONLY = True  # Always retail investor\n",
    "\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(str(x).replace(\"‚Çπ\", \"\").replace(\",\", \"\").strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def try_parse_date(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    # Try YYYY-MM-DD\n",
    "    try:\n",
    "        return datetime.strptime(s[:10], \"%Y-%m-%d\").date()\n",
    "    except Exception:\n",
    "        pass\n",
    "    fmts = [\"%d-%b-%Y\", \"%d %b %Y\", \"%d/%m/%Y\", \"%d-%m-%Y\", \"%d %B %Y\"]\n",
    "    for f in fmts:\n",
    "        try:\n",
    "            return datetime.strptime(s, f).date()\n",
    "        except Exception:\n",
    "            continue\n",
    "    try:\n",
    "        import dateutil.parser\n",
    "        return dateutil.parser.parse(s, dayfirst=True).date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_lot_and_min_invest(text):\n",
    "    \"\"\"\n",
    "    Parse lot size and min invest from strings like:\n",
    "    \"Min: 137 shares/‚Çπ14,933; Max (Retail): 1,781 shares/‚Çπ1,94,129\"\n",
    "    Returns (lot_size, min_invest)\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None, None\n",
    "    text = str(text)\n",
    "    # Find first \"Min: ...\" pattern\n",
    "    lot = None\n",
    "    min_inv = None\n",
    "\n",
    "    # Pattern for something like '137 shares/‚Çπ14,933'\n",
    "    m = re.search(r\"(\\d{1,5})\\s*shares?.*?‚Çπ\\s?([\\d,]+)\", text)\n",
    "    if m:\n",
    "        lot = safe_float(m.group(1))\n",
    "        min_inv = safe_float(m.group(2))\n",
    "    else:\n",
    "        # try fallback: just ‚Çπ number\n",
    "        m2 = re.search(r\"‚Çπ\\s?([\\d,]+)\", text)\n",
    "        if m2:\n",
    "            min_inv = safe_float(m2.group(1))\n",
    "\n",
    "    return lot, min_inv\n",
    "\n",
    "\n",
    "def load_ipos_and_scores():\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    ipos = list(client[DB_NAME][COL_IPOS].find({}))\n",
    "    analysis = list(client[DB_NAME][COL_ANALYSIS].find({\"status\": \"scored\"}))\n",
    "    client.close()\n",
    "\n",
    "    ipos_by_name = {d[\"ipo\"]: d for d in ipos if \"ipo\" in d}\n",
    "    scored_by_name = {a[\"ipo\"]: a for a in analysis if \"ipo\" in a}\n",
    "    return ipos_by_name, scored_by_name\n",
    "\n",
    "\n",
    "def parse_issue_price(ipo_doc):\n",
    "    \"\"\"Extract mid price from issue_price dict or string.\"\"\"\n",
    "    v = ipo_doc.get(\"issue_price\") or ipo_doc.get(\"extracted_fields\", {}).get(\"Price Band\")\n",
    "    if isinstance(v, dict):\n",
    "        nums = [v.get(\"avg\") or v.get(\"mid\") or v.get(\"min\")]\n",
    "    else:\n",
    "        nums = re.findall(r\"\\d+\\.?\\d*\", str(v))\n",
    "    nums = [safe_float(n) for n in nums if safe_float(n) is not None]\n",
    "    return sum(nums) / len(nums) if nums else None\n",
    "\n",
    "\n",
    "# ---------- BUILD IPO CANDIDATES ----------\n",
    "def prepare_candidates(ipos_by_name, scored_by_name, hold_until):\n",
    "    candidates = []\n",
    "\n",
    "    for ipo_name, ipo_doc in ipos_by_name.items():\n",
    "        if ipo_name not in scored_by_name:\n",
    "            continue\n",
    "\n",
    "        analysis = scored_by_name[ipo_name]\n",
    "        fields = ipo_doc.get(\"extracted_fields\", {}) or {}\n",
    "        score = analysis.get(\"score\")\n",
    "\n",
    "        # Skip incomplete records\n",
    "        if not score:\n",
    "            continue\n",
    "\n",
    "        # Close date\n",
    "        close_str = (\n",
    "            ipo_doc.get(\"close_date\")\n",
    "            or fields.get(\"Close Date\")\n",
    "            or fields.get(\"IPO Dates\")\n",
    "            or \"\"\n",
    "        )\n",
    "        date_match = re.findall(r\"\\d{4}-\\d{2}-\\d{2}\", close_str)\n",
    "        close_date = try_parse_date(date_match[0]) if date_match else try_parse_date(close_str)\n",
    "        if not close_date or close_date > hold_until:\n",
    "            continue\n",
    "\n",
    "        category = ipo_doc.get(\"category\", \"Mainboard\").lower()\n",
    "        issue_mid = parse_issue_price(ipo_doc)\n",
    "        if not issue_mid:\n",
    "            continue\n",
    "\n",
    "        lot_text = fields.get(\"Market Lot & Amounts\")\n",
    "        lot, min_invest = parse_lot_and_min_invest(lot_text)\n",
    "\n",
    "        # Determine final minimum investment\n",
    "        if \"sme\" in category:\n",
    "            if not min_invest and lot:\n",
    "                min_invest = lot * issue_mid\n",
    "        else:\n",
    "            # For Mainboard, fallback to Rs 15k\n",
    "            if not min_invest:\n",
    "                min_invest = MIN_INVEST_MAINBOARD\n",
    "            # If parsed, ensure at least 15k (retail minimum)\n",
    "            min_invest = max(min_invest, MIN_INVEST_MAINBOARD)\n",
    "\n",
    "        if not min_invest:\n",
    "            continue\n",
    "\n",
    "        candidates.append({\n",
    "            \"ipo\": ipo_name,\n",
    "            \"category\": \"SME\" if \"sme\" in category else \"Mainboard\",\n",
    "            \"score\": score,\n",
    "            \"issue_mid\": issue_mid,\n",
    "            \"lot\": int(lot) if lot else None,\n",
    "            \"min_invest\": float(min_invest),\n",
    "            \"close_date\": close_date,\n",
    "            \"gmp_pct\": analysis.get(\"gmp_pct\"),\n",
    "        })\n",
    "\n",
    "    return candidates\n",
    "\n",
    "\n",
    "# ---------- GREEDY OPTIMIZATION ----------\n",
    "def allocate_budget(candidates, budget):\n",
    "    for c in candidates:\n",
    "        c[\"score_per_inr\"] = c[\"score\"] / c[\"min_invest\"]\n",
    "\n",
    "    candidates = sorted(candidates, key=lambda x: x[\"score_per_inr\"], reverse=True)\n",
    "    allocation = []\n",
    "    remaining = budget\n",
    "\n",
    "    for c in candidates:\n",
    "        if remaining >= c[\"min_invest\"]:\n",
    "            lots = int(remaining // c[\"min_invest\"])\n",
    "            invested = lots * c[\"min_invest\"]\n",
    "            remaining -= invested\n",
    "\n",
    "            allocation.append({\n",
    "                \"ipo\": c[\"ipo\"],\n",
    "                \"score\": c[\"score\"],\n",
    "                \"issue_mid\": c[\"issue_mid\"],\n",
    "                \"lots\": lots,\n",
    "                \"min_invest\": c[\"min_invest\"],\n",
    "                \"invested\": invested,\n",
    "                \"category\": c[\"category\"],\n",
    "            })\n",
    "\n",
    "    return allocation, remaining\n",
    "\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main():\n",
    "    print(\"üìà IPO Portfolio Optimizer for Retail Investors\\n\")\n",
    "\n",
    "    try:\n",
    "        budget = float(input(\"üí∞ Enter your total investment budget (e.g., 100000): \").strip())\n",
    "        hold_date = datetime.strptime(input(\"üìÖ Enter your max hold date (YYYY-MM-DD): \").strip(), \"%Y-%m-%d\").date()\n",
    "    except Exception:\n",
    "        print(\"‚ùå Invalid input.\")\n",
    "        return\n",
    "\n",
    "    ipos_by_name, scored_by_name = load_ipos_and_scores()\n",
    "    candidates = prepare_candidates(ipos_by_name, scored_by_name, hold_date)\n",
    "\n",
    "    if not candidates:\n",
    "        print(\"‚ö†Ô∏è No valid IPOs found for your criteria.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n‚úÖ Found {len(candidates)} eligible IPOs:\\n\")\n",
    "    for c in candidates:\n",
    "        print(f\"‚Ä¢ {c['ipo']} | {c['category']} | Score: {c['score']} | Min Invest: ‚Çπ{int(c['min_invest'])} | Close: {c['close_date']}\")\n",
    "\n",
    "    allocation, leftover = allocate_budget(candidates, budget)\n",
    "\n",
    "    print(\"\\nüìä Final Allocation Plan:\")\n",
    "    total_invested = 0\n",
    "    for a in allocation:\n",
    "        total_invested += a[\"invested\"]\n",
    "        print(f\"  - {a['ipo']} ({a['category']}): {a['lots']} lot(s), ‚Çπ{int(a['invested'])} invested, score {a['score']}\")\n",
    "\n",
    "    print(f\"\\nüíµ Total Invested: ‚Çπ{int(total_invested)}\")\n",
    "    print(f\"üí§ Remaining Unused: ‚Çπ{int(leftover)}\")\n",
    "\n",
    "    # Save to MongoDB\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    rec = {\n",
    "        \"created_at\": datetime.utcnow().isoformat(),\n",
    "        \"budget\": budget,\n",
    "        \"hold_until\": hold_date.isoformat(),\n",
    "        \"allocation\": allocation,\n",
    "        \"total_invested\": total_invested,\n",
    "        \"leftover\": leftover,\n",
    "    }\n",
    "    client[DB_NAME][COL_RECOMMEND].insert_one(rec)\n",
    "    client.close()\n",
    "\n",
    "    print(\"\\nüì¶ Recommendation saved to MongoDB (collection: ipo_portfolio_recommendations)\")\n",
    "    print(\"‚úÖ Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86573a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä IPO Portfolio Optimizer (Enhanced: Fundamentals, Retail Probability & Max Utilization)\n",
      "\n",
      "‚úÖ Found 6 eligible IPOs:\n",
      "\n",
      "‚Ä¢ PhysicsWallah | Mainboard | Score: 6.3 | Min ‚Çπ14933 | Retail 10.0%\n",
      "‚Ä¢ Emmvee Photovoltaic Power | Mainboard | Score: 6.17 | Min ‚Çπ14973 | Retail 10.0%\n",
      "‚Ä¢ Workmates Core2Cloud | SME | Score: 6.13 | Min ‚Çπ244800 | Retail 10.0%\n",
      "‚Ä¢ Tenneco Clean Air | Mainboard | Score: 6.09 | Min ‚Çπ14689 | Retail 10.0%\n",
      "‚Ä¢ Shining Tools | SME | Score: 6.03 | Min ‚Çπ273600 | Retail 10.0%\n",
      "‚Ä¢ Shreeji Global FMCG | SME | Score: 5.91 | Min ‚Çπ250000 | Retail 10.0%\n",
      "\n",
      "üìà Optimized Allocation Plan:\n",
      "  - PhysicsWallah: ‚Çπ194129 (13 lots) | Score: 6.3 | Retail 10.0%\n",
      "  - Tenneco Clean Air: ‚Çπ14689 (1 lots) | Score: 6.09 | Retail 10.0%\n",
      "  - Emmvee Photovoltaic Power: ‚Çπ14973 (1 lots) | Score: 6.17 | Retail 10.0%\n",
      "  - Workmates Core2Cloud: ‚Çπ244800 (1 lots) | Score: 6.13 | Retail 10.0%\n",
      "  - Shreeji Global FMCG: ‚Çπ250000 (1 lots) | Score: 5.91 | Retail 10.0%\n",
      "  - Shining Tools: ‚Çπ273600 (1 lots) | Score: 6.03 | Retail 10.0%\n",
      "\n",
      "üíµ Total Invested: ‚Çπ992191\n",
      "üí§ Remaining: ‚Çπ7809\n",
      "\n",
      "üì¶ Recommendation saved to MongoDB.\n",
      "‚úÖ Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "COL_ANALYSIS = \"ipo_analysis\"\n",
    "COL_RECOMMEND = \"ipo_portfolio_recommendations\"\n",
    "\n",
    "MIN_INVEST_MAINBOARD = 15000\n",
    "\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(str(x).replace(\"‚Çπ\", \"\").replace(\",\", \"\").strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def try_parse_date(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    fmts = [\"%Y-%m-%d\", \"%d-%b-%Y\", \"%d %b %Y\", \"%d/%m/%Y\"]\n",
    "    for f in fmts:\n",
    "        try:\n",
    "            return datetime.strptime(s[:len(f)], f).date()\n",
    "        except Exception:\n",
    "            continue\n",
    "    try:\n",
    "        import dateutil.parser\n",
    "        return dateutil.parser.parse(s, dayfirst=True).date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_lot_and_min_invest(text):\n",
    "    \"\"\"Parse lot size and min invest from strings like 'Min: 137 shares/‚Çπ14,933'\"\"\"\n",
    "    if not text:\n",
    "        return None, None\n",
    "    text = str(text)\n",
    "    lot = None\n",
    "    min_inv = None\n",
    "    m = re.search(r\"(\\d{1,5})\\s*shares?.*?‚Çπ\\s?([\\d,]+)\", text)\n",
    "    if m:\n",
    "        lot = safe_float(m.group(1))\n",
    "        min_inv = safe_float(m.group(2))\n",
    "    else:\n",
    "        m2 = re.search(r\"‚Çπ\\s?([\\d,]+)\", text)\n",
    "        if m2:\n",
    "            min_inv = safe_float(m2.group(1))\n",
    "    return lot, min_inv\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    ipos = list(client[DB_NAME][COL_IPOS].find({}))\n",
    "    analysis = list(client[DB_NAME][COL_ANALYSIS].find({\"status\": \"scored\"}))\n",
    "    client.close()\n",
    "    ipos_by_name = {d[\"ipo\"]: d for d in ipos if \"ipo\" in d}\n",
    "    scored = {a[\"ipo\"]: a for a in analysis if \"ipo\" in a}\n",
    "    return ipos_by_name, scored\n",
    "\n",
    "\n",
    "# ---------- FACTOR EXTRACTORS ----------\n",
    "def extract_retail_quota(text):\n",
    "    \"\"\"Extract Retail % from 'Investor Quota Split: QIB 75%, NII 15%, Retail 10%'\"\"\"\n",
    "    if not text:\n",
    "        return 10\n",
    "    m = re.search(r\"Retail\\s*:?(\\d+\\.?\\d*)%\", text, flags=re.I)\n",
    "    if m:\n",
    "        return safe_float(m.group(1))\n",
    "    return 10.0\n",
    "\n",
    "\n",
    "def extract_fundamental_score(text):\n",
    "    \"\"\"\n",
    "    Crude rule-based scoring based on Financial Performance & Valuation Ratios.\n",
    "    Higher EPS, ROE, lower D/E = better.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 5\n",
    "    score = 5.0\n",
    "    t = str(text).lower()\n",
    "\n",
    "    if \"profit\" in t or \"positive\" in t or \"growth\" in t:\n",
    "        score += 2\n",
    "    if \"loss\" in t or \"negative\" in t:\n",
    "        score -= 2\n",
    "    if \"roe\" in t:\n",
    "        m = re.search(r\"roe[:\\s]*([-\\d.]+)\", t)\n",
    "        if m:\n",
    "            roe = safe_float(m.group(1))\n",
    "            if roe and roe > 10:\n",
    "                score += 1.5\n",
    "    if \"d/e\" in t:\n",
    "        m = re.search(r\"d/e[:\\s]*([-\\d.]+)\", t)\n",
    "        if m:\n",
    "            de = safe_float(m.group(1))\n",
    "            if de and de > 1:\n",
    "                score -= 1\n",
    "    if \"eps\" in t:\n",
    "        m = re.search(r\"eps[:\\s]*[-(‚Çπ]?([\\d.]+)\", t)\n",
    "        if m:\n",
    "            eps = safe_float(m.group(1))\n",
    "            if eps and eps > 0:\n",
    "                score += 1\n",
    "            else:\n",
    "                score -= 1\n",
    "    return max(1, min(score, 10))\n",
    "\n",
    "\n",
    "def extract_sentiment_from_overview(text):\n",
    "    \"\"\"Very crude semantic scoring based on company description.\"\"\"\n",
    "    if not text:\n",
    "        return 5\n",
    "    t = str(text).lower()\n",
    "    good = [\"growing\", \"leader\", \"expanding\", \"innovative\", \"strong\", \"profitable\", \"stable\"]\n",
    "    bad = [\"loss\", \"decline\", \"volatile\", \"uncertain\", \"risky\", \"unprofitable\"]\n",
    "    score = 5\n",
    "    for w in good:\n",
    "        if w in t:\n",
    "            score += 0.5\n",
    "    for w in bad:\n",
    "        if w in t:\n",
    "            score -= 0.5\n",
    "    return max(1, min(score, 10))\n",
    "\n",
    "\n",
    "def compute_composite_score(ipo_doc, analysis):\n",
    "    fields = ipo_doc.get(\"extracted_fields\", {}) or {}\n",
    "    base_score = analysis.get(\"score\", 5)\n",
    "\n",
    "    retail_quota = extract_retail_quota(fields.get(\"Investor Quota Split\"))\n",
    "    fund_score = extract_fundamental_score(\n",
    "        fields.get(\"Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)\")\n",
    "        or fields.get(\"Financial Performance (FY23‚ÄìFY25)\")\n",
    "    )\n",
    "    sentiment_score = extract_sentiment_from_overview(fields.get(\"Company Overview\"))\n",
    "    gmp = safe_float(ipo_doc.get(\"gmp_investorgain\")) or 0\n",
    "    issue = ipo_doc.get(\"issue_price\", {}).get(\"avg\") if isinstance(ipo_doc.get(\"issue_price\"), dict) else None\n",
    "    gmp_strength = (gmp / issue * 100) if (gmp and issue) else 0\n",
    "\n",
    "    # Normalize retail quota to 0‚Äì10 scale\n",
    "    rq_score = min(retail_quota / 10, 1) * 10\n",
    "\n",
    "    # Weighted composite\n",
    "    composite = (\n",
    "        0.30 * base_score +\n",
    "        0.25 * rq_score +\n",
    "        0.20 * fund_score +\n",
    "        0.15 * (gmp_strength / 10) +\n",
    "        0.10 * sentiment_score\n",
    "    )\n",
    "    return round(min(composite, 10), 2)\n",
    "\n",
    "\n",
    "# ---------- PREPARE CANDIDATES ----------\n",
    "def prepare_candidates(ipos_by_name, scored_by_name, hold_until):\n",
    "    candidates = []\n",
    "\n",
    "    for name, ipo_doc in ipos_by_name.items():\n",
    "        if name not in scored_by_name:\n",
    "            continue\n",
    "        analysis = scored_by_name[name]\n",
    "        fields = ipo_doc.get(\"extracted_fields\", {}) or {}\n",
    "\n",
    "        close_str = ipo_doc.get(\"close_date\") or fields.get(\"Close Date\") or fields.get(\"IPO Dates\")\n",
    "        close_date = try_parse_date(close_str)\n",
    "        if not close_date or close_date > hold_until:\n",
    "            continue\n",
    "\n",
    "        category = ipo_doc.get(\"category\", \"Mainboard\").lower()\n",
    "        lot, min_invest = parse_lot_and_min_invest(fields.get(\"Market Lot & Amounts\"))\n",
    "        issue_mid = ipo_doc.get(\"issue_price\", {}).get(\"avg\") if isinstance(ipo_doc.get(\"issue_price\"), dict) else None\n",
    "        if not issue_mid:\n",
    "            continue\n",
    "\n",
    "        if not min_invest:\n",
    "            min_invest = MIN_INVEST_MAINBOARD\n",
    "\n",
    "        composite_score = compute_composite_score(ipo_doc, analysis)\n",
    "\n",
    "        candidates.append({\n",
    "            \"ipo\": name,\n",
    "            \"category\": \"SME\" if \"sme\" in category else \"Mainboard\",\n",
    "            \"score\": composite_score,\n",
    "            \"issue_mid\": issue_mid,\n",
    "            \"lot\": lot,\n",
    "            \"min_invest\": float(min_invest),\n",
    "            \"close_date\": close_date,\n",
    "            \"retail_quota\": extract_retail_quota(fields.get(\"Investor Quota Split\")),\n",
    "        })\n",
    "\n",
    "    return candidates\n",
    "\n",
    "\n",
    "# ---------- ALLOCATION (NEW MAX UTILIZATION VERSION) ----------\n",
    "def allocate_budget(candidates, budget):\n",
    "    for c in candidates:\n",
    "        c[\"score_per_inr\"] = c[\"score\"] / c[\"min_invest\"]\n",
    "    candidates = sorted(candidates, key=lambda x: x[\"score_per_inr\"], reverse=True)\n",
    "\n",
    "    allocation = []\n",
    "    remaining = budget\n",
    "\n",
    "    # Pass 1 ‚Äî Diversify: give one minimum lot to each IPO if possible\n",
    "    for c in candidates:\n",
    "        if remaining >= c[\"min_invest\"]:\n",
    "            allocation.append({\n",
    "                \"ipo\": c[\"ipo\"],\n",
    "                \"category\": c[\"category\"],\n",
    "                \"score\": c[\"score\"],\n",
    "                \"lots\": 1,\n",
    "                \"invested\": c[\"min_invest\"],\n",
    "                \"min_invest\": c[\"min_invest\"],\n",
    "                \"retail_quota\": c[\"retail_quota\"]\n",
    "            })\n",
    "            remaining -= c[\"min_invest\"]\n",
    "\n",
    "    # Pass 2 ‚Äî Maximize: add more lots where score_per_inr is highest\n",
    "    while True:\n",
    "        affordable = [c for c in candidates if c[\"min_invest\"] <= remaining]\n",
    "        if not affordable:\n",
    "            break\n",
    "\n",
    "        best = max(affordable, key=lambda x: x[\"score_per_inr\"])\n",
    "        for alloc in allocation:\n",
    "            if alloc[\"ipo\"] == best[\"ipo\"]:\n",
    "                alloc[\"lots\"] += 1\n",
    "                alloc[\"invested\"] += best[\"min_invest\"]\n",
    "                remaining -= best[\"min_invest\"]\n",
    "                break\n",
    "        else:\n",
    "            allocation.append({\n",
    "                \"ipo\": best[\"ipo\"],\n",
    "                \"category\": best[\"category\"],\n",
    "                \"score\": best[\"score\"],\n",
    "                \"lots\": 1,\n",
    "                \"invested\": best[\"min_invest\"],\n",
    "                \"min_invest\": best[\"min_invest\"],\n",
    "                \"retail_quota\": best[\"retail_quota\"]\n",
    "            })\n",
    "            remaining -= best[\"min_invest\"]\n",
    "\n",
    "        if remaining < min(c[\"min_invest\"] for c in candidates):\n",
    "            break\n",
    "\n",
    "    # Smart rebalance if large leftover (>10% budget)\n",
    "    if remaining > 0.1 * budget and allocation:\n",
    "        lowest = min(allocation, key=lambda x: x[\"score\"], default=None)\n",
    "        if lowest:\n",
    "            removed_amt = lowest[\"invested\"]\n",
    "            allocation.remove(lowest)\n",
    "            remaining += removed_amt\n",
    "            affordable = [c for c in candidates if c[\"min_invest\"] <= remaining]\n",
    "            for best in sorted(affordable, key=lambda x: x[\"score_per_inr\"], reverse=True):\n",
    "                if remaining < best[\"min_invest\"]:\n",
    "                    continue\n",
    "                allocation.append({\n",
    "                    \"ipo\": best[\"ipo\"],\n",
    "                    \"category\": best[\"category\"],\n",
    "                    \"score\": best[\"score\"],\n",
    "                    \"lots\": 1,\n",
    "                    \"invested\": best[\"min_invest\"],\n",
    "                    \"min_invest\": best[\"min_invest\"],\n",
    "                    \"retail_quota\": best[\"retail_quota\"]\n",
    "                })\n",
    "                remaining -= best[\"min_invest\"]\n",
    "                if remaining < min(c[\"min_invest\"] for c in candidates):\n",
    "                    break\n",
    "\n",
    "    return allocation, remaining\n",
    "\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main():\n",
    "    print(\"üìä IPO Portfolio Optimizer (Enhanced: Fundamentals, Retail Probability & Max Utilization)\\n\")\n",
    "\n",
    "    try:\n",
    "        budget = float(input(\"üí∞ Enter your total investment budget (e.g., 100000): \").strip())\n",
    "        hold_until = datetime.strptime(input(\"üìÖ Enter your max hold date (YYYY-MM-DD): \").strip(), \"%Y-%m-%d\").date()\n",
    "    except Exception:\n",
    "        print(\"‚ùå Invalid input.\")\n",
    "        return\n",
    "\n",
    "    ipos_by_name, scored_by_name = load_data()\n",
    "    candidates = prepare_candidates(ipos_by_name, scored_by_name, hold_until)\n",
    "    if not candidates:\n",
    "        print(\"‚ö†Ô∏è No valid IPOs found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"‚úÖ Found {len(candidates)} eligible IPOs:\\n\")\n",
    "    for c in candidates:\n",
    "        print(f\"‚Ä¢ {c['ipo']} | {c['category']} | Score: {c['score']} | Min ‚Çπ{int(c['min_invest'])} | Retail {c['retail_quota']}%\")\n",
    "\n",
    "    allocation, leftover = allocate_budget(candidates, budget)\n",
    "\n",
    "    print(\"\\nüìà Optimized Allocation Plan:\")\n",
    "    total_invested = 0\n",
    "    for a in allocation:\n",
    "        total_invested += a[\"invested\"]\n",
    "        print(f\"  - {a['ipo']}: ‚Çπ{int(a['invested'])} ({a['lots']} lots) | Score: {a['score']} | Retail {a['retail_quota']}%\")\n",
    "\n",
    "    print(f\"\\nüíµ Total Invested: ‚Çπ{int(total_invested)}\")\n",
    "    print(f\"üí§ Remaining: ‚Çπ{int(leftover)}\")\n",
    "\n",
    "    # Save recommendation\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    client[DB_NAME][COL_RECOMMEND].insert_one({\n",
    "        \"created_at\": datetime.utcnow().isoformat(),\n",
    "        \"budget\": budget,\n",
    "        \"hold_until\": hold_until.isoformat(),\n",
    "        \"allocation\": allocation,\n",
    "        \"total_invested\": total_invested,\n",
    "        \"leftover\": leftover\n",
    "    })\n",
    "    client.close()\n",
    "\n",
    "    print(\"\\nüì¶ Recommendation saved to MongoDB.\")\n",
    "    print(\"‚úÖ Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b865c9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPO Allocator ‚Äî final (no leftovers unless all poor)\n",
      "\n",
      "Eligible IPOs (score >=5 and within hold date):\n",
      " ‚Ä¢ PhysicsWallah: composite=6.3, min_invest=‚Çπ14933, retail=10.0% , max_lots=3\n",
      " ‚Ä¢ Emmvee Photovoltaic Power: composite=6.171, min_invest=‚Çπ14973, retail=10.0% , max_lots=3\n",
      " ‚Ä¢ Workmates Core2Cloud: composite=6.135, min_invest=‚Çπ244800, retail=10.0% , max_lots=3\n",
      " ‚Ä¢ Tenneco Clean Air: composite=6.089, min_invest=‚Çπ14689, retail=10.0% , max_lots=3\n",
      " ‚Ä¢ Shining Tools: composite=6.028, min_invest=‚Çπ273600, retail=10.0% , max_lots=3\n",
      " ‚Ä¢ Shreeji Global FMCG: composite=5.91, min_invest=‚Çπ250000, retail=10.0% , max_lots=3\n",
      "\n",
      "--- Allocation ---\n",
      "PhysicsWallah: lots=31, invested=‚Çπ462923, min_unit=‚Çπ14933, score=6.3\n",
      "Tenneco Clean Air: lots=1, invested=‚Çπ14689, min_unit=‚Çπ14689, score=6.09\n",
      "Emmvee Photovoltaic Power: lots=1, invested=‚Çπ14973, min_unit=‚Çπ14973, score=6.17\n",
      "Workmates Core2Cloud: lots=1, invested=‚Çπ244800, min_unit=‚Çπ244800, score=6.13\n",
      "Shreeji Global FMCG: lots=1, invested=‚Çπ250000, min_unit=‚Çπ250000, score=5.91\n",
      "\n",
      "Total invested: ‚Çπ987385\n",
      "Remaining (uninvested): ‚Çπ12615\n",
      "\n",
      "--- Explainability ---\n",
      "\n",
      "PhysicsWallah:\n",
      "  Reasons to invest more:\n",
      "   - Above-average composite score.\n",
      "   - GMP indicates listing strength (~34.0%).\n",
      "  Reasons to be cautious / invest less:\n",
      "   - Retail quota is low (10.0%) ‚Äî allotment chance may be lower.\n",
      "\n",
      "Tenneco Clean Air:\n",
      "  Reasons to invest more:\n",
      "   - Above-average composite score.\n",
      "   - Fundamentals look decent.\n",
      "   - GMP indicates listing strength (~11.9%).\n",
      "  Reasons to be cautious / invest less:\n",
      "   - Retail quota is low (10.0%) ‚Äî allotment chance may be lower.\n",
      "\n",
      "Emmvee Photovoltaic Power:\n",
      "  Reasons to invest more:\n",
      "   - Above-average composite score.\n",
      "   - Fundamentals look decent.\n",
      "   - GMP indicates listing strength (~19.4%).\n",
      "  Reasons to be cautious / invest less:\n",
      "   - Retail quota is low (10.0%) ‚Äî allotment chance may be lower.\n",
      "\n",
      "Workmates Core2Cloud:\n",
      "  Reasons to invest more:\n",
      "   - Above-average composite score.\n",
      "   - Fundamentals look decent.\n",
      "   - GMP indicates listing strength (~11.0%).\n",
      "  Reasons to be cautious / invest less:\n",
      "   - Retail quota is low (10.0%) ‚Äî allotment chance may be lower.\n",
      "   - SME IPO: higher risk, less liquidity ‚Äî keep small exposure.\n",
      "\n",
      "Shreeji Global FMCG:\n",
      "  Reasons to invest more:\n",
      "   - Moderate composite score.\n",
      "   - Fundamentals look decent.\n",
      "  Reasons to be cautious / invest less:\n",
      "   - Retail quota is low (10.0%) ‚Äî allotment chance may be lower.\n",
      "   - SME IPO: higher risk, less liquidity ‚Äî keep small exposure.\n"
     ]
    },
    {
     "ename": "InvalidDocument",
     "evalue": "cannot encode object: datetime.date(2025, 11, 13), of type: <class 'datetime.date'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidDocument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 453\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 447\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    437\u001b[0m client \u001b[38;5;241m=\u001b[39m MongoClient(MONGO_URI)\n\u001b[0;32m    438\u001b[0m rec \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m\"\u001b[39m: datetime\u001b[38;5;241m.\u001b[39mutcnow()\u001b[38;5;241m.\u001b[39misoformat(),\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbudget\u001b[39m\u001b[38;5;124m\"\u001b[39m: budget,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleftover\u001b[39m\u001b[38;5;124m\"\u001b[39m: remaining\n\u001b[0;32m    446\u001b[0m }\n\u001b[1;32m--> 447\u001b[0m \u001b[43mclient\u001b[49m\u001b[43m[\u001b[49m\u001b[43mDB_NAME\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCOL_RECOMMEND\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m client\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSaved recommendation to MongoDB (collection:\u001b[39m\u001b[38;5;124m\"\u001b[39m, COL_RECOMMEND, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\collection.py:669\u001b[0m, in \u001b[0;36mCollection.insert_one\u001b[1;34m(self, document, bypass_document_validation, session, comment)\u001b[0m\n\u001b[0;32m    665\u001b[0m     document[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ObjectId()  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m    667\u001b[0m write_concern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_concern_for(session)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m InsertOneResult(\n\u001b[1;32m--> 669\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_insert_one\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mordered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_concern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_concern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbypass_doc_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbypass_document_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    678\u001b[0m     write_concern\u001b[38;5;241m.\u001b[39macknowledged,\n\u001b[0;32m    679\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\collection.py:609\u001b[0m, in \u001b[0;36mCollection._insert_one\u001b[1;34m(self, doc, ordered, write_concern, op_id, bypass_doc_val, session, comment)\u001b[0m\n\u001b[0;32m    597\u001b[0m     result \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcommand(\n\u001b[0;32m    598\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__database\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    599\u001b[0m         command,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m         retryable_write\u001b[38;5;241m=\u001b[39mretryable_write,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    607\u001b[0m     _check_write_command_response(result)\n\u001b[1;32m--> 609\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__database\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retryable_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43macknowledged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_insert_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc, RawBSONDocument):\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\mongo_client.py:1523\u001b[0m, in \u001b[0;36mMongoClient._retryable_write\u001b[1;34m(self, retryable, func, session, bulk)\u001b[0m\n\u001b[0;32m   1509\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute an operation with consecutive retries if possible\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \n\u001b[0;32m   1511\u001b[0m \u001b[38;5;124;03mReturns func()'s return value on success. On error retries the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1520\u001b[0m \u001b[38;5;124;03m  - `bulk`: bulk abstraction to execute operations in bulk, defaults to None\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tmp_session(session) \u001b[38;5;28;01mas\u001b[39;00m s:\n\u001b[1;32m-> 1523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_with_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretryable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbulk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\mongo_client.py:1421\u001b[0m, in \u001b[0;36mMongoClient._retry_with_session\u001b[1;34m(self, retryable, func, session, bulk)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;66;03m# Ensure that the options supports retry_writes and there is a valid session not in\u001b[39;00m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;66;03m# transaction, otherwise, we will not support retry behavior for this txn.\u001b[39;00m\n\u001b[0;32m   1418\u001b[0m retryable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\n\u001b[0;32m   1419\u001b[0m     retryable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mretry_writes \u001b[38;5;129;01mand\u001b[39;00m session \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m session\u001b[38;5;241m.\u001b[39min_transaction\n\u001b[0;32m   1420\u001b[0m )\n\u001b[1;32m-> 1421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbulk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbulk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretryable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretryable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\_csot.py:107\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\mongo_client.py:1462\u001b[0m, in \u001b[0;36mMongoClient._retry_internal\u001b[1;34m(self, func, session, bulk, is_read, address, read_pref, retryable)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;129m@_csot\u001b[39m\u001b[38;5;241m.\u001b[39mapply\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retry_internal\u001b[39m(\n\u001b[0;32m   1430\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1437\u001b[0m     retryable: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1438\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Internal retryable helper for all client transactions.\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m \n\u001b[0;32m   1441\u001b[0m \u001b[38;5;124;03m    :Parameters:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[38;5;124;03m      Output of the calling func()\u001b[39;00m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ClientConnectionRetryable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmongo_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbulk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbulk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_read\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_read\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_pref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_pref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretryable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretryable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 1462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\mongo_client.py:2315\u001b[0m, in \u001b[0;36m_ClientConnectionRetryable.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_last_error(check_csot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_read \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2316\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ServerSelectionTimeoutError:\n\u001b[0;32m   2317\u001b[0m     \u001b[38;5;66;03m# The application may think the write was never attempted\u001b[39;00m\n\u001b[0;32m   2318\u001b[0m     \u001b[38;5;66;03m# if we raise ServerSelectionTimeoutError on the retry\u001b[39;00m\n\u001b[0;32m   2319\u001b[0m     \u001b[38;5;66;03m# attempt. Raise the original exception instead.\u001b[39;00m\n\u001b[0;32m   2320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_last_error()\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\mongo_client.py:2423\u001b[0m, in \u001b[0;36m_ClientConnectionRetryable._write\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2421\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_last_error()\n\u001b[0;32m   2422\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retryable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 2423\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retryable\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PyMongoError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   2425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retryable:\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\collection.py:597\u001b[0m, in \u001b[0;36mCollection._insert_one.<locals>._insert_command\u001b[1;34m(session, conn, retryable_write)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bypass_doc_val:\n\u001b[0;32m    595\u001b[0m     command[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbypassDocumentValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__database\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_concern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_concern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcodec_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__write_response_codec_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__database\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretryable_write\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretryable_write\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m _check_write_command_response(result)\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\helpers.py:322\u001b[0m, in \u001b[0;36m_handle_reauth.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymongo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Connection\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailure \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m no_reauth:\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\pool.py:996\u001b[0m, in \u001b[0;36mConnection.command\u001b[1;34m(self, dbname, spec, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;66;03m# Catch socket.error, KeyboardInterrupt, etc. and close ourselves.\u001b[39;00m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m--> 996\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_connection_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\pool.py:968\u001b[0m, in \u001b[0;36mConnection.command\u001b[1;34m(self, dbname, spec, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_not_writable(unacknowledged)\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcommand\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_mongos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_preference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcodec_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallowable_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlisteners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_bson_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_concern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_write_concern_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_write_concern_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression_ctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_op_msg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop_msg_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m        \u001b[49m\u001b[43munacknowledged\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munacknowledged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexhaust_allowed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexhaust_allowed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_concern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_concern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (OperationFailure, NotPrimaryError):\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\network.py:151\u001b[0m, in \u001b[0;36mcommand\u001b[1;34m(conn, dbname, spec, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed, write_concern)\u001b[0m\n\u001b[0;32m    149\u001b[0m flags \u001b[38;5;241m=\u001b[39m _OpMsg\u001b[38;5;241m.\u001b[39mMORE_TO_COME \u001b[38;5;28;01mif\u001b[39;00m unacknowledged \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    150\u001b[0m flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m _OpMsg\u001b[38;5;241m.\u001b[39mEXHAUST_ALLOWED \u001b[38;5;28;01mif\u001b[39;00m exhaust_allowed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 151\u001b[0m request_id, msg, size, max_doc_size \u001b[38;5;241m=\u001b[39m \u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op_msg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_preference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodec_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression_ctx\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# If this is an unacknowledged write then make sure the encoded doc(s)\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# are small enough, otherwise rely on the server to return an error.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unacknowledged \u001b[38;5;129;01mand\u001b[39;00m max_bson_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m max_doc_size \u001b[38;5;241m>\u001b[39m max_bson_size:\n",
      "File \u001b[1;32mc:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\message.py:762\u001b[0m, in \u001b[0;36m_op_msg\u001b[1;34m(flags, command, dbname, read_preference, opts, ctx)\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ctx:\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _op_msg_compressed(flags, command, identifier, docs, opts, ctx)\n\u001b[1;32m--> 762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_op_msg_uncompressed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;66;03m# Add the field back to the command.\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m identifier:\n",
      "\u001b[1;31mInvalidDocument\u001b[0m: cannot encode object: datetime.date(2025, 11, 13), of type: <class 'datetime.date'>"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "IPO allocator (final):\n",
    "\n",
    "- Filters: score >= 5; close_date <= user hold date.\n",
    "- Attempts to use all budget (unless no eligible IPOs).\n",
    "- Primary solver: pulp MILP (integer lots).\n",
    "- Fallback solver: greedy + repair to fully utilize budget.\n",
    "- Explainability: reasons for more/less allocation per IPO.\n",
    "- Persists recommendation to MongoDB.\n",
    "\n",
    "Requires: pymongo. Optional: pulp (recommended).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "COL_ANALYSIS = \"ipo_analysis\"\n",
    "COL_RECOMMEND = \"ipo_portfolio_recommendations\"\n",
    "\n",
    "MIN_INVEST_MAINBOARD = 15000\n",
    "# max lots per IPO to avoid over-concentration (retail behaviour) ‚Äî tweakable\n",
    "DEFAULT_MAX_LOTS_PER_IPO = 3\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(str(x).replace(\"‚Çπ\", \"\").replace(\",\", \"\").strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def try_parse_date(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    fmts = [\"%Y-%m-%d\", \"%d-%b-%Y\", \"%d %b %Y\", \"%d/%m/%Y\"]\n",
    "    for f in fmts:\n",
    "        try:\n",
    "            return datetime.strptime(s[:len(f)], f).date()\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        import dateutil.parser\n",
    "        return dateutil.parser.parse(s, dayfirst=True).date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def parse_lot_and_min_invest(text):\n",
    "    \"\"\"Return (lot, min_invest) from Market Lot & Amounts string.\"\"\"\n",
    "    if not text:\n",
    "        return None, None\n",
    "    s = str(text)\n",
    "    # look for 'Min: 137 shares/‚Çπ14,933' or '137 shares/‚Çπ14,933'\n",
    "    m = re.search(r\"(?:Min[:\\s]*)?(\\d{1,6})\\s*shares?.*?‚Çπ\\s?([\\d,]+)\", s, flags=re.I)\n",
    "    if m:\n",
    "        lot = safe_float(m.group(1))\n",
    "        min_inv = safe_float(m.group(2))\n",
    "        return int(lot) if lot else None, float(min_inv) if min_inv else None\n",
    "    # fallback: find first '‚Çπ' number\n",
    "    m2 = re.search(r\"‚Çπ\\s?([\\d,]+)\", s)\n",
    "    if m2:\n",
    "        return None, float(safe_float(m2.group(1)))\n",
    "    return None, None\n",
    "\n",
    "def parse_issue_mid(ipo_doc):\n",
    "    v = ipo_doc.get(\"issue_price\") or ipo_doc.get(\"extracted_fields\", {}).get(\"Price Band\")\n",
    "    if isinstance(v, dict):\n",
    "        mid = v.get(\"avg\") or v.get(\"mid\") or v.get(\"min\")\n",
    "        return safe_float(mid)\n",
    "    if not v:\n",
    "        return None\n",
    "    nums = re.findall(r\"\\d+\\.?\\d*\", str(v))\n",
    "    nums = [safe_float(n) for n in nums if safe_float(n) is not None]\n",
    "    return sum(nums)/len(nums) if nums else None\n",
    "\n",
    "def load_data():\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    ipos = list(client[DB_NAME][COL_IPOS].find({}))\n",
    "    analysis = list(client[DB_NAME][COL_ANALYSIS].find({}))\n",
    "    client.close()\n",
    "    ipos_by_name = {d[\"ipo\"]: d for d in ipos if \"ipo\" in d}\n",
    "    scored = {a[\"ipo\"]: a for a in analysis if \"ipo\" in a}\n",
    "    return ipos_by_name, scored\n",
    "\n",
    "# composite score extractor reused from previous pipeline:\n",
    "def extract_retail_quota(text):\n",
    "    if not text:\n",
    "        return 10.0\n",
    "    m = re.search(r\"Retail\\s*:?(\\d+\\.?\\d*)%\", str(text), flags=re.I)\n",
    "    if m:\n",
    "        return safe_float(m.group(1))\n",
    "    return 10.0\n",
    "\n",
    "def extract_fundamental_score(text):\n",
    "    if not text:\n",
    "        return 5.0\n",
    "    score = 5.0\n",
    "    t = str(text).lower()\n",
    "    if \"profit\" in t or \"positive\" in t or \"growth\" in t:\n",
    "        score += 2\n",
    "    if \"loss\" in t or \"negative\" in t:\n",
    "        score -= 2\n",
    "    if \"roe\" in t:\n",
    "        m = re.search(r\"roe[:\\s]*([-\\d.]+)\", t)\n",
    "        if m:\n",
    "            roe = safe_float(m.group(1))\n",
    "            if roe and roe > 10:\n",
    "                score += 1.5\n",
    "    if \"d/e\" in t:\n",
    "        m = re.search(r\"d/e[:\\s]*([-\\d.]+)\", t)\n",
    "        if m:\n",
    "            de = safe_float(m.group(1))\n",
    "            if de and de > 1:\n",
    "                score -= 1\n",
    "    if \"eps\" in t:\n",
    "        m = re.search(r\"eps[:\\s]*[-(‚Çπ]?([\\d.]+)\", t)\n",
    "        if m:\n",
    "            eps = safe_float(m.group(1))\n",
    "            if eps and eps > 0:\n",
    "                score += 1\n",
    "            else:\n",
    "                score -= 1\n",
    "    return max(1, min(score, 10))\n",
    "\n",
    "def extract_sentiment(text):\n",
    "    if not text:\n",
    "        return 5.0\n",
    "    t = str(text).lower()\n",
    "    score = 5.0\n",
    "    good = [\"growing\", \"leader\", \"expanding\", \"innovative\", \"strong\", \"profitable\", \"stable\"]\n",
    "    bad = [\"loss\", \"decline\", \"volatile\", \"uncertain\", \"risky\", \"unprofitable\"]\n",
    "    for w in good:\n",
    "        if w in t:\n",
    "            score += 0.5\n",
    "    for w in bad:\n",
    "        if w in t:\n",
    "            score -= 0.5\n",
    "    return max(1, min(score, 10))\n",
    "\n",
    "def compute_composite(ipo_doc, analysis):\n",
    "    fields = ipo_doc.get(\"extracted_fields\", {}) or {}\n",
    "    base = analysis.get(\"score\", 5)\n",
    "    retail = extract_retail_quota(fields.get(\"Investor Quota Split\"))\n",
    "    fund = extract_fundamental_score(fields.get(\"Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)\") or fields.get(\"Financial Performance (FY23‚ÄìFY25)\"))\n",
    "    sent = extract_sentiment(fields.get(\"Company Overview\"))\n",
    "    gmp = safe_float(ipo_doc.get(\"gmp_investorgain\")) or 0\n",
    "    issue = parse_issue_mid(ipo_doc)\n",
    "    gmp_strength = (gmp / issue * 100) if (gmp and issue) else 0\n",
    "    rq_score = min(retail / 10, 1) * 10\n",
    "    composite = 0.30*base + 0.25*rq_score + 0.20*fund + 0.15*(gmp_strength/10) + 0.10*sent\n",
    "    return round(min(composite, 10), 3), retail, fund, sent, gmp_strength\n",
    "\n",
    "# ---------- ALLOCATION CORE ----------\n",
    "def build_candidates(ipos_by_name, scored, hold_date):\n",
    "    cands = []\n",
    "    for name, ipo in ipos_by_name.items():\n",
    "        if name not in scored:\n",
    "            continue\n",
    "        analysis = scored[name]\n",
    "        if analysis.get(\"status\") != \"scored\" and \"score\" not in analysis:\n",
    "            # skip not scored\n",
    "            continue\n",
    "        fields = ipo.get(\"extracted_fields\", {}) or {}\n",
    "        # close date parse\n",
    "        close = ipo.get(\"close_date\") or fields.get(\"IPO Dates\") or fields.get(\"Close Date\") or ipo.get(\"extracted_fields\", {}).get(\"IPO Dates\")\n",
    "        close_date = None\n",
    "        if close:\n",
    "            # try to extract year-month-day if present\n",
    "            m = re.search(r\"\\d{4}-\\d{2}-\\d{2}\", str(close))\n",
    "            if m:\n",
    "                close_date = try_parse_date(m.group(0))\n",
    "            else:\n",
    "                close_date = try_parse_date(close)\n",
    "        if not close_date:\n",
    "            # can't use if no reliable close date\n",
    "            continue\n",
    "        if close_date > hold_date:\n",
    "            # user can't hold that long\n",
    "            continue\n",
    "\n",
    "        issue_mid = parse_issue_mid(ipo)\n",
    "        if not issue_mid:\n",
    "            continue\n",
    "\n",
    "        lot, min_inv = parse_lot_and_min_invest(fields.get(\"Market Lot & Amounts\"))\n",
    "        if not min_inv:\n",
    "            # fallback for mainboard: lot*issue_mid preferred, otherwise MIN_INVEST_MAINBOARD\n",
    "            if lot:\n",
    "                min_inv = lot * issue_mid\n",
    "            else:\n",
    "                min_inv = MIN_INVEST_MAINBOARD\n",
    "\n",
    "        composite_score, retail_quota, fund_score, sent_score, gmp_strength = compute_composite(ipo, analysis)\n",
    "        # filter by composite >= 5\n",
    "        if composite_score < 5:\n",
    "            continue\n",
    "\n",
    "        # caps for lots (avoid insane concentration)\n",
    "        max_lots = int(max(1, min(DEFAULT_MAX_LOTS_PER_IPO, (1000000000 if min_inv==0 else 10**9))))  # will be tightened later by budget\n",
    "        # final candidate\n",
    "        cands.append({\n",
    "            \"ipo\": name,\n",
    "            \"category\": ipo.get(\"category\", \"Mainboard\"),\n",
    "            \"composite\": composite_score,\n",
    "            \"retail_quota\": retail_quota,\n",
    "            \"fund_score\": fund_score,\n",
    "            \"sentiment\": sent_score,\n",
    "            \"gmp_strength\": gmp_strength,\n",
    "            \"issue_mid\": issue_mid,\n",
    "            \"lot\": int(lot) if lot else None,\n",
    "            \"min_invest\": float(min_inv),\n",
    "            \"close_date\": close_date,\n",
    "            \"analysis\": analysis\n",
    "        })\n",
    "    return cands\n",
    "\n",
    "def solve_with_pulp(candidates, budget):\n",
    "    try:\n",
    "        import pulp\n",
    "    except Exception:\n",
    "        return None  # fallback if pulp not installed\n",
    "\n",
    "    prob = pulp.LpProblem(\"IPO_Allocation\", pulp.LpMaximize)\n",
    "\n",
    "    lot_vars = {}\n",
    "    for c in candidates:\n",
    "        max_possible = int(max(1, budget // c[\"min_invest\"]))\n",
    "        cap = min(DEFAULT_MAX_LOTS_PER_IPO, max_possible)\n",
    "\n",
    "        # fix: build safe variable name outside f-string\n",
    "        safe_name = re.sub(r\"\\W+\", \"_\", c[\"ipo\"])\n",
    "        var = pulp.LpVariable(f\"lots_{safe_name}\", lowBound=0, upBound=cap, cat=\"Integer\")\n",
    "        lot_vars[c[\"ipo\"]] = var\n",
    "\n",
    "    # objective: maximize weighted total score\n",
    "    prob += pulp.lpSum([c[\"composite\"] * lot_vars[c[\"ipo\"]] for c in candidates])\n",
    "\n",
    "    # budget constraint\n",
    "    prob += pulp.lpSum([c[\"min_invest\"] * lot_vars[c[\"ipo\"]] for c in candidates]) <= budget\n",
    "\n",
    "    # solve using CBC solver\n",
    "    prob.solve(pulp.PULP_CBC_CMD(msg=False, timeLimit=10))\n",
    "\n",
    "    # collect solution\n",
    "    allocation = []\n",
    "    total_invested = 0.0\n",
    "    for c in candidates:\n",
    "        v = int(pulp.value(lot_vars[c[\"ipo\"]]) or 0)\n",
    "        if v > 0:\n",
    "            invested = v * c[\"min_invest\"]\n",
    "            allocation.append({\n",
    "                \"ipo\": c[\"ipo\"],\n",
    "                \"lots\": v,\n",
    "                \"invested\": invested,\n",
    "                \"min_invest\": c[\"min_invest\"],\n",
    "                \"composite\": c[\"composite\"],\n",
    "                \"retail_quota\": c[\"retail_quota\"],\n",
    "                \"reason_fields\": c\n",
    "            })\n",
    "            total_invested += invested\n",
    "\n",
    "    remaining = budget - total_invested\n",
    "    return allocation, remaining\n",
    "\n",
    "\n",
    "# fallback greedy + repair that fully uses budget\n",
    "def greedy_fill_full(candidates, budget):\n",
    "    # sort by composite per rupee descending; start by giving 1 lot to top N until can't\n",
    "    cand_sorted = sorted(candidates, key=lambda x: x[\"composite\"]/x[\"min_invest\"], reverse=True)\n",
    "    allocation = []\n",
    "    remaining = budget\n",
    "\n",
    "    # initial pass: try one lot each to top candidates while possible\n",
    "    for c in cand_sorted:\n",
    "        if remaining >= c[\"min_invest\"]:\n",
    "            allocation.append({\"ipo\": c[\"ipo\"], \"lots\": 1, \"min_invest\": c[\"min_invest\"], \"invested\": c[\"min_invest\"], \"composite\": c[\"composite\"], \"retail_quota\": c[\"retail_quota\"], \"reason_fields\": c})\n",
    "            remaining -= c[\"min_invest\"]\n",
    "\n",
    "    # second pass: attempt to add lots to highest marginal benefit\n",
    "    while True:\n",
    "        affordable = [c for c in cand_sorted if c[\"min_invest\"] <= remaining]\n",
    "        if not affordable:\n",
    "            break\n",
    "        best = max(affordable, key=lambda x: x[\"composite\"]/x[\"min_invest\"])\n",
    "        # find alloc entry\n",
    "        found = next((a for a in allocation if a[\"ipo\"] == best[\"ipo\"]), None)\n",
    "        if found:\n",
    "            found[\"lots\"] += 1\n",
    "            found[\"invested\"] += best[\"min_invest\"]\n",
    "        else:\n",
    "            allocation.append({\"ipo\": best[\"ipo\"], \"lots\": 1, \"min_invest\": best[\"min_invest\"], \"invested\": best[\"min_invest\"], \"composite\": best[\"composite\"], \"retail_quota\": best[\"retail_quota\"], \"reason_fields\": best})\n",
    "        remaining -= best[\"min_invest\"]\n",
    "\n",
    "    # repair: if remaining > 0 but < min(min_invest), attempt to rebalance:\n",
    "    min_unit = min([c[\"min_invest\"] for c in candidates]) if candidates else 0\n",
    "    if remaining > 0 and remaining < min_unit:\n",
    "        # try swapping out the lowest composite-per-rupee allocated lot\n",
    "        # pick allocated entry with smallest marginal benefit\n",
    "        allocation_sorted = sorted(allocation, key=lambda a: a[\"composite\"]/a[\"min_invest\"])\n",
    "        for out in allocation_sorted:\n",
    "            if out[\"lots\"] <= 0:\n",
    "                continue\n",
    "            # remove one lot\n",
    "            out[\"lots\"] -= 1\n",
    "            out[\"invested\"] -= out[\"min_invest\"]\n",
    "            remaining += out[\"min_invest\"]\n",
    "            if out[\"lots\"] == 0:\n",
    "                allocation = [x for x in allocation if x[\"ipo\"] != out[\"ipo\"]]\n",
    "            # now try to fill with candidate(s)\n",
    "            filled = False\n",
    "            for c in cand_sorted:\n",
    "                while remaining >= c[\"min_invest\"]:\n",
    "                    # add lot\n",
    "                    found = next((a for a in allocation if a[\"ipo\"] == c[\"ipo\"]), None)\n",
    "                    if found:\n",
    "                        found[\"lots\"] += 1\n",
    "                        found[\"invested\"] += c[\"min_invest\"]\n",
    "                    else:\n",
    "                        allocation.append({\"ipo\": c[\"ipo\"], \"lots\": 1, \"min_invest\": c[\"min_invest\"], \"invested\": c[\"min_invest\"], \"composite\": c[\"composite\"], \"retail_quota\": c[\"retail_quota\"], \"reason_fields\": c})\n",
    "                    remaining -= c[\"min_invest\"]\n",
    "                    filled = True\n",
    "            if filled:\n",
    "                break\n",
    "        # if still leftover and cannot allocate, leave small remainder\n",
    "    return allocation, remaining\n",
    "\n",
    "# generate explainability text\n",
    "def explain_allocation(allocation, candidates_dict):\n",
    "    explain = {}\n",
    "    for a in allocation:\n",
    "        c = candidates_dict.get(a[\"ipo\"])\n",
    "        reasons_more = []\n",
    "        reasons_less = []\n",
    "        # why more: high composite, decent retail quota, good fundamentals, GMP strength\n",
    "        if c:\n",
    "            if c[\"composite\"] >= 7:\n",
    "                reasons_more.append(\"High composite score (strong fundamentals + allotment chance + GMP).\")\n",
    "            elif c[\"composite\"] >= 6:\n",
    "                reasons_more.append(\"Above-average composite score.\")\n",
    "            else:\n",
    "                reasons_more.append(\"Moderate composite score.\")\n",
    "            if c[\"retail_quota\"] >= 30:\n",
    "                reasons_more.append(f\"Retail quota is {c['retail_quota']}% ‚Äî good allotment chance.\")\n",
    "            else:\n",
    "                reasons_less.append(f\"Retail quota is low ({c['retail_quota']}%) ‚Äî allotment chance may be lower.\")\n",
    "            if c[\"fund_score\"] and c[\"fund_score\"] >= 6:\n",
    "                reasons_more.append(\"Fundamentals look decent.\")\n",
    "            if c[\"gmp_strength\"] and c[\"gmp_strength\"] > 10:\n",
    "                reasons_more.append(f\"GMP indicates listing strength (~{round(c['gmp_strength'],1)}%).\")\n",
    "            # SME note\n",
    "            if \"sme\" in str(c.get(\"category\",\"\")).lower():\n",
    "                reasons_less.append(\"SME IPO: higher risk, less liquidity ‚Äî keep small exposure.\")\n",
    "        explain[a[\"ipo\"]] = {\"reasons_more\": reasons_more, \"reasons_less\": reasons_less}\n",
    "    return explain\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main():\n",
    "    print(\"IPO Allocator ‚Äî final (no leftovers unless all poor)\\n\")\n",
    "    try:\n",
    "        budget = float(input(\"Enter total budget in INR (e.g., 120000): \").strip())\n",
    "        hold_until = datetime.strptime(input(\"Enter hold-until date (YYYY-MM-DD): \").strip(), \"%Y-%m-%d\").date()\n",
    "    except Exception as e:\n",
    "        print(\"Invalid input:\", e)\n",
    "        return\n",
    "\n",
    "    ipos_by_name, scored = load_data()\n",
    "    candidates = build_candidates(ipos_by_name, scored, hold_until)\n",
    "\n",
    "    if not candidates:\n",
    "        print(\"No eligible IPOs (or all below score threshold / missing dates). Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Tighten max_lots per IPO based on budget\n",
    "    for c in candidates:\n",
    "        max_possible = int(budget // c[\"min_invest\"]) if c[\"min_invest\"]>0 else 0\n",
    "        c[\"max_lots\"] = max(0, min(DEFAULT_MAX_LOTS_PER_IPO, max_possible))\n",
    "\n",
    "    # remove candidates with max_lots==0 (too expensive)\n",
    "    candidates = [c for c in candidates if c[\"max_lots\"]>0]\n",
    "    if not candidates:\n",
    "        print(\"All eligible IPOs have min investment > budget. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Eligible IPOs (score >=5 and within hold date):\")\n",
    "    for c in candidates:\n",
    "        print(f\" ‚Ä¢ {c['ipo']}: composite={c['composite']}, min_invest=‚Çπ{int(c['min_invest'])}, retail={c['retail_quota']}% , max_lots={c['max_lots']}\")\n",
    "\n",
    "    # try pulp MILP\n",
    "    pulp_result = solve_with_pulp(candidates, budget)\n",
    "    if pulp_result is not None:\n",
    "        allocation, remaining = pulp_result\n",
    "        # if solution left a lot of leftover, try greedy_fill_full as alternative and pick better utilization\n",
    "        if remaining > 0.05 * budget:\n",
    "            g_alloc, g_rem = greedy_fill_full(candidates, budget)\n",
    "            # choose whichever uses more budget (smaller remainder), tie-break on higher objective\n",
    "            def used(a): return sum(x[\"invested\"] for x in a)\n",
    "            if (budget - g_rem) > (budget - remaining):\n",
    "                allocation, remaining = g_alloc, g_rem\n",
    "    else:\n",
    "        allocation, remaining = greedy_fill_full(candidates, budget)\n",
    "\n",
    "    # ensure we invested something ‚Äî if nothing, stop\n",
    "    if not allocation:\n",
    "        print(\"Could not allocate to any IPO (budget too small vs min_invest).\")\n",
    "        return\n",
    "\n",
    "    # Build explainability\n",
    "    candidates_dict = {c[\"ipo\"]: c for c in candidates}\n",
    "    explain = explain_allocation(allocation, candidates_dict)\n",
    "\n",
    "    total_invested = sum(a[\"invested\"] for a in allocation)\n",
    "    print(\"\\n--- Allocation ---\")\n",
    "    for a in allocation:\n",
    "        print(f\"{a['ipo']}: lots={a['lots']}, invested=‚Çπ{int(a['invested'])}, min_unit=‚Çπ{int(a['min_invest'])}, score={round(a['composite'],2) if 'composite' in a else 'N/A'}\")\n",
    "    print(f\"\\nTotal invested: ‚Çπ{int(total_invested)}\")\n",
    "    print(f\"Remaining (uninvested): ‚Çπ{int(remaining)}\")\n",
    "\n",
    "    # print explainability per IPO\n",
    "    print(\"\\n--- Explainability ---\")\n",
    "    for ipo, ex in explain.items():\n",
    "        print(f\"\\n{ipo}:\")\n",
    "        if ex[\"reasons_more\"]:\n",
    "            print(\"  Reasons to invest more:\")\n",
    "            for r in ex[\"reasons_more\"]:\n",
    "                print(\"   -\", r)\n",
    "        if ex[\"reasons_less\"]:\n",
    "            print(\"  Reasons to be cautious / invest less:\")\n",
    "            for r in ex[\"reasons_less\"]:\n",
    "                print(\"   -\", r)\n",
    "\n",
    "    # save recommendation\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    rec = {\n",
    "        \"created_at\": datetime.utcnow().isoformat(),\n",
    "        \"budget\": budget,\n",
    "        \"hold_until\": hold_until.isoformat(),\n",
    "        \"allocation\": allocation,\n",
    "        \"explain\": explain,\n",
    "        \"total_invested\": total_invested,\n",
    "        \"leftover\": remaining\n",
    "    }\n",
    "    client[DB_NAME][COL_RECOMMEND].insert_one(rec)\n",
    "    client.close()\n",
    "    print(\"\\nSaved recommendation to MongoDB (collection:\", COL_RECOMMEND, \")\")\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c7d21ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Balanced IPO Allocator (Retail)\n",
      "\n",
      "‚úÖ Found 6 eligible IPOs:\n",
      "\n",
      "‚Ä¢ PhysicsWallah | Mainboard | Score 6.3 | Min ‚Çπ14933 | Retail 10.0%\n",
      "‚Ä¢ Emmvee Photovoltaic Power | Mainboard | Score 6.171 | Min ‚Çπ14973 | Retail 10.0%\n",
      "‚Ä¢ Workmates Core2Cloud | SME | Score 6.135 | Min ‚Çπ244800 | Retail 10.0%\n",
      "‚Ä¢ Tenneco Clean Air | Mainboard | Score 6.089 | Min ‚Çπ14689 | Retail 10.0%\n",
      "‚Ä¢ Shining Tools | SME | Score 6.028 | Min ‚Çπ273600 | Retail 10.0%\n",
      "‚Ä¢ Shreeji Global FMCG | SME | Score 5.91 | Min ‚Çπ250000 | Retail 10.0%\n",
      "‚ö†Ô∏è PuLP not installed, using fallback greedy mode.\n",
      "\n",
      "üìà Optimized Allocation Plan:\n",
      "  - PhysicsWallah: ‚Çπ44799 (3 lot(s)) | Score 6.3 | Retail 10.0%\n",
      "  - Tenneco Clean Air: ‚Çπ44067 (3 lot(s)) | Score 6.089 | Retail 10.0%\n",
      "  - Emmvee Photovoltaic Power: ‚Çπ44919 (3 lot(s)) | Score 6.171 | Retail 10.0%\n",
      "  - Workmates Core2Cloud: ‚Çπ734400 (3 lot(s)) | Score 6.135 | Retail 10.0%\n",
      "\n",
      "üíµ Total Invested: ‚Çπ868185\n",
      "üí§ Remaining: ‚Çπ131815\n",
      "\n",
      "‚úÖ Saved recommendation to MongoDB successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime, date\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "COL_ANALYSIS = \"ipo_analysis\"\n",
    "COL_RECOMMEND = \"ipo_portfolio_recommendations\"\n",
    "\n",
    "MIN_INVEST_MAINBOARD = 15000\n",
    "DEFAULT_MAX_LOTS_PER_IPO = 3   # retail-friendly cap\n",
    "DIVERSIFICATION_WEIGHT = 0.1   # penalty for over-concentration\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(str(x).replace(\"‚Çπ\", \"\").replace(\",\", \"\").strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def try_parse_date(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    fmts = [\"%Y-%m-%d\", \"%d-%b-%Y\", \"%d %b %Y\", \"%d/%m/%Y\"]\n",
    "    for f in fmts:\n",
    "        try:\n",
    "            return datetime.strptime(s[:len(f)], f).date()\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        import dateutil.parser\n",
    "        return dateutil.parser.parse(s, dayfirst=True).date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def parse_lot_and_min_invest(text):\n",
    "    if not text:\n",
    "        return None, None\n",
    "    s = str(text)\n",
    "    m = re.search(r\"(?:Min[:\\s]*)?(\\d{1,6})\\s*shares?.*?‚Çπ\\s?([\\d,]+)\", s, flags=re.I)\n",
    "    if m:\n",
    "        lot = safe_float(m.group(1))\n",
    "        min_inv = safe_float(m.group(2))\n",
    "        return int(lot) if lot else None, float(min_inv) if min_inv else None\n",
    "    m2 = re.search(r\"‚Çπ\\s?([\\d,]+)\", s)\n",
    "    if m2:\n",
    "        return None, float(safe_float(m2.group(1)))\n",
    "    return None, None\n",
    "\n",
    "def parse_issue_mid(ipo_doc):\n",
    "    v = ipo_doc.get(\"issue_price\") or ipo_doc.get(\"extracted_fields\", {}).get(\"Price Band\")\n",
    "    if isinstance(v, dict):\n",
    "        mid = v.get(\"avg\") or v.get(\"mid\") or v.get(\"min\")\n",
    "        return safe_float(mid)\n",
    "    if not v:\n",
    "        return None\n",
    "    nums = re.findall(r\"\\d+\\.?\\d*\", str(v))\n",
    "    nums = [safe_float(n) for n in nums if safe_float(n) is not None]\n",
    "    return sum(nums)/len(nums) if nums else None\n",
    "\n",
    "def sanitize_for_mongo(obj):\n",
    "    \"\"\"Recursively convert datetime.date to ISO string.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: sanitize_for_mongo(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [sanitize_for_mongo(x) for x in obj]\n",
    "    elif isinstance(obj, date):\n",
    "        return datetime(obj.year, obj.month, obj.day).isoformat()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "def extract_retail_quota(text):\n",
    "    if not text:\n",
    "        return 10.0\n",
    "    m = re.search(r\"Retail\\s*:?(\\d+\\.?\\d*)%\", str(text), flags=re.I)\n",
    "    if m:\n",
    "        return safe_float(m.group(1))\n",
    "    return 10.0\n",
    "\n",
    "def extract_fundamental_score(text):\n",
    "    if not text:\n",
    "        return 5.0\n",
    "    score = 5.0\n",
    "    t = str(text).lower()\n",
    "    if \"profit\" in t or \"positive\" in t or \"growth\" in t:\n",
    "        score += 2\n",
    "    if \"loss\" in t or \"negative\" in t:\n",
    "        score -= 2\n",
    "    if \"roe\" in t:\n",
    "        m = re.search(r\"roe[:\\s]*([-\\d.]+)\", t)\n",
    "        if m:\n",
    "            roe = safe_float(m.group(1))\n",
    "            if roe and roe > 10:\n",
    "                score += 1.5\n",
    "    if \"d/e\" in t:\n",
    "        m = re.search(r\"d/e[:\\s]*([-\\d.]+)\", t)\n",
    "        if m:\n",
    "            de = safe_float(m.group(1))\n",
    "            if de and de > 1:\n",
    "                score -= 1\n",
    "    if \"eps\" in t:\n",
    "        m = re.search(r\"eps[:\\s]*[-(‚Çπ]?([\\d.]+)\", t)\n",
    "        if m:\n",
    "            eps = safe_float(m.group(1))\n",
    "            if eps and eps > 0:\n",
    "                score += 1\n",
    "            else:\n",
    "                score -= 1\n",
    "    return max(1, min(score, 10))\n",
    "\n",
    "def extract_sentiment(text):\n",
    "    if not text:\n",
    "        return 5.0\n",
    "    t = str(text).lower()\n",
    "    score = 5.0\n",
    "    good = [\"growing\", \"leader\", \"expanding\", \"innovative\", \"strong\", \"profitable\", \"stable\"]\n",
    "    bad = [\"loss\", \"decline\", \"volatile\", \"uncertain\", \"risky\", \"unprofitable\"]\n",
    "    for w in good:\n",
    "        if w in t:\n",
    "            score += 0.5\n",
    "    for w in bad:\n",
    "        if w in t:\n",
    "            score -= 0.5\n",
    "    return max(1, min(score, 10))\n",
    "\n",
    "def compute_composite(ipo_doc, analysis):\n",
    "    fields = ipo_doc.get(\"extracted_fields\", {}) or {}\n",
    "    base = analysis.get(\"score\", 5)\n",
    "    retail = extract_retail_quota(fields.get(\"Investor Quota Split\"))\n",
    "    fund = extract_fundamental_score(fields.get(\"Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)\") or fields.get(\"Financial Performance (FY23‚ÄìFY25)\"))\n",
    "    sent = extract_sentiment(fields.get(\"Company Overview\"))\n",
    "    gmp = safe_float(ipo_doc.get(\"gmp_investorgain\")) or 0\n",
    "    issue = parse_issue_mid(ipo_doc)\n",
    "    gmp_strength = (gmp / issue * 100) if (gmp and issue) else 0\n",
    "    rq_score = min(retail / 10, 1) * 10\n",
    "    composite = 0.30*base + 0.25*rq_score + 0.20*fund + 0.15*(gmp_strength/10) + 0.10*sent\n",
    "    return round(min(composite, 10), 3), retail, fund, sent, gmp_strength\n",
    "\n",
    "def load_data():\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    ipos = list(client[DB_NAME][COL_IPOS].find({}))\n",
    "    analysis = list(client[DB_NAME][COL_ANALYSIS].find({}))\n",
    "    client.close()\n",
    "    ipos_by_name = {d[\"ipo\"]: d for d in ipos if \"ipo\" in d}\n",
    "    scored = {a[\"ipo\"]: a for a in analysis if \"ipo\" in a}\n",
    "    return ipos_by_name, scored\n",
    "\n",
    "# ---------- CANDIDATE PREP ----------\n",
    "def build_candidates(ipos_by_name, scored, hold_date):\n",
    "    cands = []\n",
    "    for name, ipo in ipos_by_name.items():\n",
    "        if name not in scored:\n",
    "            continue\n",
    "        analysis = scored[name]\n",
    "        if analysis.get(\"status\") != \"scored\" and \"score\" not in analysis:\n",
    "            continue\n",
    "        fields = ipo.get(\"extracted_fields\", {}) or {}\n",
    "        close = ipo.get(\"close_date\") or fields.get(\"IPO Dates\") or fields.get(\"Close Date\")\n",
    "        close_date = try_parse_date(str(close))\n",
    "        if not close_date or close_date > hold_date:\n",
    "            continue\n",
    "\n",
    "        issue_mid = parse_issue_mid(ipo)\n",
    "        if not issue_mid:\n",
    "            continue\n",
    "\n",
    "        lot, min_inv = parse_lot_and_min_invest(fields.get(\"Market Lot & Amounts\"))\n",
    "        if not min_inv:\n",
    "            min_inv = lot * issue_mid if lot else MIN_INVEST_MAINBOARD\n",
    "\n",
    "        composite, retail, fund, sent, gmp_strength = compute_composite(ipo, analysis)\n",
    "        if composite < 5:\n",
    "            continue\n",
    "\n",
    "        cands.append({\n",
    "            \"ipo\": name,\n",
    "            \"category\": ipo.get(\"category\", \"Mainboard\"),\n",
    "            \"composite\": composite,\n",
    "            \"retail_quota\": retail,\n",
    "            \"fund_score\": fund,\n",
    "            \"sentiment\": sent,\n",
    "            \"gmp_strength\": gmp_strength,\n",
    "            \"issue_mid\": issue_mid,\n",
    "            \"lot\": lot,\n",
    "            \"min_invest\": min_inv,\n",
    "            \"close_date\": close_date,\n",
    "        })\n",
    "    return cands\n",
    "\n",
    "# ---------- ALLOCATION ----------\n",
    "def allocate_balanced(candidates, budget):\n",
    "    \"\"\"Balanced allocator that penalizes over-concentration and uses all budget.\"\"\"\n",
    "    try:\n",
    "        import pulp\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è PuLP not installed, using fallback greedy mode.\")\n",
    "        return greedy_fill_full(candidates, budget)\n",
    "\n",
    "    prob = pulp.LpProblem(\"Balanced_IPO_Allocation\", pulp.LpMaximize)\n",
    "    lot_vars = {}\n",
    "\n",
    "    for c in candidates:\n",
    "        safe_name = re.sub(r\"\\W+\", \"_\", c[\"ipo\"])\n",
    "        max_possible = int(max(1, budget // c[\"min_invest\"]))\n",
    "        cap = min(DEFAULT_MAX_LOTS_PER_IPO, max_possible)\n",
    "        lot_vars[c[\"ipo\"]] = pulp.LpVariable(f\"lots_{safe_name}\", lowBound=0, upBound=cap, cat=\"Integer\")\n",
    "\n",
    "    # objective: maximize (score * lots) - diversification penalty\n",
    "    total_lots = pulp.lpSum(lot_vars.values())\n",
    "    objective = pulp.lpSum([c[\"composite\"] * lot_vars[c[\"ipo\"]] for c in candidates])\n",
    "    penalty = DIVERSIFICATION_WEIGHT * pulp.lpSum([(lot_vars[c[\"ipo\"]] ** 2) for c in candidates])\n",
    "    prob += objective - penalty\n",
    "\n",
    "    # budget constraint\n",
    "    prob += pulp.lpSum([c[\"min_invest\"] * lot_vars[c[\"ipo\"]] for c in candidates]) <= budget\n",
    "\n",
    "    prob.solve(pulp.PULP_CBC_CMD(msg=False, timeLimit=10))\n",
    "\n",
    "    allocation = []\n",
    "    total_invested = 0\n",
    "    for c in candidates:\n",
    "        v = int(pulp.value(lot_vars[c[\"ipo\"]]) or 0)\n",
    "        if v > 0:\n",
    "            invested = v * c[\"min_invest\"]\n",
    "            allocation.append({\n",
    "                \"ipo\": c[\"ipo\"],\n",
    "                \"lots\": v,\n",
    "                \"invested\": invested,\n",
    "                \"min_invest\": c[\"min_invest\"],\n",
    "                \"composite\": c[\"composite\"],\n",
    "                \"retail_quota\": c[\"retail_quota\"]\n",
    "            })\n",
    "            total_invested += invested\n",
    "    remaining = budget - total_invested\n",
    "    return allocation, remaining\n",
    "\n",
    "def greedy_fill_full(candidates, budget):\n",
    "    candidates = sorted(candidates, key=lambda x: x[\"composite\"]/x[\"min_invest\"], reverse=True)\n",
    "    allocation = []\n",
    "    remaining = budget\n",
    "    for c in candidates:\n",
    "        if remaining < min(x[\"min_invest\"] for x in candidates):\n",
    "            break\n",
    "        max_lots = min(DEFAULT_MAX_LOTS_PER_IPO, int(remaining // c[\"min_invest\"]))\n",
    "        if max_lots <= 0:\n",
    "            continue\n",
    "        invested = c[\"min_invest\"] * max_lots\n",
    "        allocation.append({\n",
    "            \"ipo\": c[\"ipo\"],\n",
    "            \"lots\": max_lots,\n",
    "            \"invested\": invested,\n",
    "            \"min_invest\": c[\"min_invest\"],\n",
    "            \"composite\": c[\"composite\"],\n",
    "            \"retail_quota\": c[\"retail_quota\"]\n",
    "        })\n",
    "        remaining -= invested\n",
    "    return allocation, remaining\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main():\n",
    "    print(\"üìä Balanced IPO Allocator (Retail)\\n\")\n",
    "    try:\n",
    "        budget = float(input(\"Enter total budget (‚Çπ): \").strip())\n",
    "        hold_date = datetime.strptime(input(\"Enter hold-until date (YYYY-MM-DD): \").strip(), \"%Y-%m-%d\").date()\n",
    "    except Exception as e:\n",
    "        print(\"Invalid input:\", e)\n",
    "        return\n",
    "\n",
    "    ipos_by_name, scored = load_data()\n",
    "    candidates = build_candidates(ipos_by_name, scored, hold_date)\n",
    "    if not candidates:\n",
    "        print(\"No eligible IPOs found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"‚úÖ Found {len(candidates)} eligible IPOs:\\n\")\n",
    "    for c in candidates:\n",
    "        print(f\"‚Ä¢ {c['ipo']} | {c['category']} | Score {c['composite']} | Min ‚Çπ{int(c['min_invest'])} | Retail {c['retail_quota']}%\")\n",
    "\n",
    "    allocation, remaining = allocate_balanced(candidates, budget)\n",
    "    if not allocation:\n",
    "        print(\"‚ùå No allocation possible with given budget.\")\n",
    "        return\n",
    "\n",
    "    total_invested = sum(a[\"invested\"] for a in allocation)\n",
    "\n",
    "    print(\"\\nüìà Optimized Allocation Plan:\")\n",
    "    for a in allocation:\n",
    "        print(f\"  - {a['ipo']}: ‚Çπ{int(a['invested'])} ({a['lots']} lot(s)) | Score {a['composite']} | Retail {a['retail_quota']}%\")\n",
    "    print(f\"\\nüíµ Total Invested: ‚Çπ{int(total_invested)}\")\n",
    "    print(f\"üí§ Remaining: ‚Çπ{int(remaining)}\")\n",
    "\n",
    "    # save results safely\n",
    "    rec = {\n",
    "        \"created_at\": datetime.utcnow().isoformat(),\n",
    "        \"budget\": budget,\n",
    "        \"hold_until\": hold_date.isoformat(),\n",
    "        \"allocation\": allocation,\n",
    "        \"total_invested\": total_invested,\n",
    "        \"leftover\": remaining,\n",
    "        \"count\": len(allocation)\n",
    "    }\n",
    "    rec = sanitize_for_mongo(rec)\n",
    "\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    client[DB_NAME][COL_RECOMMEND].insert_one(rec)\n",
    "    client.close()\n",
    "    print(\"\\n‚úÖ Saved recommendation to MongoDB successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fffc0525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä IPO Allocator ‚Äî Full explainable mode\n",
      "\n",
      "‚úÖ Found 6 eligible IPOs:\n",
      "\n",
      "‚Ä¢ PhysicsWallah | Mainboard | Composite 6.3 | Min ‚Çπ14933 | Retail 10.0%\n",
      "‚Ä¢ Emmvee Photovoltaic Power | Mainboard | Composite 6.171 | Min ‚Çπ14973 | Retail 10.0%\n",
      "‚Ä¢ Workmates Core2Cloud | SME | Composite 6.135 | Min ‚Çπ244800 | Retail 10.0%\n",
      "‚Ä¢ Tenneco Clean Air | Mainboard | Composite 6.089 | Min ‚Çπ14689 | Retail 10.0%\n",
      "‚Ä¢ Shining Tools | SME | Composite 6.028 | Min ‚Çπ273600 | Retail 10.0%\n",
      "‚Ä¢ Shreeji Global FMCG | SME | Composite 5.91 | Min ‚Çπ250000 | Retail 10.0%\n",
      "‚ö†Ô∏è PuLP not installed or failed ‚Äî using improved greedy filler.\n",
      "\n",
      "üìà Final Allocation Plan:\n",
      "  - PhysicsWallah: ‚Çπ74665 (5 lots) | min_unit=‚Çπ14933 | score 6.3\n",
      "  - Emmvee Photovoltaic Power: ‚Çπ74865 (5 lots) | min_unit=‚Çπ14973 | score 6.171\n",
      "  - Workmates Core2Cloud: ‚Çπ244800 (1 lots) | min_unit=‚Çπ244800 | score 6.135\n",
      "  - Tenneco Clean Air: ‚Çπ73445 (5 lots) | min_unit=‚Çπ14689 | score 6.089\n",
      "  - Shining Tools: ‚Çπ273600 (1 lots) | min_unit=‚Çπ273600 | score 6.028\n",
      "  - Shreeji Global FMCG: ‚Çπ250000 (1 lots) | min_unit=‚Çπ250000 | score 5.91\n",
      "\n",
      "üíµ Total Invested: ‚Çπ991375\n",
      "üí§ Remaining: ‚Çπ8625\n",
      "\n",
      "--- Explainability & Formulas ---\n",
      "\n",
      "Algorithm summary:\n",
      "  - We compute a composite score per IPO combining:\n",
      "      composite = 0.30*base_score + 0.25*rq_score + 0.20*fund_score + 0.15*(gmp_strength/10) + 0.10*sentiment_score\n",
      "    where rq_score = min(retail_pct/10,1)*10 (normalized 0-10).\n",
      "  - Primary solver: MILP (PuLP) maximizing sum(composite * lots) minus DIVERSIFICATION_WEIGHT * sum(lots^2).\n",
      "  - Fallback: improved greedy that:\n",
      "      1) gives 1 lot to each top candidate by composite/unit if affordable,\n",
      "      2) repeatedly fills top K candidates (round-robin) to use leftover,\n",
      "      3) finally uses any remaining budget on best composite/unit candidate.\n",
      "  - Unit = min_invest (usually lot * issue price or ‚Çπ15k for mainboard fallback).\n",
      "  - We skip any IPO with composite < 5 per your instruction.\n",
      "\n",
      "Parameters used:\n",
      "  - MIN_INVEST_MAINBOARD = 15000\n",
      "  - DEFAULT_MAX_LOTS_PER_IPO = 3\n",
      "  - DIVERSIFICATION_WEIGHT = 0.1\n",
      "  - TOP_FILL_K = 3\n",
      "\n",
      "Per-IPO reasons (why more / why less):\n",
      "\n",
      "üîé PhysicsWallah\n",
      "  Breakdown: base=5.8, retail%=10.0%, rq_score=10.0, fund=5.0, sentiment=5.5, gmp_str%=33.981\n",
      "  Reasons to invest more:\n",
      "   - Composite score 6.3 computed from base_score=5.8, retail_q=10.0%, fund=5.0, sentiment=5.5, gmp_str=33.981% using weights {'base': 0.3, 'retail': 0.25, 'fund': 0.2, 'gmp': 0.15, 'sentiment': 0.1}.\n",
      "   - High GMP strength 33.981% ‚Üí strong listing expectation.\n",
      "  Reasons to be cautious:\n",
      "   - Retail quota 10.0% is low; allotment probability may be limited.\n",
      "   - Fundamentals are weak/moderate.\n",
      "\n",
      "üîé Emmvee Photovoltaic Power\n",
      "  Breakdown: base=5.1, retail%=10.0%, rq_score=10.0, fund=6.5, sentiment=5.5, gmp_str%=19.417\n",
      "  Reasons to invest more:\n",
      "   - Composite score 6.171 computed from base_score=5.1, retail_q=10.0%, fund=6.5, sentiment=5.5, gmp_str=19.417% using weights {'base': 0.3, 'retail': 0.25, 'fund': 0.2, 'gmp': 0.15, 'sentiment': 0.1}.\n",
      "   - High GMP strength 19.417% ‚Üí strong listing expectation.\n",
      "   - Fundamentals show positive indicators.\n",
      "  Reasons to be cautious:\n",
      "   - Retail quota 10.0% is low; allotment probability may be limited.\n",
      "\n",
      "üîé Workmates Core2Cloud\n",
      "  Breakdown: base=4.9, retail%=10.0%, rq_score=10.0, fund=7.5, sentiment=5.0, gmp_str%=11.0\n",
      "  Reasons to invest more:\n",
      "   - Composite score 6.135 computed from base_score=4.9, retail_q=10.0%, fund=7.5, sentiment=5.0, gmp_str=11.0% using weights {'base': 0.3, 'retail': 0.25, 'fund': 0.2, 'gmp': 0.15, 'sentiment': 0.1}.\n",
      "   - High GMP strength 11.0% ‚Üí strong listing expectation.\n",
      "   - Fundamentals show positive indicators.\n",
      "  Reasons to be cautious:\n",
      "   - Retail quota 10.0% is low; allotment probability may be limited.\n",
      "   - SME IPO: higher risk & lower liquidity ‚Äî allocate small exposure.\n",
      "\n",
      "üîé Tenneco Clean Air\n",
      "  Breakdown: base=4.7, retail%=10.0%, rq_score=10.0, fund=7.5, sentiment=5.0, gmp_str%=11.905\n",
      "  Reasons to invest more:\n",
      "   - Composite score 6.089 computed from base_score=4.7, retail_q=10.0%, fund=7.5, sentiment=5.0, gmp_str=11.905% using weights {'base': 0.3, 'retail': 0.25, 'fund': 0.2, 'gmp': 0.15, 'sentiment': 0.1}.\n",
      "   - High GMP strength 11.905% ‚Üí strong listing expectation.\n",
      "   - Fundamentals show positive indicators.\n",
      "  Reasons to be cautious:\n",
      "   - Retail quota 10.0% is low; allotment probability may be limited.\n",
      "\n",
      "üîé Shining Tools\n",
      "  Breakdown: base=4.9, retail%=10.0%, rq_score=10.0, fund=7.0, sentiment=5.0, gmp_str%=10.526\n",
      "  Reasons to invest more:\n",
      "   - Composite score 6.028 computed from base_score=4.9, retail_q=10.0%, fund=7.0, sentiment=5.0, gmp_str=10.526% using weights {'base': 0.3, 'retail': 0.25, 'fund': 0.2, 'gmp': 0.15, 'sentiment': 0.1}.\n",
      "   - High GMP strength 10.526% ‚Üí strong listing expectation.\n",
      "   - Fundamentals show positive indicators.\n",
      "  Reasons to be cautious:\n",
      "   - Retail quota 10.0% is low; allotment probability may be limited.\n",
      "   - SME IPO: higher risk & lower liquidity ‚Äî allocate small exposure.\n",
      "\n",
      "üîé Shreeji Global FMCG\n",
      "  Breakdown: base=4.7, retail%=10.0%, rq_score=10.0, fund=6.5, sentiment=6.0, gmp_str%=6.667\n",
      "  Reasons to invest more:\n",
      "   - Composite score 5.91 computed from base_score=4.7, retail_q=10.0%, fund=6.5, sentiment=6.0, gmp_str=6.667% using weights {'base': 0.3, 'retail': 0.25, 'fund': 0.2, 'gmp': 0.15, 'sentiment': 0.1}.\n",
      "   - Fundamentals show positive indicators.\n",
      "  Reasons to be cautious:\n",
      "   - Retail quota 10.0% is low; allotment probability may be limited.\n",
      "   - SME IPO: higher risk & lower liquidity ‚Äî allocate small exposure.\n",
      "\n",
      "‚úÖ Saved recommendation to MongoDB (collection: ipo_portfolio_recommendations )\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime, date\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "COL_ANALYSIS = \"ipo_analysis\"\n",
    "COL_RECOMMEND = \"ipo_portfolio_recommendations\"\n",
    "\n",
    "MIN_INVEST_MAINBOARD = 15000\n",
    "DEFAULT_MAX_LOTS_PER_IPO = 3   # soft cap for diversification initially\n",
    "DIVERSIFICATION_WEIGHT = 0.10  # penalty in MILP objective\n",
    "TOP_FILL_K = 3                 # when filling leftovers, prioritize top K IPOs\n",
    "\n",
    "# ---------- UTILITIES ----------\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(str(x).replace(\"‚Çπ\", \"\").replace(\",\", \"\").strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def try_parse_date(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    fmts = [\"%Y-%m-%d\", \"%d-%b-%Y\", \"%d %b %Y\", \"%d/%m/%Y\"]\n",
    "    for f in fmts:\n",
    "        try:\n",
    "            return datetime.strptime(s[:len(f)], f).date()\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        import dateutil.parser\n",
    "        return dateutil.parser.parse(s, dayfirst=True).date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def parse_lot_and_min_invest(text):\n",
    "    if not text:\n",
    "        return None, None\n",
    "    s = str(text)\n",
    "    m = re.search(r\"(?:Min[:\\s]*)?(\\d{1,6})\\s*shares?.*?‚Çπ\\s?([\\d,]+)\", s, flags=re.I)\n",
    "    if m:\n",
    "        lot = safe_float(m.group(1))\n",
    "        min_inv = safe_float(m.group(2))\n",
    "        return int(lot) if lot else None, float(min_inv) if min_inv else None\n",
    "    m2 = re.search(r\"‚Çπ\\s?([\\d,]+)\", s)\n",
    "    if m2:\n",
    "        return None, float(safe_float(m2.group(1)))\n",
    "    return None, None\n",
    "\n",
    "def parse_issue_mid(ipo_doc):\n",
    "    v = ipo_doc.get(\"issue_price\") or ipo_doc.get(\"extracted_fields\", {}).get(\"Price Band\")\n",
    "    if isinstance(v, dict):\n",
    "        mid = v.get(\"avg\") or v.get(\"mid\") or v.get(\"min\")\n",
    "        return safe_float(mid)\n",
    "    if not v:\n",
    "        return None\n",
    "    nums = re.findall(r\"\\d+\\.?\\d*\", str(v))\n",
    "    nums = [safe_float(n) for n in nums if safe_float(n) is not None]\n",
    "    return sum(nums)/len(nums) if nums else None\n",
    "\n",
    "def sanitize_for_mongo(obj):\n",
    "    \"\"\"Recursively convert datetime.date to ISO string and datetime to iso.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: sanitize_for_mongo(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [sanitize_for_mongo(x) for x in obj]\n",
    "    elif isinstance(obj, date):\n",
    "        return datetime(obj.year, obj.month, obj.day).isoformat()\n",
    "    elif isinstance(obj, datetime):\n",
    "        return obj.isoformat()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# ---------- SCORING COMPONENTS ----------\n",
    "def extract_retail_quota(text):\n",
    "    if not text:\n",
    "        return 10.0\n",
    "    m = re.search(r\"Retail\\s*:?(\\d+\\.?\\d*)%\", str(text), flags=re.I)\n",
    "    if m:\n",
    "        return safe_float(m.group(1))\n",
    "    return 10.0\n",
    "\n",
    "def extract_fundamental_score(text):\n",
    "    if not text:\n",
    "        return 5.0\n",
    "    score = 5.0\n",
    "    t = str(text).lower()\n",
    "    if \"profit\" in t or \"positive\" in t or \"growth\" in t:\n",
    "        score += 2\n",
    "    if \"loss\" in t or \"negative\" in t:\n",
    "        score -= 2\n",
    "    # ROE, D/E, EPS heuristics:\n",
    "    m = re.search(r\"roe[:\\s]*([-\\d.]+)\", t)\n",
    "    if m:\n",
    "        roe = safe_float(m.group(1))\n",
    "        if roe and roe > 10:\n",
    "            score += 1.5\n",
    "    m = re.search(r\"d/?e[:\\s]*([-\\d.]+)\", t)\n",
    "    if m:\n",
    "        de = safe_float(m.group(1))\n",
    "        if de and de > 1:\n",
    "            score -= 1\n",
    "    m = re.search(r\"eps[:\\s]*[-(‚Çπ]?([\\d.]+)\", t)\n",
    "    if m:\n",
    "        eps = safe_float(m.group(1))\n",
    "        if eps and eps > 0:\n",
    "            score += 1\n",
    "        else:\n",
    "            score -= 1\n",
    "    return max(1, min(score, 10))\n",
    "\n",
    "def extract_sentiment(text):\n",
    "    if not text:\n",
    "        return 5.0\n",
    "    t = str(text).lower()\n",
    "    score = 5.0\n",
    "    good = [\"growing\", \"leader\", \"expanding\", \"innovative\", \"strong\", \"profitable\", \"stable\"]\n",
    "    bad = [\"loss\", \"decline\", \"volatile\", \"uncertain\", \"risky\", \"unprofitable\"]\n",
    "    for w in good:\n",
    "        if w in t:\n",
    "            score += 0.5\n",
    "    for w in bad:\n",
    "        if w in t:\n",
    "            score -= 0.5\n",
    "    return max(1, min(score, 10))\n",
    "\n",
    "def compute_composite_and_breakdown(ipo_doc, analysis):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      composite (float),\n",
    "      breakdown: dict with base_score, retail_quota, rq_score, fund_score, sentiment, gmp_strength, formula_weights\n",
    "    \"\"\"\n",
    "    fields = ipo_doc.get(\"extracted_fields\", {}) or {}\n",
    "    base = analysis.get(\"score\", 5)  # from earlier scorer\n",
    "    retail = extract_retail_quota(fields.get(\"Investor Quota Split\"))\n",
    "    fund = extract_fundamental_score(fields.get(\"Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)\") or fields.get(\"Financial Performance (FY23‚ÄìFY25)\"))\n",
    "    sent = extract_sentiment(fields.get(\"Company Overview\"))\n",
    "    gmp = safe_float(ipo_doc.get(\"gmp_investorgain\")) or 0\n",
    "    issue = parse_issue_mid(ipo_doc)\n",
    "    gmp_strength = (gmp / issue * 100) if (gmp and issue) else 0\n",
    "    # retail quota normalized to 0-10\n",
    "    rq_score = min(retail / 10, 1) * 10\n",
    "\n",
    "    # weights (documented to user later)\n",
    "    w_base = 0.30\n",
    "    w_rq = 0.25\n",
    "    w_fund = 0.20\n",
    "    w_gmp = 0.15\n",
    "    w_sent = 0.10\n",
    "\n",
    "    composite = w_base*base + w_rq*rq_score + w_fund*fund + w_gmp*(gmp_strength/10) + w_sent*sent\n",
    "    composite = round(min(composite, 10), 3)\n",
    "\n",
    "    breakdown = {\n",
    "        \"base_score\": base,\n",
    "        \"retail_quota_pct\": retail,\n",
    "        \"rq_score\": round(rq_score,3),\n",
    "        \"fund_score\": round(fund,3),\n",
    "        \"sentiment_score\": round(sent,3),\n",
    "        \"gmp_strength_pct\": round(gmp_strength,3),\n",
    "        \"weights\": {\"base\": w_base, \"retail\": w_rq, \"fund\": w_fund, \"gmp\": w_gmp, \"sentiment\": w_sent}\n",
    "    }\n",
    "    return composite, breakdown\n",
    "\n",
    "# ---------- DATA LOAD ----------\n",
    "def load_data():\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    ipos = list(client[DB_NAME][COL_IPOS].find({}))\n",
    "    analysis = list(client[DB_NAME][COL_ANALYSIS].find({}))\n",
    "    client.close()\n",
    "    ipos_by_name = {d[\"ipo\"]: d for d in ipos if \"ipo\" in d}\n",
    "    scored = {a[\"ipo\"]: a for a in analysis if \"ipo\" in a}\n",
    "    return ipos_by_name, scored\n",
    "\n",
    "# ---------- BUILD CANDIDATES ----------\n",
    "def build_candidates(ipos_by_name, scored, hold_date):\n",
    "    cands = []\n",
    "    for name, ipo in ipos_by_name.items():\n",
    "        if name not in scored:\n",
    "            continue\n",
    "        analysis = scored[name]\n",
    "        if analysis.get(\"status\") != \"scored\" and \"score\" not in analysis:\n",
    "            continue\n",
    "        fields = ipo.get(\"extracted_fields\", {}) or {}\n",
    "        close = ipo.get(\"close_date\") or fields.get(\"IPO Dates\") or fields.get(\"Close Date\")\n",
    "        close_date = try_parse_date(str(close))\n",
    "        if not close_date or close_date > hold_date:\n",
    "            continue\n",
    "\n",
    "        issue_mid = parse_issue_mid(ipo)\n",
    "        if not issue_mid:\n",
    "            continue\n",
    "\n",
    "        lot, min_inv = parse_lot_and_min_invest(fields.get(\"Market Lot & Amounts\"))\n",
    "        if not min_inv:\n",
    "            min_inv = (lot * issue_mid) if lot else MIN_INVEST_MAINBOARD\n",
    "\n",
    "        composite, breakdown = compute_composite_and_breakdown(ipo, analysis)\n",
    "        if composite < 5:\n",
    "            # skip per user instruction\n",
    "            continue\n",
    "\n",
    "        cands.append({\n",
    "            \"ipo\": name,\n",
    "            \"category\": ipo.get(\"category\", \"Mainboard\"),\n",
    "            \"composite\": composite,\n",
    "            \"breakdown\": breakdown,\n",
    "            \"issue_mid\": issue_mid,\n",
    "            \"lot\": int(lot) if lot else None,\n",
    "            \"min_invest\": float(min_inv),\n",
    "            \"close_date\": close_date,\n",
    "            \"gmp_investorgain\": ipo.get(\"gmp_investorgain\"),\n",
    "            \"analysis\": analysis\n",
    "        })\n",
    "    return cands\n",
    "\n",
    "# ---------- GREEDY-FILL (improved) ----------\n",
    "def greedy_fill_full(candidates, budget):\n",
    "    \"\"\"\n",
    "    Improved greedy:\n",
    "     - initial pass: allocate 1 lot to as many top candidates as possible (descending composite/min_invest)\n",
    "     - second pass: try to add additional lots to top K candidates in round-robin until can't\n",
    "     - final pass: try any candidate that can fit another lot\n",
    "    This aggressively uses budget to minimize leftover while respecting lot units.\n",
    "    \"\"\"\n",
    "    candidates = sorted(candidates, key=lambda x: x[\"composite\"]/x[\"min_invest\"], reverse=True)\n",
    "    allocation = []\n",
    "    remaining = budget\n",
    "    min_unit = min(c[\"min_invest\"] for c in candidates)\n",
    "\n",
    "    # initial one-lot diversification\n",
    "    for c in candidates:\n",
    "        if remaining >= c[\"min_invest\"]:\n",
    "            allocation.append({\"ipo\": c[\"ipo\"], \"lots\": 1, \"min_invest\": c[\"min_invest\"], \"invested\": c[\"min_invest\"], \"composite\": c[\"composite\"]})\n",
    "            remaining -= c[\"min_invest\"]\n",
    "\n",
    "    # second pass: fill top-K repeatedly (this prevents huge leftover)\n",
    "    top_k = candidates[:min(TOP_FILL_K, len(candidates))]\n",
    "    # keep adding 1 lot to each top_k in order while possible\n",
    "    added = True\n",
    "    while added and remaining >= min_unit:\n",
    "        added = False\n",
    "        for c in top_k:\n",
    "            if remaining >= c[\"min_invest\"]:\n",
    "                found = next((a for a in allocation if a[\"ipo\"] == c[\"ipo\"]), None)\n",
    "                if found:\n",
    "                    found[\"lots\"] += 1\n",
    "                    found[\"invested\"] += c[\"min_invest\"]\n",
    "                else:\n",
    "                    allocation.append({\"ipo\": c[\"ipo\"], \"lots\": 1, \"min_invest\": c[\"min_invest\"], \"invested\": c[\"min_invest\"], \"composite\": c[\"composite\"]})\n",
    "                remaining -= c[\"min_invest\"]\n",
    "                added = True\n",
    "            if remaining < min_unit:\n",
    "                break\n",
    "\n",
    "    # final pass: try to spend remaining on any candidate by composite/unit\n",
    "    while remaining >= min_unit:\n",
    "        affordable = [c for c in candidates if c[\"min_invest\"] <= remaining]\n",
    "        if not affordable:\n",
    "            break\n",
    "        pick = max(affordable, key=lambda x: x[\"composite\"]/x[\"min_invest\"])\n",
    "        found = next((a for a in allocation if a[\"ipo\"] == pick[\"ipo\"]), None)\n",
    "        if found:\n",
    "            found[\"lots\"] += 1\n",
    "            found[\"invested\"] += pick[\"min_invest\"]\n",
    "        else:\n",
    "            allocation.append({\"ipo\": pick[\"ipo\"], \"lots\": 1, \"min_invest\": pick[\"min_invest\"], \"invested\": pick[\"min_invest\"], \"composite\": pick[\"composite\"]})\n",
    "        remaining -= pick[\"min_invest\"]\n",
    "\n",
    "    # sort allocation by composite desc\n",
    "    allocation = sorted(allocation, key=lambda x: x[\"composite\"], reverse=True)\n",
    "    return allocation, remaining\n",
    "\n",
    "# ---------- MILP (balanced) ----------\n",
    "def allocate_balanced(candidates, budget):\n",
    "    \"\"\"Try PuLP MILP with diversification penalty; fallback to greedy_fill_full if PuLP absent.\"\"\"\n",
    "    try:\n",
    "        import pulp\n",
    "    except ImportError:\n",
    "        return None, None  # caller will pick greedy\n",
    "\n",
    "    prob = pulp.LpProblem(\"Balanced_IPO\", pulp.LpMaximize)\n",
    "    vars_map = {}\n",
    "    for c in candidates:\n",
    "        safe_name = re.sub(r\"\\W+\", \"_\", c[\"ipo\"])\n",
    "        max_possible = int(max(1, budget // c[\"min_invest\"]))\n",
    "        cap = min(DEFAULT_MAX_LOTS_PER_IPO, max_possible)\n",
    "        vars_map[c[\"ipo\"]] = pulp.LpVariable(f\"lots_{safe_name}\", lowBound=0, upBound=cap, cat=\"Integer\")\n",
    "\n",
    "    # objective: maximize sum(score * lots) - diversification_penalty\n",
    "    obj = pulp.lpSum([c[\"composite\"] * vars_map[c[\"ipo\"]] for c in candidates])\n",
    "    # diversification penalty uses squared lots to penalize concentration\n",
    "    penalty = DIVERSIFICATION_WEIGHT * pulp.lpSum([(vars_map[c[\"ipo\"]]**2) for c in candidates])\n",
    "    prob += obj - penalty\n",
    "\n",
    "    # budget constraint\n",
    "    prob += pulp.lpSum([c[\"min_invest\"] * vars_map[c[\"ipo\"]] for c in candidates]) <= budget\n",
    "\n",
    "    # solve\n",
    "    prob.solve(pulp.PULP_CBC_CMD(msg=False, timeLimit=10))\n",
    "\n",
    "    allocation = []\n",
    "    total_invested = 0.0\n",
    "    for c in candidates:\n",
    "        v = int(pulp.value(vars_map[c[\"ipo\"]]) or 0)\n",
    "        if v > 0:\n",
    "            invested = v * c[\"min_invest\"]\n",
    "            allocation.append({\"ipo\": c[\"ipo\"], \"lots\": v, \"invested\": invested, \"min_invest\": c[\"min_invest\"], \"composite\": c[\"composite\"]})\n",
    "            total_invested += invested\n",
    "    remaining = budget - total_invested\n",
    "    return allocation, remaining\n",
    "\n",
    "# ---------- EXPLAINABILITY ----------\n",
    "def explain_allocation(allocation, candidates_dict):\n",
    "    explain = {}\n",
    "    for a in allocation:\n",
    "        c = candidates_dict.get(a[\"ipo\"])\n",
    "        reasons_more = []\n",
    "        reasons_less = []\n",
    "        br = c[\"breakdown\"]\n",
    "        # add numeric breakdown\n",
    "        reasons_more.append(f\"Composite score {c['composite']} computed from base_score={br['base_score']}, retail_q={br['retail_quota_pct']}%, fund={br['fund_score']}, sentiment={br['sentiment_score']}, gmp_str={br['gmp_strength_pct']}% using weights {br['weights']}.\")\n",
    "        if br['gmp_strength_pct'] > 10:\n",
    "            reasons_more.append(f\"High GMP strength {br['gmp_strength_pct']}% ‚Üí strong listing expectation.\")\n",
    "        if br['retail_quota_pct'] >= 30:\n",
    "            reasons_more.append(\"High retail quota ‚Üí better allotment odds.\")\n",
    "        else:\n",
    "            reasons_less.append(f\"Retail quota {br['retail_quota_pct']}% is low; allotment probability may be limited.\")\n",
    "        if br['fund_score'] >= 6:\n",
    "            reasons_more.append(\"Fundamentals show positive indicators.\")\n",
    "        else:\n",
    "            reasons_less.append(\"Fundamentals are weak/moderate.\")\n",
    "        if \"sme\" in str(c.get(\"category\",\"\")).lower():\n",
    "            reasons_less.append(\"SME IPO: higher risk & lower liquidity ‚Äî allocate small exposure.\")\n",
    "        explain[a[\"ipo\"]] = {\"reasons_more\": reasons_more, \"reasons_less\": reasons_less, \"breakdown\": br}\n",
    "    return explain\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main():\n",
    "    print(\"üìä IPO Allocator ‚Äî Full explainable mode\\n\")\n",
    "    try:\n",
    "        budget = float(input(\"Enter total budget (‚Çπ): \").strip())\n",
    "        hold_date = datetime.strptime(input(\"Enter hold-until date (YYYY-MM-DD): \").strip(), \"%Y-%m-%d\").date()\n",
    "    except Exception as e:\n",
    "        print(\"Invalid input:\", e)\n",
    "        return\n",
    "\n",
    "    ipos_by_name, scored = load_data()\n",
    "    candidates = build_candidates(ipos_by_name, scored, hold_date)\n",
    "    if not candidates:\n",
    "        print(\"No eligible IPOs (score >=5 & within hold date). Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(f\"‚úÖ Found {len(candidates)} eligible IPOs:\\n\")\n",
    "    for c in candidates:\n",
    "        print(f\"‚Ä¢ {c['ipo']} | {c['category']} | Composite {c['composite']} | Min ‚Çπ{int(c['min_invest'])} | Retail {c['breakdown']['retail_quota_pct']}%\")\n",
    "\n",
    "    # Try MILP; if not possible or leftover too high, fallback to improved greedy that aggressively consumes budget\n",
    "    allocation, remaining = allocate_balanced(candidates, budget)\n",
    "    if allocation is None:\n",
    "        print(\"‚ö†Ô∏è PuLP not installed or failed ‚Äî using improved greedy filler.\")\n",
    "        allocation, remaining = greedy_fill_full(candidates, budget)\n",
    "    else:\n",
    "        # if remaining is too large ( > 1% budget ), try aggressive fill to reduce leftover\n",
    "        if remaining > 0.01 * budget:\n",
    "            g_alloc, g_rem = greedy_fill_full(candidates, budget)\n",
    "            # pick one with smaller leftover; if tie, pick one with larger total composite*lots\n",
    "            def used(a): return sum(x[\"invested\"] for x in a)\n",
    "            if (budget - g_rem) > (budget - remaining):\n",
    "                allocation, remaining = g_alloc, g_rem\n",
    "\n",
    "    total_invested = sum(a[\"invested\"] for a in allocation)\n",
    "    print(\"\\nüìà Final Allocation Plan:\")\n",
    "    for a in allocation:\n",
    "        print(f\"  - {a['ipo']}: ‚Çπ{int(a['invested'])} ({a['lots']} lots) | min_unit=‚Çπ{int(a['min_invest'])} | score {a['composite']}\")\n",
    "    print(f\"\\nüíµ Total Invested: ‚Çπ{int(total_invested)}\")\n",
    "    print(f\"üí§ Remaining: ‚Çπ{int(remaining)}\")\n",
    "\n",
    "    # explain\n",
    "    candidates_dict = {c[\"ipo\"]: c for c in candidates}\n",
    "    explain = explain_allocation(allocation, candidates_dict)\n",
    "\n",
    "    print(\"\\n--- Explainability & Formulas ---\")\n",
    "    print(\"\\nAlgorithm summary:\")\n",
    "    print(\"  - We compute a composite score per IPO combining:\")\n",
    "    print(\"      composite = 0.30*base_score + 0.25*rq_score + 0.20*fund_score + 0.15*(gmp_strength/10) + 0.10*sentiment_score\")\n",
    "    print(\"    where rq_score = min(retail_pct/10,1)*10 (normalized 0-10).\")\n",
    "    print(\"  - Primary solver: MILP (PuLP) maximizing sum(composite * lots) minus DIVERSIFICATION_WEIGHT * sum(lots^2).\")\n",
    "    print(\"  - Fallback: improved greedy that:\")\n",
    "    print(\"      1) gives 1 lot to each top candidate by composite/unit if affordable,\")\n",
    "    print(\"      2) repeatedly fills top K candidates (round-robin) to use leftover,\")\n",
    "    print(\"      3) finally uses any remaining budget on best composite/unit candidate.\")\n",
    "    print(\"  - Unit = min_invest (usually lot * issue price or ‚Çπ15k for mainboard fallback).\")\n",
    "    print(\"  - We skip any IPO with composite < 5 per your instruction.\\n\")\n",
    "\n",
    "    print(\"Parameters used:\")\n",
    "    print(f\"  - MIN_INVEST_MAINBOARD = {MIN_INVEST_MAINBOARD}\")\n",
    "    print(f\"  - DEFAULT_MAX_LOTS_PER_IPO = {DEFAULT_MAX_LOTS_PER_IPO}\")\n",
    "    print(f\"  - DIVERSIFICATION_WEIGHT = {DIVERSIFICATION_WEIGHT}\")\n",
    "    print(f\"  - TOP_FILL_K = {TOP_FILL_K}\\n\")\n",
    "\n",
    "    print(\"Per-IPO reasons (why more / why less):\")\n",
    "    for ipo, info in explain.items():\n",
    "        print(f\"\\nüîé {ipo}\")\n",
    "        br = info[\"breakdown\"]\n",
    "        print(f\"  Breakdown: base={br['base_score']}, retail%={br['retail_quota_pct']}%, rq_score={br['rq_score']}, fund={br['fund_score']}, sentiment={br['sentiment_score']}, gmp_str%={br['gmp_strength_pct']}\")\n",
    "        if info[\"reasons_more\"]:\n",
    "            print(\"  Reasons to invest more:\")\n",
    "            for r in info[\"reasons_more\"]:\n",
    "                print(\"   -\", r)\n",
    "        if info[\"reasons_less\"]:\n",
    "            print(\"  Reasons to be cautious:\")\n",
    "            for r in info[\"reasons_less\"]:\n",
    "                print(\"   -\", r)\n",
    "\n",
    "    # persist recommendation (sanitize dates)\n",
    "    rec = {\n",
    "        \"created_at\": datetime.utcnow().isoformat(),\n",
    "        \"budget\": budget,\n",
    "        \"hold_until\": hold_date.isoformat(),\n",
    "        \"allocation\": allocation,\n",
    "        \"explain\": explain,\n",
    "        \"total_invested\": total_invested,\n",
    "        \"leftover\": remaining\n",
    "    }\n",
    "    rec = sanitize_for_mongo(rec)\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    client[DB_NAME][COL_RECOMMEND].insert_one(rec)\n",
    "    client.close()\n",
    "    print(\"\\n‚úÖ Saved recommendation to MongoDB (collection:\", COL_RECOMMEND, \")\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
