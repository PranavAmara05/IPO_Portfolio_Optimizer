{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7232aebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| IPO                       | Category   | GMP_InvestorGain | GMP_IPOWatch | Issue_Price      | Open_Date   | Close_Date  | GMP_Diff |\n",
      "|---------------------------|------------|------------------|--------------|------------------|-------------|-------------|----------|\n",
      "| Mahamaya Lifesciences     | SME        | 18               | 15           | ‚Çπ108 ‚Äì ‚Çπ114      | 2025-11-11  | 2025-11-13  | 3        |\n",
      "| Workmates Core2Cloud      | SME        | 22               | 20           | ‚Çπ200 ‚Äì ‚Çπ204      | 2025-11-11  | 2025-11-13  | 2        |\n",
      "| PhysicsWallah             | Mainboard  | 35               | 30           | ‚Çπ103 ‚Äì ‚Çπ109      | 2025-11-11  | 2025-11-13  | 5        |\n",
      "| Emmvee Photovoltaic Power | Mainboard  | 40               | 38           | ‚Çπ206 ‚Äì ‚Çπ217      | 2025-11-11  | 2025-11-13  | 2        |\n",
      "| Tenneco Clean Air         | Mainboard  | 45               | 42           | ‚Çπ378 ‚Äì ‚Çπ397      | 2025-11-12  | 2025-11-14  | 3        |\n",
      "| Shining Tools             | SME        | 12               | 10           | ‚Çπ114             | 2025-11-07  | 2025-11-11  | 2        |\n",
      "| Curis Lifesciences        | SME        | 0                | 0            | ‚Çπ120 ‚Äì ‚Çπ128      | 2025-11-07  | 2025-11-11  | 0        |\n",
      "| Finbud Financial          | SME        | 0                | 0            | ‚Çπ140 ‚Äì ‚Çπ142      | 2025-11-06  | 2025-11-10  | 0        |\n",
      "| Shreeji Global FMCG       | SME        | 8                | 7            | ‚Çπ120 ‚Äì ‚Çπ125      | 2025-11-04  | 2025-11-07  | 1        |\n",
      "\n",
      "‚úÖ Saved latest IPOs to latest_ipo_comparison.md\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "# URLs\n",
    "ipowatch_url = 'https://ipowatch.in/ipo-grey-market-premium-latest-ipo-gmp/'\n",
    "investorgain_url = 'https://www.investorgain.com/report/live-ipo-gmp/331/'\n",
    "\n",
    "# --- Fetch HTML ---\n",
    "def fetch_html(url, limit=15000):  # smaller limit -> top section only (latest IPOs)\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=20)\n",
    "        resp.raise_for_status()\n",
    "        html = re.sub(r'\\s+', ' ', resp.text)\n",
    "        return html[:limit]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to fetch {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "ipowatch_html = fetch_html(ipowatch_url)\n",
    "investorgain_html = fetch_html(investorgain_url)\n",
    "\n",
    "# --- Enhanced Prompt ---\n",
    "prompt = f\"\"\"\n",
    "You are a financial data extractor.\n",
    "\n",
    "Extract **only the current and upcoming IPOs** (ignore old or archived ones) from the two HTML pages below.\n",
    "Focus on IPOs mentioned near the top of the page (recent issues).\n",
    "\n",
    "Output a **Markdown table** with the exact columns:\n",
    "\n",
    "| IPO | Category | GMP_InvestorGain | GMP_IPOWatch | Issue_Price | Open_Date | Close_Date | GMP_Diff |\n",
    "\n",
    "Rules:\n",
    "- GMP_Diff = GMP_InvestorGain - GMP_IPOWatch\n",
    "- If GMP is missing, assume 0.\n",
    "- Only include IPOs that are currently open, recently closed, or upcoming.\n",
    "- Ignore historical performance tables or 2023 data.\n",
    "- Sort IPOs by **Open_Date descending (newest first)**.\n",
    "- Output table only. No explanations, notes, or extra text.\n",
    "\n",
    "### IPOWatch HTML (latest section only):\n",
    "{ipowatch_html}\n",
    "\n",
    "### InvestorGain HTML (latest section only):\n",
    "{investorgain_html}\n",
    "\"\"\"\n",
    "\n",
    "# --- Send to Perplexity API ---\n",
    "api_url = \"https://api.perplexity.ai/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer 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\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "payload = {\n",
    "    \"model\": \"sonar-pro\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"max_tokens\": 3000,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a precise data extraction agent.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# --- Handle Request ---\n",
    "try:\n",
    "    response = requests.post(api_url, headers=headers, json=payload, timeout=60)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    content = result.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "\n",
    "    # Extract table safely\n",
    "    match = re.search(r\"(\\|.+\\|[\\s\\S]*)\", content)\n",
    "    if match:\n",
    "        table = match.group(1).strip()\n",
    "        with open(\"latest_ipo_comparison.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(table)\n",
    "        print(table)\n",
    "        print(\"\\n‚úÖ Saved latest IPOs to latest_ipo_comparison.md\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No table found. Raw output:\")\n",
    "        print(content)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "525c0c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Normalized IPO entries: 9\n",
      "‚úÖ Inserted 0, Updated 9 IPO records in MongoDB.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import parser as dateparse\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "# -----------------------------\n",
    "\n",
    "# ---------- Utility Functions ----------\n",
    "def markdown_table_to_df(table_md: str) -> pd.DataFrame:\n",
    "    \"\"\"Convert a GitHub-style Markdown table into a pandas DataFrame.\"\"\"\n",
    "    lines = [ln.strip() for ln in table_md.splitlines() if ln.strip()]\n",
    "    lines = [ln for ln in lines if ln.startswith(\"|\")]\n",
    "    if len(lines) < 2:\n",
    "        raise ValueError(\"Invalid markdown table format.\")\n",
    "    header = [h.strip() for h in lines[0].strip(\"|\").split(\"|\")]\n",
    "    rows = []\n",
    "    for ln in lines[2:]:\n",
    "        cols = [c.strip() for c in ln.strip(\"|\").split(\"|\")]\n",
    "        if len(cols) < len(header):\n",
    "            cols += [\"\"] * (len(header) - len(cols))\n",
    "        rows.append(cols)\n",
    "    df = pd.DataFrame(rows, columns=header)\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_float(value):\n",
    "    \"\"\"Extract first numeric float value from a string like ‚Çπ123 or '5.5%'.\"\"\"\n",
    "    if not value or str(value).strip() in [\"-\", \"‚Äî\", \"None\"]:\n",
    "        return None\n",
    "    try:\n",
    "        match = re.search(r\"(-?\\d+(\\.\\d+)?)\", str(value).replace(\",\", \"\"))\n",
    "        return float(match.group(1)) if match else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_issue_price(price_str):\n",
    "    \"\"\"Extract range or single numeric price.\"\"\"\n",
    "    if not price_str:\n",
    "        return None\n",
    "    s = str(price_str).replace(\"‚Çπ\", \"\").replace(\",\", \"\").strip()\n",
    "    if \"-\" in s:\n",
    "        parts = re.findall(r\"\\d+\\.?\\d*\", s)\n",
    "        if len(parts) >= 2:\n",
    "            low, high = float(parts[0]), float(parts[1])\n",
    "            return {\"min\": low, \"max\": high, \"avg\": (low + high) / 2}\n",
    "    num = parse_float(s)\n",
    "    if num is not None:\n",
    "        return {\"min\": num, \"max\": num, \"avg\": num}\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Normalize dates to ISO format (YYYY-MM-DD).\"\"\"\n",
    "    if not date_str or date_str.strip() == \"\":\n",
    "        return None\n",
    "    try:\n",
    "        d = dateparse.parse(date_str, fuzzy=True)\n",
    "        return d.date().isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_mongo_collection(uri, db_name, collection):\n",
    "    client = MongoClient(uri, serverSelectionTimeoutMS=5000)\n",
    "    db = client[db_name]\n",
    "    return db[collection]\n",
    "\n",
    "\n",
    "# ---------- Core Processing ----------\n",
    "def normalize_ipo_table(table_md: str) -> pd.DataFrame:\n",
    "    \"\"\"Parse markdown table, clean and normalize IPO data.\"\"\"\n",
    "    df = markdown_table_to_df(table_md)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # Ensure all expected columns exist\n",
    "    expected_cols = [\n",
    "        \"IPO\", \"Category\", \"GMP_InvestorGain\", \"GMP_IPOWatch\",\n",
    "        \"Issue_Price\", \"Open_Date\", \"Close_Date\", \"GMP_Diff\"\n",
    "    ]\n",
    "    for col in expected_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "    # Clean numeric and date columns\n",
    "    df[\"GMP_InvestorGain_num\"] = df[\"GMP_InvestorGain\"].apply(parse_float)\n",
    "    df[\"GMP_IPOWatch_num\"] = df[\"GMP_IPOWatch\"].apply(parse_float)\n",
    "\n",
    "    # If GMP_Diff missing or invalid, recompute it\n",
    "    def compute_diff(row):\n",
    "        a, b = row[\"GMP_InvestorGain_num\"], row[\"GMP_IPOWatch_num\"]\n",
    "        return (a or 0) - (b or 0)\n",
    "\n",
    "    df[\"GMP_Diff_num\"] = [\n",
    "        parse_float(x) if parse_float(x) is not None else compute_diff(r)\n",
    "        for x, r in zip(df[\"GMP_Diff\"], df.to_dict(orient=\"records\"))\n",
    "    ]\n",
    "\n",
    "    df[\"Issue_Price_struct\"] = df[\"Issue_Price\"].apply(clean_issue_price)\n",
    "    df[\"Open_Date_iso\"] = df[\"Open_Date\"].apply(parse_date)\n",
    "    df[\"Close_Date_iso\"] = df[\"Close_Date\"].apply(parse_date)\n",
    "\n",
    "    # Construct normalized structure\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        rec = {\n",
    "            \"ipo\": row[\"IPO\"],\n",
    "            \"category\": row[\"Category\"],\n",
    "            \"gmp_investorgain\": row[\"GMP_InvestorGain_num\"],\n",
    "            \"gmp_ipowatch\": row[\"GMP_IPOWatch_num\"],\n",
    "            \"gmp_diff\": row[\"GMP_Diff_num\"],\n",
    "            \"issue_price\": row[\"Issue_Price_struct\"],\n",
    "            \"open_date\": row[\"Open_Date_iso\"],\n",
    "            \"close_date\": row[\"Close_Date_iso\"],\n",
    "            \"raw\": {\n",
    "                \"GMP_InvestorGain\": row[\"GMP_InvestorGain\"],\n",
    "                \"GMP_IPOWatch\": row[\"GMP_IPOWatch\"],\n",
    "                \"Issue_Price\": row[\"Issue_Price\"],\n",
    "                \"GMP_Diff\": row[\"GMP_Diff\"],\n",
    "            },\n",
    "            \"inserted_at\": datetime.utcnow().isoformat()\n",
    "        }\n",
    "        records.append(rec)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "def insert_to_mongodb(df: pd.DataFrame):\n",
    "    \"\"\"Insert or update IPO records in MongoDB.\"\"\"\n",
    "    collection = get_mongo_collection(MONGO_URI, DB_NAME, COL_IPOS)\n",
    "    inserted, updated = 0, 0\n",
    "    for _, row in df.iterrows():\n",
    "        key = {\"ipo\": row[\"ipo\"], \"open_date\": row[\"open_date\"]}\n",
    "        existing = collection.find_one(key)\n",
    "        if existing:\n",
    "            collection.update_one(key, {\"$set\": row.to_dict()})\n",
    "            updated += 1\n",
    "        else:\n",
    "            collection.insert_one(row.to_dict())\n",
    "            inserted += 1\n",
    "    print(f\"‚úÖ Inserted {inserted}, Updated {updated} IPO records in MongoDB.\")\n",
    "\n",
    "\n",
    "# ---------- Main Entry ----------\n",
    "if __name__ == \"__main__\":\n",
    "    md_path = \"latest_ipo_comparison.md\"\n",
    "    if not os.path.exists(md_path):\n",
    "        raise FileNotFoundError(\"‚ö†Ô∏è File latest_ipo_comparison.md not found. Run your LLM extractor first.\")\n",
    "    with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        md_content = f.read()\n",
    "\n",
    "    df_norm = normalize_ipo_table(md_content)\n",
    "    print(\"üßæ Normalized IPO entries:\", len(df_norm))\n",
    "    insert_to_mongodb(df_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1748d594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Found 10 IPO records in MongoDB\n",
      "\n",
      "üîç Processing: PhysicsWallah\n",
      "üåê https://ipowatch.in/physicswallah-ipo-date-review-price-allotment-details/\n",
      "‚úÖ Saved extracted data for PhysicsWallah ‚Üí ipo_details\\physicswallah_details.md\n",
      "\n",
      "üîç Processing: Emmvee Photovoltaic Power\n",
      "üåê https://ipowatch.in/emmvee-photovoltaic-power-ipo-date-review-price-allotment-details/\n",
      "‚ö†Ô∏è Failed to fetch https://ipowatch.in/emmvee-photovoltaic-power-ipo-date-review-price-allotment-details/: 404 Client Error: Not Found for url: https://ipowatch.in/emmvee-photovoltaic-power-ipo-date-review-price-allotment-details/\n",
      "\n",
      "üîç Processing: Tenneco Clean Air India\n",
      "üåê https://ipowatch.in/tenneco-clean-air-india-ipo-date-review-price-allotment-details/\n",
      "‚ö†Ô∏è Failed to fetch https://ipowatch.in/tenneco-clean-air-india-ipo-date-review-price-allotment-details/: 404 Client Error: Not Found for url: https://ipowatch.in/tenneco-clean-air-india-ipo-date-review-price-allotment-details/\n",
      "\n",
      "üîç Processing: Mahamaya Lifesciences\n",
      "üåê https://ipowatch.in/mahamaya-lifesciences-ipo-date-review-price-allotment-details/\n",
      "‚úÖ Saved extracted data for Mahamaya Lifesciences ‚Üí ipo_details\\mahamaya-lifesciences_details.md\n",
      "\n",
      "üîç Processing: Workmates Core2Cloud\n",
      "üåê https://ipowatch.in/workmates-core2cloud-ipo-date-review-price-allotment-details/\n",
      "‚úÖ Saved extracted data for Workmates Core2Cloud ‚Üí ipo_details\\workmates-core2cloud_details.md\n",
      "\n",
      "üîç Processing: Tenneco Clean Air\n",
      "üåê https://ipowatch.in/tenneco-clean-air-ipo-date-review-price-allotment-details/\n",
      "‚ö†Ô∏è Failed to fetch https://ipowatch.in/tenneco-clean-air-ipo-date-review-price-allotment-details/: 404 Client Error: Not Found for url: https://ipowatch.in/tenneco-clean-air-ipo-date-review-price-allotment-details/\n",
      "\n",
      "üîç Processing: Shining Tools\n",
      "üåê https://ipowatch.in/shining-tools-ipo-date-review-price-allotment-details/\n",
      "‚úÖ Saved extracted data for Shining Tools ‚Üí ipo_details\\shining-tools_details.md\n",
      "\n",
      "üîç Processing: Curis Lifesciences\n",
      "üåê https://ipowatch.in/curis-lifesciences-ipo-date-review-price-allotment-details/\n",
      "‚úÖ Saved extracted data for Curis Lifesciences ‚Üí ipo_details\\curis-lifesciences_details.md\n",
      "\n",
      "üîç Processing: Finbud Financial\n",
      "üåê https://ipowatch.in/finbud-financial-ipo-date-review-price-allotment-details/\n",
      "‚ö†Ô∏è Failed to fetch https://ipowatch.in/finbud-financial-ipo-date-review-price-allotment-details/: 404 Client Error: Not Found for url: https://ipowatch.in/finbud-financial-ipo-date-review-price-allotment-details/\n",
      "\n",
      "üîç Processing: Shreeji Global FMCG\n",
      "üåê https://ipowatch.in/shreeji-global-fmcg-ipo-date-review-price-allotment-details/\n",
      "‚úÖ Saved extracted data for Shreeji Global FMCG ‚Üí ipo_details\\shreeji-global-fmcg_details.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from time import sleep\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "OUTPUT_DIR = \"ipo_details\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Perplexity API Config\n",
    "PPLX_API_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "PPLX_API_KEY = os.getenv(\"PPLX_API_KEY\", \"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\")  # <-- put your key here\n",
    "MODEL_NAME = \"sonar-pro\"\n",
    "# -------------------------------------------\n",
    "\n",
    "\n",
    "def get_mongo_collection(uri, db_name, collection):\n",
    "    client = MongoClient(uri, serverSelectionTimeoutMS=5000)\n",
    "    db = client[db_name]\n",
    "    return db[collection]\n",
    "\n",
    "\n",
    "def fetch_html(url, limit=80000):\n",
    "    \"\"\"Fetch the IPO HTML page with truncation.\"\"\"\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=30, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        resp.raise_for_status()\n",
    "        html = re.sub(r\"\\s+\", \" \", resp.text)\n",
    "        return html[:limit]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to fetch {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def generate_prompt(ipo_name, html):\n",
    "    \"\"\"Construct prompt for Perplexity extraction.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a financial data extraction model.\n",
    "\n",
    "Extract the following 13 fields from the IPO details page HTML provided below.\n",
    "\n",
    "Output as a **Markdown table** with these exact columns (one row only):\n",
    "\n",
    "| IPO | Price Band | Issue Size | Issue Type | Listing Exchanges | IPO Dates | Market Lot & Amounts | Investor Quota Split | Anchor Details | Promoter Holdings (Pre/Post) | Financial Performance (FY23‚ÄìFY25) | Valuation Ratios (EPS, ROE, ROCE, D/E, NAV) | Lead Managers & Registrar | Company Overview | Peer Comparison |\n",
    "\n",
    "Rules:\n",
    "- Extract exact numeric and date values from the HTML.\n",
    "- Keep it concise and clean (no commentary).\n",
    "- If a value is missing, leave the cell blank.\n",
    "- All data must come from the provided HTML only.\n",
    "\n",
    "### HTML for {ipo_name}:\n",
    "{html}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def call_perplexity(prompt):\n",
    "    \"\"\"Send HTML prompt to Perplexity API.\"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PPLX_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 4000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise structured data extractor for IPO information.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        resp = requests.post(PPLX_API_URL, headers=headers, json=payload, timeout=90)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        content = data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "        return content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def extract_table(markdown_text):\n",
    "    \"\"\"Extract table markdown only.\"\"\"\n",
    "    match = re.search(r\"(\\|.+\\|[\\s\\S]*)\", markdown_text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def process_all_ipos():\n",
    "    \"\"\"Iterate through MongoDB IPOs, fetch IPOWatch page, call Perplexity.\"\"\"\n",
    "    collection = get_mongo_collection(MONGO_URI, DB_NAME, COL_IPOS)\n",
    "    ipos = list(collection.find({}))\n",
    "    print(f\"üìä Found {len(ipos)} IPO records in MongoDB\")\n",
    "\n",
    "    for ipo in ipos:\n",
    "        name = ipo.get(\"ipo\", \"\").strip()\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        # Create IPOWatch URL (format-safe)\n",
    "        slug = name.lower().replace(\" \", \"-\")\n",
    "        url = f\"https://ipowatch.in/{slug}-ipo-date-review-price-allotment-details/\"\n",
    "        print(f\"\\nüîç Processing: {name}\")\n",
    "        print(f\"üåê {url}\")\n",
    "\n",
    "        html = fetch_html(url)\n",
    "        if not html:\n",
    "            continue\n",
    "\n",
    "        prompt = generate_prompt(name, html)\n",
    "        result = call_perplexity(prompt)\n",
    "        table = extract_table(result)\n",
    "\n",
    "        if table:\n",
    "            out_path = os.path.join(OUTPUT_DIR, f\"{slug}_details.md\")\n",
    "            with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(table)\n",
    "            print(f\"‚úÖ Saved extracted data for {name} ‚Üí {out_path}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No table extracted for {name}\")\n",
    "\n",
    "        # Sleep between API calls (to respect rate limits)\n",
    "        sleep(3)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_ipos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb866d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Need to re-extract/enrich 10 IPOs ‚Äî running with 4 workers...\n",
      "\n",
      "üìä Extraction Summary:\n",
      "‚û°Ô∏è Finbud Financial: ok\n",
      "‚û°Ô∏è Shreeji Global FMCG: ok\n",
      "‚û°Ô∏è Tenneco Clean Air India: ok\n",
      "‚û°Ô∏è Mahamaya Lifesciences: ok\n",
      "‚û°Ô∏è Tenneco Clean Air: ok\n",
      "‚û°Ô∏è Curis Lifesciences: ok\n",
      "‚û°Ô∏è PhysicsWallah: ok\n",
      "‚û°Ô∏è Emmvee Photovoltaic Power: ok\n",
      "‚û°Ô∏è Shining Tools: ok\n",
      "‚û°Ô∏è Workmates Core2Cloud: ok\n",
      "\n",
      "üèÅ Done ‚Äî Spark stopped.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import findspark\n",
    "from typing import Optional\n",
    "\n",
    "# ---------- ENV ----------\n",
    "findspark.init()\n",
    "python_path = r\"C:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = python_path\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = python_path\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"C:/spark-temp\"\n",
    "os.makedirs(\"C:/spark-temp\", exist_ok=True)\n",
    "\n",
    "if SparkContext._active_spark_context:\n",
    "    SparkContext._active_spark_context.stop()\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "\n",
    "PPLX_API_KEY = os.getenv(\"PPLX_API_KEY\", \"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\")\n",
    "PPLX_API_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "MODEL_NAME = \"sonar-pro\"\n",
    "\n",
    "SPARK_PARALLELISM = int(os.getenv(\"SPARK_PARALLELISM\", \"4\"))\n",
    "API_DELAY = float(os.getenv(\"API_DELAY\", \"1.5\"))  # throttle to avoid rate limits\n",
    "FETCH_RETRIES = 3\n",
    "FETCH_DELAY = 2  # seconds backoff\n",
    "\n",
    "# Which fields must be present (your 15 fields + metadata)\n",
    "REQUIRED_FIELDS = [\n",
    "    \"Price Band\", \"Issue Size\", \"Issue Type\", \"Listing Exchanges\", \"IPO Dates\",\n",
    "    \"Market Lot & Amounts\", \"Investor Quota Split\", \"Anchor Details\",\n",
    "    \"Promoter Holdings (Pre/Post)\", \"Financial Performance (FY23‚ÄìFY25)\",\n",
    "    \"Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)\", \"Lead Managers & Registrar\",\n",
    "    \"Company Overview\", \"Peer Comparison\", \"ipo\"\n",
    "]\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def make_slug_candidates(name: str):\n",
    "    \"\"\"Return multiple slug variants to try on IPOWatch.\"\"\"\n",
    "    toks = re.findall(r\"[A-Za-z0-9]+\", name.lower())\n",
    "    candidates = []\n",
    "    if toks:\n",
    "        # first two words\n",
    "        candidates.append(\"-\".join(toks[:2]))\n",
    "        # first three words\n",
    "        if len(toks) >= 3:\n",
    "            candidates.append(\"-\".join(toks[:3]))\n",
    "        # entire name as slug (trim to first 6)\n",
    "        candidates.append(\"-\".join(toks[:6]))\n",
    "    # add safe fallback: name with hyphens\n",
    "    candidates.append(\"-\".join(toks))\n",
    "    return list(dict.fromkeys([c for c in candidates if c]))  # unique preserve order\n",
    "\n",
    "def fetch_html_try(url: str, retries=FETCH_RETRIES, delay=FETCH_DELAY) -> Optional[str]:\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (compatible; IPOBot/1.0)\"}\n",
    "    for attempt in range(1, retries+1):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=25, headers=headers, allow_redirects=True)\n",
    "            status = r.status_code\n",
    "            if status == 200 and r.text:\n",
    "                return re.sub(r\"\\s+\", \" \", r.text)[:120000]  # keep top content\n",
    "            else:\n",
    "                # non-200 often means not found; don't retry too many times but still backoff a little\n",
    "                time.sleep(delay * attempt)\n",
    "        except Exception as e:\n",
    "            time.sleep(delay * attempt)\n",
    "    return None\n",
    "\n",
    "def fetch_ipowatch_html_for(ipo_name: str):\n",
    "    \"\"\"Try several URL patterns and site search to get the IPOWatch HTML.\"\"\"\n",
    "    base = \"https://ipowatch.in\"\n",
    "    # Try candidate slugs\n",
    "    for slug in make_slug_candidates(ipo_name):\n",
    "        url1 = f\"{base}/{slug}-ipo-date-review-price-allotment-details/\"\n",
    "        html = fetch_html_try(url1)\n",
    "        if html:\n",
    "            return html, url1\n",
    "        # try simple slug\n",
    "        url2 = f\"{base}/{slug}/\"\n",
    "        html = fetch_html_try(url2)\n",
    "        if html:\n",
    "            return html, url2\n",
    "    # fallback: site search (ipowatch uses ?s=)\n",
    "    try:\n",
    "        search_url = f\"{base}/?s={requests.utils.quote(ipo_name)}\"\n",
    "        html = fetch_html_try(search_url)\n",
    "        if html:\n",
    "            return html, search_url\n",
    "    except:\n",
    "        pass\n",
    "    return None, None\n",
    "\n",
    "def call_perplexity(prompt: str) -> Optional[str]:\n",
    "    headers = {\"Authorization\": f\"Bearer {PPLX_API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 3000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise IPO data extraction assistant. Output only a single-row Markdown table with the requested columns.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(PPLX_API_URL, headers=headers, json=payload, timeout=90)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        return data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def extract_table(text: str) -> Optional[str]:\n",
    "    if not text:\n",
    "        return None\n",
    "    m = re.search(r\"(\\|.+\\|[\\s\\S]*)\", text)\n",
    "    return m.group(1).strip() if m else None\n",
    "\n",
    "def parse_markdown_table(md_text: str) -> dict:\n",
    "    \"\"\"Parse a single-row markdown table into a dict.\"\"\"\n",
    "    lines = [ln.strip() for ln in md_text.splitlines() if ln.strip()]\n",
    "    if len(lines) < 3:\n",
    "        return {}\n",
    "    headers = [h.strip() for h in lines[0].strip(\"|\").split(\"|\")]\n",
    "    values = [v.strip() for v in lines[2].strip(\"|\").split(\"|\")]\n",
    "    # pad values if shorter\n",
    "    if len(values) < len(headers):\n",
    "        values += [\"\"] * (len(headers) - len(values))\n",
    "    return dict(zip(headers, values))\n",
    "\n",
    "def count_present_fields(extracted: dict):\n",
    "    \"\"\"Count how many required fields are present and non-empty.\"\"\"\n",
    "    if not extracted:\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for k in REQUIRED_FIELDS:\n",
    "        if k == \"ipo\":\n",
    "            # 'ipo' mandatory as a sanity check\n",
    "            if extracted.get(\"ipo\"):\n",
    "                cnt += 1\n",
    "        else:\n",
    "            v = extracted.get(k)\n",
    "            if v is not None and str(v).strip() != \"\":\n",
    "                cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def mongo_get_all_ipos():\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    coll = client[DB_NAME][COL_IPOS]\n",
    "    docs = list(coll.find({}, {\"ipo\": 1, \"extracted_fields\": 1}))\n",
    "    client.close()\n",
    "    return docs\n",
    "\n",
    "def mongo_update_partial(ipo_name: str, new_fields: dict, source_url: str, raw_md: str):\n",
    "    \"\"\"Merge new_fields into existing document's 'extracted_fields' and append to history.\"\"\"\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    coll = client[DB_NAME][COL_IPOS]\n",
    "    doc = coll.find_one({\"ipo\": ipo_name}) or {}\n",
    "    existing = doc.get(\"extracted_fields\") or {}\n",
    "    # Merge: prefer existing non-empty value, otherwise take new\n",
    "    merged = existing.copy()\n",
    "    for k, v in new_fields.items():\n",
    "        # if existing missing or empty, replace\n",
    "        if (k not in merged) or (merged.get(k) in [None, \"\", [], {}]):\n",
    "            merged[k] = v\n",
    "    # metadata\n",
    "    history_entry = {\n",
    "        \"extracted_at\": datetime.utcnow().isoformat(),\n",
    "        \"source_url\": source_url,\n",
    "        \"raw_markdown\": raw_md,\n",
    "        \"fields_added\": {k: v for k, v in new_fields.items() if (existing.get(k) in [None, \"\", {}, []])}\n",
    "    }\n",
    "    # update doc\n",
    "    coll.update_one({\"ipo\": ipo_name}, {\"$set\": {\"extracted_fields\": merged, \"last_extracted_at\": history_entry[\"extracted_at\"]}, \"$push\": {\"extraction_history\": history_entry}}, upsert=True)\n",
    "    client.close()\n",
    "\n",
    "# ---------- PROCESS ONE IPO ----------\n",
    "def process_ipo(name: str):\n",
    "    print(f\"\\nüîç Starting: {name}\")\n",
    "    # 1) fetch HTML (try many patterns)\n",
    "    html, url = fetch_ipowatch_html_for(name)\n",
    "    if not html:\n",
    "        print(f\"‚ö†Ô∏è Fetch failed for {name} (tried multiple slugs/search).\")\n",
    "        return {\"ipo\": name, \"status\": \"fetch_failed\"}\n",
    "\n",
    "    # 2) load existing extracted_fields to include in prompt (so model only fills missing)\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    coll = client[DB_NAME][COL_IPOS]\n",
    "    doc = coll.find_one({\"ipo\": name}) or {}\n",
    "    client.close()\n",
    "    existing = doc.get(\"extracted_fields\") or {}\n",
    "\n",
    "    # 3) Build a focused prompt: include list of missing fields and existing values\n",
    "    missing = [f for f in REQUIRED_FIELDS if not existing.get(f)]\n",
    "    # always include 'ipo' field in the table header\n",
    "    header_cols = REQUIRED_FIELDS.copy()\n",
    "\n",
    "    prompt_lines = [\n",
    "        \"You are an expert IPO data extractor. You will be given an HTML snippet (IPOWatch) and a list of existing extracted fields (may be partial).\",\n",
    "        f\"IPO name: {name}\",\n",
    "        \"\",\n",
    "        \"Existing extracted fields (only show values already present):\"\n",
    "    ]\n",
    "    if existing:\n",
    "        for k, v in existing.items():\n",
    "            prompt_lines.append(f\"- {k}: {v}\")\n",
    "    else:\n",
    "        prompt_lines.append(\"- (none)\")\n",
    "\n",
    "    prompt_lines += [\n",
    "        \"\",\n",
    "        f\"Please extract the following missing fields (fill blanks). Missing fields: {missing}\",\n",
    "        \"Output a single-row Markdown table with this exact header (in this order):\",\n",
    "        \"| \" + \" | \".join(header_cols) + \" |\",\n",
    "        \"\",\n",
    "        \"Rules:\",\n",
    "        \"- If a value already exists in 'Existing extracted fields', preserve it in the output.\",\n",
    "        \"- Only output the table (no commentary).\",\n",
    "        \"- Leave values blank where you cannot find them.\",\n",
    "        \"\",\n",
    "        \"HTML:\",\n",
    "        html[:90000]  # keep prompt bounded\n",
    "    ]\n",
    "\n",
    "    prompt = \"\\n\".join(prompt_lines)\n",
    "\n",
    "    # 4) call Perplexity\n",
    "    result_text = call_perplexity(prompt)\n",
    "    time.sleep(API_DELAY)\n",
    "    if not result_text:\n",
    "        print(f\"‚ö†Ô∏è API failed for {name}\")\n",
    "        return {\"ipo\": name, \"status\": \"api_failed\"}\n",
    "\n",
    "    table_md = extract_table(result_text)\n",
    "    if not table_md:\n",
    "        print(f\"‚ö†Ô∏è No table parsed from LLM output for {name}. Raw start:\\n{result_text[:400]}\")\n",
    "        return {\"ipo\": name, \"status\": \"no_table\", \"raw_snippet\": result_text[:400]}\n",
    "\n",
    "    parsed = parse_markdown_table(table_md)\n",
    "    # ensure 'ipo' key present\n",
    "    parsed[\"ipo\"] = parsed.get(\"ipo\", name)\n",
    "    # merge into mongo\n",
    "    mongo_update_partial(name, parsed, url, table_md)\n",
    "    print(f\"‚úÖ Updated {name} (added {len(parsed)} fields, merged).\")\n",
    "    return {\"ipo\": name, \"status\": \"ok\"}\n",
    "\n",
    "# ---------- DRIVER ----------\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .setMaster(f\"local[{SPARK_PARALLELISM}]\")\n",
    "    .setAppName(\"IPO-Fill-Missing-Fields\")\n",
    "    .set(\"spark.python.worker.reuse\", \"false\")\n",
    "    .set(\"spark.local.dir\", \"C:/spark-temp\")\n",
    ")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # fetch all IPO docs and compute completeness\n",
    "    docs = mongo_get_all_ipos()\n",
    "    candidates = []\n",
    "    for d in docs:\n",
    "        name = d.get(\"ipo\")\n",
    "        existing = d.get(\"extracted_fields\") or {}\n",
    "        present = count_present_fields(existing)\n",
    "        completeness = present / len(REQUIRED_FIELDS)\n",
    "        if completeness < 1.0:\n",
    "            candidates.append((name, present, completeness))\n",
    "    # sort by least-complete first\n",
    "    candidates = sorted(candidates, key=lambda x: (x[2], -x[1]))\n",
    "    ipo_names = [c[0] for c in candidates]\n",
    "\n",
    "    if not ipo_names:\n",
    "        print(\"‚úÖ All IPOs already complete (100%). Nothing to do.\")\n",
    "        sc.stop()\n",
    "        exit()\n",
    "\n",
    "    print(f\"üì° Need to re-extract/enrich {len(ipo_names)} IPOs ‚Äî running with {SPARK_PARALLELISM} workers...\")\n",
    "    rdd = sc.parallelize(ipo_names, min(len(ipo_names), SPARK_PARALLELISM))\n",
    "    results = rdd.map(process_ipo).collect()\n",
    "\n",
    "    print(\"\\nüìä Extraction Summary:\")\n",
    "    for res in results:\n",
    "        print(f\"‚û°Ô∏è {res['ipo']}: {res['status']}\")\n",
    "\n",
    "    sc.stop()\n",
    "    print(\"\\nüèÅ Done ‚Äî Spark stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f12fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Fetching IPO data from MongoDB...\n",
      "üîç Found 10 total IPO records.\n",
      "‚úÖ 6 IPOs scored and written to 'ipo_analysis'\n",
      "\n",
      "üìä Summary:\n",
      "Scored: 6\n",
      "Skipped: 4\n",
      "Skipped details:\n",
      " - Tenneco Clean Air India: missing_critical_data\n",
      " - Mahamaya Lifesciences: skip_few_fields(4)\n",
      " - Curis Lifesciences: skip_few_fields(4)\n",
      " - Finbud Financial: missing_critical_data\n",
      "\n",
      "üèÜ Top Recommendations:\n",
      " PhysicsWallah: 5.8/10 ‚Äî Moderate (GMP 33.02%)\n",
      " Emmvee Photovoltaic Power: 5.1/10 ‚Äî Moderate (GMP 18.91%)\n",
      " Workmates Core2Cloud: 4.9/10 ‚Äî Moderate (GMP 10.89%)\n",
      " Shining Tools: 4.9/10 ‚Äî Moderate (GMP 10.53%)\n",
      " Tenneco Clean Air: 4.7/10 ‚Äî Moderate (GMP 11.61%)\n",
      " Shreeji Global FMCG: 4.7/10 ‚Äî Moderate (GMP 6.53%)\n",
      "\n",
      "üèÅ Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import findspark\n",
    "\n",
    "# ---------- SPARK & ENV SETUP ----------\n",
    "findspark.init()\n",
    "PYTHON_PATH = r\"C:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = PYTHON_PATH\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = PYTHON_PATH\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"C:/spark-temp\"\n",
    "os.makedirs(\"C:/spark-temp\", exist_ok=True)\n",
    "\n",
    "if SparkContext._active_spark_context:\n",
    "    SparkContext._active_spark_context.stop()\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "COL_ANALYSIS = \"ipo_analysis\"\n",
    "\n",
    "SPARK_PARALLELISM = 4\n",
    "\n",
    "# ---------- SCORING WEIGHTS ----------\n",
    "W_GMP = 0.45\n",
    "W_PRICE = 0.20\n",
    "W_SIZE = 0.20\n",
    "W_EXPECT = 0.15\n",
    "\n",
    "# ---------- UTILITIES ----------\n",
    "def get_mongo_data():\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    data = list(client[DB_NAME][COL_IPOS].find({}))\n",
    "    client.close()\n",
    "    return data\n",
    "\n",
    "def write_results(results):\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    coll = client[DB_NAME][COL_ANALYSIS]\n",
    "    for rec in results:\n",
    "        coll.update_one({\"ipo\": rec[\"ipo\"]}, {\"$set\": rec}, upsert=True)\n",
    "    client.close()\n",
    "\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(str(x).replace(\"‚Çπ\", \"\").replace(\",\", \"\").strip())\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_issue_price(value):\n",
    "    \"\"\"Parse avg issue price\"\"\"\n",
    "    if isinstance(value, dict):\n",
    "        return value.get(\"avg\") or value.get(\"mid\") or value.get(\"min\")\n",
    "    if not value:\n",
    "        return None\n",
    "    nums = re.findall(r\"\\d+\\.?\\d*\", str(value))\n",
    "    if not nums:\n",
    "        return None\n",
    "    nums = [safe_float(x) for x in nums]\n",
    "    return sum(nums)/len(nums)\n",
    "\n",
    "def parse_issue_size(value):\n",
    "    if not value:\n",
    "        return None\n",
    "    s = str(value).lower().replace(\",\", \"\")\n",
    "    m = re.search(r\"(\\d+\\.?\\d*)\\s*(cr|crore|lakh|lac|mn|m|bn|b)?\", s)\n",
    "    if not m:\n",
    "        return None\n",
    "    num = float(m.group(1))\n",
    "    mult = (m.group(2) or \"\").lower()\n",
    "    if mult in [\"cr\", \"crore\"]:\n",
    "        return num * 1e7\n",
    "    if mult in [\"lakh\", \"lac\"]:\n",
    "        return num * 1e5\n",
    "    if mult in [\"mn\", \"m\"]:\n",
    "        return num * 1e6\n",
    "    if mult in [\"bn\", \"b\"]:\n",
    "        return num * 1e9\n",
    "    return num\n",
    "\n",
    "# ---------- SCORING ----------\n",
    "def compute_score(doc):\n",
    "    fields = doc.get(\"extracted_fields\", {}) or {}\n",
    "    ipo = doc.get(\"ipo\") or fields.get(\"IPO\")\n",
    "\n",
    "    # Skip IPOs with too few extracted fields\n",
    "    nonempty_fields = len([v for v in fields.values() if v not in [None, \"\", {}]])\n",
    "    if nonempty_fields < 5:\n",
    "        return {\"ipo\": ipo, \"status\": f\"skip_few_fields({nonempty_fields})\"}\n",
    "\n",
    "    # Try multiple fallbacks for GMP\n",
    "    gmp = safe_float(fields.get(\"GMP_InvestorGain\")) or safe_float(fields.get(\"GMP_IPOWatch\")) \\\n",
    "        or safe_float(doc.get(\"gmp_investorgain\")) or safe_float(doc.get(\"gmp_ipowatch\"))\n",
    "    issue_price = parse_issue_price(fields.get(\"Price Band\") or fields.get(\"Issue_Price\") or doc.get(\"issue_price\"))\n",
    "    issue_size = parse_issue_size(fields.get(\"Issue Size\") or fields.get(\"Issue_Size\") or doc.get(\"issue_size\"))\n",
    "\n",
    "    if not all([gmp, issue_price, issue_size]):\n",
    "        return {\"ipo\": ipo, \"status\": \"missing_critical_data\"}\n",
    "\n",
    "    # 1Ô∏è‚É£ GMP Score (relative to issue price)\n",
    "    gmp_pct = (gmp / issue_price) * 100\n",
    "    gmp_score = min(max(gmp_pct, 0), 100)\n",
    "\n",
    "    # 2Ô∏è‚É£ Price Score (retail affordability)\n",
    "    if issue_price < 100:\n",
    "        price_score = 90\n",
    "    elif issue_price < 500:\n",
    "        price_score = 80\n",
    "    elif issue_price < 1000:\n",
    "        price_score = 60\n",
    "    else:\n",
    "        price_score = 40\n",
    "\n",
    "    # 3Ô∏è‚É£ Size Score (mid-size preferred)\n",
    "    if issue_size < 1e8:\n",
    "        size_score = 40\n",
    "    elif issue_size < 1e9:\n",
    "        size_score = 70\n",
    "    elif issue_size < 5e9:\n",
    "        size_score = 90\n",
    "    else:\n",
    "        size_score = 60\n",
    "\n",
    "    # 4Ô∏è‚É£ Expected Listing Gain\n",
    "    expect_score = min(max(gmp_pct / 2 + 50, 0), 100)\n",
    "\n",
    "    # Weighted average\n",
    "    total = (\n",
    "        W_GMP * gmp_score +\n",
    "        W_PRICE * price_score +\n",
    "        W_SIZE * size_score +\n",
    "        W_EXPECT * expect_score\n",
    "    )\n",
    "\n",
    "    score = round((total / 100) * 9 + 1, 1)\n",
    "    verdict = \"Good\" if score >= 7 else \"Moderate\" if score >= 4 else \"Bad\"\n",
    "\n",
    "    return {\n",
    "        \"ipo\": ipo,\n",
    "        \"gmp\": gmp,\n",
    "        \"issue_price\": issue_price,\n",
    "        \"issue_size\": issue_size,\n",
    "        \"gmp_pct\": round(gmp_pct, 2),\n",
    "        \"score\": score,\n",
    "        \"verdict\": verdict,\n",
    "        \"scored_at\": datetime.utcnow().isoformat(),\n",
    "        \"components\": {\n",
    "            \"GMP\": gmp_score,\n",
    "            \"Price\": price_score,\n",
    "            \"Size\": size_score,\n",
    "            \"Expectation\": expect_score\n",
    "        },\n",
    "        \"status\": \"scored\"\n",
    "    }\n",
    "\n",
    "# ---------- SPARK SETUP ----------\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .setMaster(f\"local[{SPARK_PARALLELISM}]\")\n",
    "    .setAppName(\"IPO-Scoring-v2\")\n",
    "    .set(\"spark.local.dir\", \"C:/spark-temp\")\n",
    ")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üì° Fetching IPO data from MongoDB...\")\n",
    "    docs = get_mongo_data()\n",
    "    print(f\"üîç Found {len(docs)} total IPO records.\")\n",
    "\n",
    "    if not docs:\n",
    "        print(\"‚ö†Ô∏è No records found.\")\n",
    "        sc.stop()\n",
    "        exit()\n",
    "\n",
    "    rdd = sc.parallelize(docs, min(len(docs), SPARK_PARALLELISM))\n",
    "    results = rdd.map(compute_score).collect()\n",
    "    sc.stop()\n",
    "\n",
    "    scored = [r for r in results if r.get(\"status\") == \"scored\"]\n",
    "    skipped = [r for r in results if r.get(\"status\") != \"scored\"]\n",
    "\n",
    "    if scored:\n",
    "        write_results(scored)\n",
    "        print(f\"‚úÖ {len(scored)} IPOs scored and written to '{COL_ANALYSIS}'\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No IPOs scored (all skipped).\")\n",
    "\n",
    "    print(\"\\nüìä Summary:\")\n",
    "    print(\"Scored:\", len(scored))\n",
    "    print(\"Skipped:\", len(skipped))\n",
    "    if skipped:\n",
    "        print(\"Skipped details:\")\n",
    "        for s in skipped:\n",
    "            print(f\" - {s['ipo']}: {s['status']}\")\n",
    "\n",
    "    if scored:\n",
    "        print(\"\\nüèÜ Top Recommendations:\")\n",
    "        top = sorted(scored, key=lambda x: x[\"score\"], reverse=True)[:10]\n",
    "        for t in top:\n",
    "            print(f\" {t['ipo']}: {t['score']}/10 ‚Äî {t['verdict']} (GMP {t['gmp_pct']}%)\")\n",
    "\n",
    "    print(\"\\nüèÅ Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e9770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sample IPO record from MongoDB ('ipo_db.ipos'):\n",
      "\n",
      "{\n",
      "    \"_id\": {\n",
      "        \"$oid\": \"690f5be67ebcab56b4d5097a\"\n",
      "    },\n",
      "    \"ipo\": \"PhysicsWallah\",\n",
      "    \"category\": \"Mainboard\",\n",
      "    \"gmp_investorgain\": 35.0,\n",
      "    \"gmp_ipowatch\": 30.0,\n",
      "    \"gmp_diff\": 5.0,\n",
      "    \"issue_price\": {\n",
      "        \"min\": 103.0,\n",
      "        \"max\": 103.0,\n",
      "        \"avg\": 103.0\n",
      "    },\n",
      "    \"open_date\": \"2025-11-11\",\n",
      "    \"close_date\": \"2025-11-13\",\n",
      "    \"raw\": {\n",
      "        \"GMP_InvestorGain\": \"35\",\n",
      "        \"GMP_IPOWatch\": \"30\",\n",
      "        \"Issue_Price\": \"\\u20b9103 \\u2013 \\u20b9109\",\n",
      "        \"GMP_Diff\": \"5\"\n",
      "    },\n",
      "    \"inserted_at\": \"2025-11-08T15:05:12.990572\",\n",
      "    \"extracted_fields\": {\n",
      "        \"IPO\": \"PhysicsWallah Ltd.\",\n",
      "        \"Price Band\": \"\\u20b9103 to \\u20b9109\",\n",
      "        \"Issue Size\": \"\\u20b93,480 Crores\",\n",
      "        \"Issue Type\": \"Book Built Issue\",\n",
      "        \"Listing Exchanges\": \"BSE, NSE\",\n",
      "        \"IPO Dates\": \"Nov 11\\u201313, 2025 (Listing: Nov 18, 2025)\",\n",
      "        \"Market Lot & Amounts\": \"Min: 137 shares/\\u20b914,933; Max (Retail): 1,781 shares/\\u20b91,94,129; S-HNI: 1,918\\u20139,042 shares/\\u20b92,09,062\\u2013\\u20b99,85,578; B-HNI: 9,179 shares/\\u20b910,00,511\",\n",
      "        \"Investor Quota Split\": \"QIB: 75%, NII: 15%, Retail: 10%\",\n",
      "        \"Anchor Details\": \"Anchor bidding: Nov 10, 2025; Lock-in: 50% till Dec 14, 2025, 50% till Feb 12, 2026; Anchor list: [PDF], Size: [.] Cr.\",\n",
      "        \"Promoter Holdings (Pre/Post)\": \"Pre: 2,60,79,56,938 (81.64%); Post: 2,89,23,60,607 (-%)\",\n",
      "        \"Financial Performance (FY23\\u2013FY25)\": \"FY24: \\u20b92,015.35 Cr revenue, \\u20b91,131.13 Cr loss; FY25: \\u20b93,039.09 Cr revenue, \\u20b9243.26 Cr loss\",\n",
      "        \"Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)\": \"EPS: \\u20b9(0.86) (Basic); ROE: (12.50)%; ROCE: -%; D/E: \\u2013; NAV: \\u20b97.73\",\n",
      "        \"Lead Managers & Registrar\": \"Lead Managers: Kotak Mahindra Capital Co. Ltd., JP Morgan India Pvt. Ltd, Goldman Sachs (India) Securities Pvt. Ltd., Axial Capital Pvt. Ltd.; Registrar: MUFG Intime India Pvt.Ltd.\",\n",
      "        \"Company Overview\": \"Edtech company founded 2020, online/offline learning, 3.5M+ students, 8M+ YouTube subscribers, strong hybrid model\",\n",
      "        \"Peer Comparison\": \"There are no listed peers of the Company.\",\n",
      "        \"ipo\": \"PhysicsWallah\",\n",
      "        \"url\": \"https://ipowatch.in/physicswallah-ipo-date-review-price-allotment-details/\",\n",
      "        \"raw_markdown\": \"| IPO                | Price Band           | Issue Size         | Issue Type        | Listing Exchanges | IPO Dates                                   | Market Lot & Amounts                                                                                  | Investor Quota Split         | Anchor Details                                                                                                 | Promoter Holdings (Pre/Post) | Financial Performance (FY23\\u2013FY25)                                                                 | Valuation Ratios (EPS, ROE, ROCE, D/E, NAV) | Lead Managers & Registrar | Company Overview                                                                                                   | Peer Comparison |\\n|--------------------|---------------------|--------------------|-------------------|-------------------|---------------------------------------------|-------------------------------------------------------------------------------------------------------|------------------------------|------------------------------------------------------------------------------------------------------------------|------------------------------|------------------------------------------------------------------------------------------------------------------|---------------------------------------------|--------------------------|-------------------------------------------------------------------------------------------------------------------|------------------|\\n| PhysicsWallah Ltd. | \\u20b9103 to \\u20b9109        | \\u20b93,480 Crores      | Book Built Issue  | BSE, NSE          | Nov 11\\u201313, 2025 (Listing: Nov 18, 2025)    | Min: 137 shares/\\u20b914,933; Max (Retail): 1,781 shares/\\u20b91,94,129; S-HNI: 1,918\\u20139,042 shares/\\u20b92,09,062\\u2013\\u20b99,85,578; B-HNI: 9,179 shares/\\u20b910,00,511 | QIB: 75%, NII: 15%, Retail: 10% | Anchor bidding: Nov 10, 2025; Lock-in: 50% till Dec 14, 2025, 50% till Feb 12, 2026; Anchor list: [PDF], Size: [.] Cr. |                          | FY24: \\u20b92,015.35 Cr revenue, \\u20b91,131.13 Cr loss; FY25: \\u20b93,039.09 Cr revenue, \\u20b9243.26 Cr loss                |                                             |                          | Edtech company founded 2020, online/offline learning, 3.5M+ students, 8M+ YouTube subscribers, strong hybrid model |                  |\",\n",
      "        \"extracted_at\": \"2025-11-09T10:41:52.355186\"\n",
      "    },\n",
      "    \"extraction_history\": [\n",
      "        {\n",
      "            \"extracted_at\": \"2025-11-10T04:51:06.629729\",\n",
      "            \"source_url\": \"https://ipowatch.in/physicswallah-ipo-date-review-price-allotment-details/\",\n",
      "            \"raw_markdown\": \"| Price Band | Issue Size | Issue Type | Listing Exchanges | IPO Dates | Market Lot & Amounts | Investor Quota Split | Anchor Details | Promoter Holdings (Pre/Post) | Financial Performance (FY23\\u2013FY25) | Valuation Ratios (EPS, ROE, ROCE, D/E, NAV) | Lead Managers & Registrar | Company Overview | Peer Comparison | ipo |\\n|------------|------------|------------|-------------------|-----------|----------------------|----------------------|---------------|------------------------------|-----------------------------------|---------------------------------------------|--------------------------|------------------|------------------|-----|\\n| \\u20b9103 to \\u20b9109 | \\u20b93,480 Crores | Book Built Issue | BSE, NSE | Nov 11\\u201313, 2025 (Listing: Nov 18, 2025) | Min: 137 shares/\\u20b914,933; Max (Retail): 1,781 shares/\\u20b91,94,129; S-HNI: 1,918\\u20139,042 shares/\\u20b92,09,062\\u2013\\u20b99,85,578; B-HNI: 9,179 shares/\\u20b910,00,511 | QIB: 75%, NII: 15%, Retail: 10% | Anchor bidding: Nov 10, 2025; Lock-in: 50% till Dec 14, 2025, 50% till Feb 12, 2026; Anchor list: [PDF], Size: [.] Cr. | Pre: 2,60,79,56,938 (81.64%); Post: 2,89,23,60,607 (-%) | FY24: \\u20b92,015.35 Cr revenue, \\u20b91,131.13 Cr loss; FY25: \\u20b93,039.09 Cr revenue, \\u20b9243.26 Cr loss | EPS: \\u20b9(0.86) (Basic); ROE: (12.50)%; ROCE: -%; D/E: \\u2013; NAV: \\u20b97.73 | Lead Managers: Kotak Mahindra Capital Co. Ltd., JP Morgan India Pvt. Ltd, Goldman Sachs (India) Securities Pvt. Ltd., Axial Capital Pvt. Ltd.; Registrar: MUFG Intime India Pvt.Ltd. | Edtech company founded 2020, online/offline learning, 3.5M+ students, 8M+ YouTube subscribers, strong hybrid model | There are no listed peers of the Company. | PhysicsWallah |\",\n",
      "            \"fields_added\": {\n",
      "                \"Promoter Holdings (Pre/Post)\": \"Pre: 2,60,79,56,938 (81.64%); Post: 2,89,23,60,607 (-%)\",\n",
      "                \"Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)\": \"EPS: \\u20b9(0.86) (Basic); ROE: (12.50)%; ROCE: -%; D/E: \\u2013; NAV: \\u20b97.73\",\n",
      "                \"Lead Managers & Registrar\": \"Lead Managers: Kotak Mahindra Capital Co. Ltd., JP Morgan India Pvt. Ltd, Goldman Sachs (India) Securities Pvt. Ltd., Axial Capital Pvt. Ltd.; Registrar: MUFG Intime India Pvt.Ltd.\",\n",
      "                \"Peer Comparison\": \"There are no listed peers of the Company.\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"last_extracted_at\": \"2025-11-10T04:51:06.629729\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from bson import json_util\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "\n",
    "# ---------- CONNECT & FETCH ----------\n",
    "def print_one_ipo_sample():\n",
    "    try:\n",
    "        client = MongoClient(MONGO_URI)\n",
    "        db = client[DB_NAME]\n",
    "        col = db[COL_IPOS]\n",
    "\n",
    "        # Fetch one IPO record\n",
    "        doc = col.find_one()\n",
    "\n",
    "        if not doc:\n",
    "            print(\"‚ö†Ô∏è No records found in collection:\", COL_IPOS)\n",
    "            return\n",
    "\n",
    "        # Pretty-print JSON\n",
    "        print(\"‚úÖ Sample IPO record from MongoDB ('ipo_db.ipos'):\\n\")\n",
    "        print(json.dumps(doc, indent=4, default=json_util.default))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error:\", e)\n",
    "\n",
    "    finally:\n",
    "        client.close()\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "if __name__ == \"__main__\":\n",
    "    print_one_ipo_sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e21ebed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà IPO Portfolio Optimizer for Retail Investors\n",
      "\n",
      "\n",
      "‚úÖ Found 6 eligible IPOs:\n",
      "\n",
      "‚Ä¢ PhysicsWallah | Mainboard | Score: 5.8 | Min Invest: ‚Çπ15000 | Close: 2025-11-13\n",
      "‚Ä¢ Emmvee Photovoltaic Power | Mainboard | Score: 5.1 | Min Invest: ‚Çπ15000 | Close: 2025-11-13\n",
      "‚Ä¢ Workmates Core2Cloud | SME | Score: 4.9 | Min Invest: ‚Çπ244800 | Close: 2025-11-13\n",
      "‚Ä¢ Tenneco Clean Air | Mainboard | Score: 4.7 | Min Invest: ‚Çπ15000 | Close: 2025-11-14\n",
      "‚Ä¢ Shining Tools | SME | Score: 4.9 | Min Invest: ‚Çπ273600 | Close: 2025-11-11\n",
      "‚Ä¢ Shreeji Global FMCG | SME | Score: 4.7 | Min Invest: ‚Çπ250000 | Close: 2025-11-07\n",
      "\n",
      "üìä Final Allocation Plan:\n",
      "  - PhysicsWallah (Mainboard): 6 lot(s), ‚Çπ90000 invested, score 5.8\n",
      "\n",
      "üíµ Total Invested: ‚Çπ90000\n",
      "üí§ Remaining Unused: ‚Çπ10000\n",
      "\n",
      "üì¶ Recommendation saved to MongoDB (collection: ipo_portfolio_recommendations)\n",
      "‚úÖ Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "COL_ANALYSIS = \"ipo_analysis\"\n",
    "COL_RECOMMEND = \"ipo_portfolio_recommendations\"\n",
    "\n",
    "MIN_INVEST_MAINBOARD = 15000  # Default min for mainboard\n",
    "RETAIL_ONLY = True  # Always retail investor\n",
    "\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(str(x).replace(\"‚Çπ\", \"\").replace(\",\", \"\").strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def try_parse_date(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    # Try YYYY-MM-DD\n",
    "    try:\n",
    "        return datetime.strptime(s[:10], \"%Y-%m-%d\").date()\n",
    "    except Exception:\n",
    "        pass\n",
    "    fmts = [\"%d-%b-%Y\", \"%d %b %Y\", \"%d/%m/%Y\", \"%d-%m-%Y\", \"%d %B %Y\"]\n",
    "    for f in fmts:\n",
    "        try:\n",
    "            return datetime.strptime(s, f).date()\n",
    "        except Exception:\n",
    "            continue\n",
    "    try:\n",
    "        import dateutil.parser\n",
    "        return dateutil.parser.parse(s, dayfirst=True).date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_lot_and_min_invest(text):\n",
    "    \"\"\"\n",
    "    Parse lot size and min invest from strings like:\n",
    "    \"Min: 137 shares/‚Çπ14,933; Max (Retail): 1,781 shares/‚Çπ1,94,129\"\n",
    "    Returns (lot_size, min_invest)\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None, None\n",
    "    text = str(text)\n",
    "    # Find first \"Min: ...\" pattern\n",
    "    lot = None\n",
    "    min_inv = None\n",
    "\n",
    "    # Pattern for something like '137 shares/‚Çπ14,933'\n",
    "    m = re.search(r\"(\\d{1,5})\\s*shares?.*?‚Çπ\\s?([\\d,]+)\", text)\n",
    "    if m:\n",
    "        lot = safe_float(m.group(1))\n",
    "        min_inv = safe_float(m.group(2))\n",
    "    else:\n",
    "        # try fallback: just ‚Çπ number\n",
    "        m2 = re.search(r\"‚Çπ\\s?([\\d,]+)\", text)\n",
    "        if m2:\n",
    "            min_inv = safe_float(m2.group(1))\n",
    "\n",
    "    return lot, min_inv\n",
    "\n",
    "\n",
    "def load_ipos_and_scores():\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    ipos = list(client[DB_NAME][COL_IPOS].find({}))\n",
    "    analysis = list(client[DB_NAME][COL_ANALYSIS].find({\"status\": \"scored\"}))\n",
    "    client.close()\n",
    "\n",
    "    ipos_by_name = {d[\"ipo\"]: d for d in ipos if \"ipo\" in d}\n",
    "    scored_by_name = {a[\"ipo\"]: a for a in analysis if \"ipo\" in a}\n",
    "    return ipos_by_name, scored_by_name\n",
    "\n",
    "\n",
    "def parse_issue_price(ipo_doc):\n",
    "    \"\"\"Extract mid price from issue_price dict or string.\"\"\"\n",
    "    v = ipo_doc.get(\"issue_price\") or ipo_doc.get(\"extracted_fields\", {}).get(\"Price Band\")\n",
    "    if isinstance(v, dict):\n",
    "        nums = [v.get(\"avg\") or v.get(\"mid\") or v.get(\"min\")]\n",
    "    else:\n",
    "        nums = re.findall(r\"\\d+\\.?\\d*\", str(v))\n",
    "    nums = [safe_float(n) for n in nums if safe_float(n) is not None]\n",
    "    return sum(nums) / len(nums) if nums else None\n",
    "\n",
    "\n",
    "# ---------- BUILD IPO CANDIDATES ----------\n",
    "def prepare_candidates(ipos_by_name, scored_by_name, hold_until):\n",
    "    candidates = []\n",
    "\n",
    "    for ipo_name, ipo_doc in ipos_by_name.items():\n",
    "        if ipo_name not in scored_by_name:\n",
    "            continue\n",
    "\n",
    "        analysis = scored_by_name[ipo_name]\n",
    "        fields = ipo_doc.get(\"extracted_fields\", {}) or {}\n",
    "        score = analysis.get(\"score\")\n",
    "\n",
    "        # Skip incomplete records\n",
    "        if not score:\n",
    "            continue\n",
    "\n",
    "        # Close date\n",
    "        close_str = (\n",
    "            ipo_doc.get(\"close_date\")\n",
    "            or fields.get(\"Close Date\")\n",
    "            or fields.get(\"IPO Dates\")\n",
    "            or \"\"\n",
    "        )\n",
    "        date_match = re.findall(r\"\\d{4}-\\d{2}-\\d{2}\", close_str)\n",
    "        close_date = try_parse_date(date_match[0]) if date_match else try_parse_date(close_str)\n",
    "        if not close_date or close_date > hold_until:\n",
    "            continue\n",
    "\n",
    "        category = ipo_doc.get(\"category\", \"Mainboard\").lower()\n",
    "        issue_mid = parse_issue_price(ipo_doc)\n",
    "        if not issue_mid:\n",
    "            continue\n",
    "\n",
    "        lot_text = fields.get(\"Market Lot & Amounts\")\n",
    "        lot, min_invest = parse_lot_and_min_invest(lot_text)\n",
    "\n",
    "        # Determine final minimum investment\n",
    "        if \"sme\" in category:\n",
    "            if not min_invest and lot:\n",
    "                min_invest = lot * issue_mid\n",
    "        else:\n",
    "            # For Mainboard, fallback to Rs 15k\n",
    "            if not min_invest:\n",
    "                min_invest = MIN_INVEST_MAINBOARD\n",
    "            # If parsed, ensure at least 15k (retail minimum)\n",
    "            min_invest = max(min_invest, MIN_INVEST_MAINBOARD)\n",
    "\n",
    "        if not min_invest:\n",
    "            continue\n",
    "\n",
    "        candidates.append({\n",
    "            \"ipo\": ipo_name,\n",
    "            \"category\": \"SME\" if \"sme\" in category else \"Mainboard\",\n",
    "            \"score\": score,\n",
    "            \"issue_mid\": issue_mid,\n",
    "            \"lot\": int(lot) if lot else None,\n",
    "            \"min_invest\": float(min_invest),\n",
    "            \"close_date\": close_date,\n",
    "            \"gmp_pct\": analysis.get(\"gmp_pct\"),\n",
    "        })\n",
    "\n",
    "    return candidates\n",
    "\n",
    "\n",
    "# ---------- GREEDY OPTIMIZATION ----------\n",
    "def allocate_budget(candidates, budget):\n",
    "    for c in candidates:\n",
    "        c[\"score_per_inr\"] = c[\"score\"] / c[\"min_invest\"]\n",
    "\n",
    "    candidates = sorted(candidates, key=lambda x: x[\"score_per_inr\"], reverse=True)\n",
    "    allocation = []\n",
    "    remaining = budget\n",
    "\n",
    "    for c in candidates:\n",
    "        if remaining >= c[\"min_invest\"]:\n",
    "            lots = int(remaining // c[\"min_invest\"])\n",
    "            invested = lots * c[\"min_invest\"]\n",
    "            remaining -= invested\n",
    "\n",
    "            allocation.append({\n",
    "                \"ipo\": c[\"ipo\"],\n",
    "                \"score\": c[\"score\"],\n",
    "                \"issue_mid\": c[\"issue_mid\"],\n",
    "                \"lots\": lots,\n",
    "                \"min_invest\": c[\"min_invest\"],\n",
    "                \"invested\": invested,\n",
    "                \"category\": c[\"category\"],\n",
    "            })\n",
    "\n",
    "    return allocation, remaining\n",
    "\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main():\n",
    "    print(\"üìà IPO Portfolio Optimizer for Retail Investors\\n\")\n",
    "\n",
    "    try:\n",
    "        budget = float(input(\"üí∞ Enter your total investment budget (e.g., 100000): \").strip())\n",
    "        hold_date = datetime.strptime(input(\"üìÖ Enter your max hold date (YYYY-MM-DD): \").strip(), \"%Y-%m-%d\").date()\n",
    "    except Exception:\n",
    "        print(\"‚ùå Invalid input.\")\n",
    "        return\n",
    "\n",
    "    ipos_by_name, scored_by_name = load_ipos_and_scores()\n",
    "    candidates = prepare_candidates(ipos_by_name, scored_by_name, hold_date)\n",
    "\n",
    "    if not candidates:\n",
    "        print(\"‚ö†Ô∏è No valid IPOs found for your criteria.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n‚úÖ Found {len(candidates)} eligible IPOs:\\n\")\n",
    "    for c in candidates:\n",
    "        print(f\"‚Ä¢ {c['ipo']} | {c['category']} | Score: {c['score']} | Min Invest: ‚Çπ{int(c['min_invest'])} | Close: {c['close_date']}\")\n",
    "\n",
    "    allocation, leftover = allocate_budget(candidates, budget)\n",
    "\n",
    "    print(\"\\nüìä Final Allocation Plan:\")\n",
    "    total_invested = 0\n",
    "    for a in allocation:\n",
    "        total_invested += a[\"invested\"]\n",
    "        print(f\"  - {a['ipo']} ({a['category']}): {a['lots']} lot(s), ‚Çπ{int(a['invested'])} invested, score {a['score']}\")\n",
    "\n",
    "    print(f\"\\nüíµ Total Invested: ‚Çπ{int(total_invested)}\")\n",
    "    print(f\"üí§ Remaining Unused: ‚Çπ{int(leftover)}\")\n",
    "\n",
    "    # Save to MongoDB\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    rec = {\n",
    "        \"created_at\": datetime.utcnow().isoformat(),\n",
    "        \"budget\": budget,\n",
    "        \"hold_until\": hold_date.isoformat(),\n",
    "        \"allocation\": allocation,\n",
    "        \"total_invested\": total_invested,\n",
    "        \"leftover\": leftover,\n",
    "    }\n",
    "    client[DB_NAME][COL_RECOMMEND].insert_one(rec)\n",
    "    client.close()\n",
    "\n",
    "    print(\"\\nüì¶ Recommendation saved to MongoDB (collection: ipo_portfolio_recommendations)\")\n",
    "    print(\"‚úÖ Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c7d21ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Balanced IPO Allocator (Retail)\n",
      "\n",
      "‚úÖ Found 6 eligible IPOs:\n",
      "\n",
      "‚Ä¢ PhysicsWallah | Mainboard | Score 6.3 | Min ‚Çπ14933 | Retail 10.0%\n",
      "‚Ä¢ Emmvee Photovoltaic Power | Mainboard | Score 6.171 | Min ‚Çπ14973 | Retail 10.0%\n",
      "‚Ä¢ Workmates Core2Cloud | SME | Score 6.135 | Min ‚Çπ244800 | Retail 10.0%\n",
      "‚Ä¢ Tenneco Clean Air | Mainboard | Score 6.089 | Min ‚Çπ14689 | Retail 10.0%\n",
      "‚Ä¢ Shining Tools | SME | Score 6.028 | Min ‚Çπ273600 | Retail 10.0%\n",
      "‚Ä¢ Shreeji Global FMCG | SME | Score 5.91 | Min ‚Çπ250000 | Retail 10.0%\n",
      "‚ö†Ô∏è PuLP not installed, using fallback greedy mode.\n",
      "\n",
      "üìà Optimized Allocation Plan:\n",
      "  - PhysicsWallah: ‚Çπ44799 (3 lot(s)) | Score 6.3 | Retail 10.0%\n",
      "  - Tenneco Clean Air: ‚Çπ44067 (3 lot(s)) | Score 6.089 | Retail 10.0%\n",
      "  - Emmvee Photovoltaic Power: ‚Çπ44919 (3 lot(s)) | Score 6.171 | Retail 10.0%\n",
      "  - Workmates Core2Cloud: ‚Çπ734400 (3 lot(s)) | Score 6.135 | Retail 10.0%\n",
      "\n",
      "üíµ Total Invested: ‚Çπ868185\n",
      "üí§ Remaining: ‚Çπ131815\n",
      "\n",
      "‚úÖ Saved recommendation to MongoDB successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime, date\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "COL_ANALYSIS = \"ipo_analysis\"\n",
    "COL_RECOMMEND = \"ipo_portfolio_recommendations\"\n",
    "\n",
    "MIN_INVEST_MAINBOARD = 15000\n",
    "DEFAULT_MAX_LOTS_PER_IPO = 3   # retail-friendly cap\n",
    "DIVERSIFICATION_WEIGHT = 0.1   # penalty for over-concentration\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(str(x).replace(\"‚Çπ\", \"\").replace(\",\", \"\").strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def try_parse_date(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    fmts = [\"%Y-%m-%d\", \"%d-%b-%Y\", \"%d %b %Y\", \"%d/%m/%Y\"]\n",
    "    for f in fmts:\n",
    "        try:\n",
    "            return datetime.strptime(s[:len(f)], f).date()\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        import dateutil.parser\n",
    "        return dateutil.parser.parse(s, dayfirst=True).date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def parse_lot_and_min_invest(text):\n",
    "    if not text:\n",
    "        return None, None\n",
    "    s = str(text)\n",
    "    m = re.search(r\"(?:Min[:\\s]*)?(\\d{1,6})\\s*shares?.*?‚Çπ\\s?([\\d,]+)\", s, flags=re.I)\n",
    "    if m:\n",
    "        lot = safe_float(m.group(1))\n",
    "        min_inv = safe_float(m.group(2))\n",
    "        return int(lot) if lot else None, float(min_inv) if min_inv else None\n",
    "    m2 = re.search(r\"‚Çπ\\s?([\\d,]+)\", s)\n",
    "    if m2:\n",
    "        return None, float(safe_float(m2.group(1)))\n",
    "    return None, None\n",
    "\n",
    "def parse_issue_mid(ipo_doc):\n",
    "    v = ipo_doc.get(\"issue_price\") or ipo_doc.get(\"extracted_fields\", {}).get(\"Price Band\")\n",
    "    if isinstance(v, dict):\n",
    "        mid = v.get(\"avg\") or v.get(\"mid\") or v.get(\"min\")\n",
    "        return safe_float(mid)\n",
    "    if not v:\n",
    "        return None\n",
    "    nums = re.findall(r\"\\d+\\.?\\d*\", str(v))\n",
    "    nums = [safe_float(n) for n in nums if safe_float(n) is not None]\n",
    "    return sum(nums)/len(nums) if nums else None\n",
    "\n",
    "def sanitize_for_mongo(obj):\n",
    "    \"\"\"Recursively convert datetime.date to ISO string.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: sanitize_for_mongo(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [sanitize_for_mongo(x) for x in obj]\n",
    "    elif isinstance(obj, date):\n",
    "        return datetime(obj.year, obj.month, obj.day).isoformat()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "def extract_retail_quota(text):\n",
    "    if not text:\n",
    "        return 10.0\n",
    "    m = re.search(r\"Retail\\s*:?(\\d+\\.?\\d*)%\", str(text), flags=re.I)\n",
    "    if m:\n",
    "        return safe_float(m.group(1))\n",
    "    return 10.0\n",
    "\n",
    "def extract_fundamental_score(text):\n",
    "    if not text:\n",
    "        return 5.0\n",
    "    score = 5.0\n",
    "    t = str(text).lower()\n",
    "    if \"profit\" in t or \"positive\" in t or \"growth\" in t:\n",
    "        score += 2\n",
    "    if \"loss\" in t or \"negative\" in t:\n",
    "        score -= 2\n",
    "    if \"roe\" in t:\n",
    "        m = re.search(r\"roe[:\\s]*([-\\d.]+)\", t)\n",
    "        if m:\n",
    "            roe = safe_float(m.group(1))\n",
    "            if roe and roe > 10:\n",
    "                score += 1.5\n",
    "    if \"d/e\" in t:\n",
    "        m = re.search(r\"d/e[:\\s]*([-\\d.]+)\", t)\n",
    "        if m:\n",
    "            de = safe_float(m.group(1))\n",
    "            if de and de > 1:\n",
    "                score -= 1\n",
    "    if \"eps\" in t:\n",
    "        m = re.search(r\"eps[:\\s]*[-(‚Çπ]?([\\d.]+)\", t)\n",
    "        if m:\n",
    "            eps = safe_float(m.group(1))\n",
    "            if eps and eps > 0:\n",
    "                score += 1\n",
    "            else:\n",
    "                score -= 1\n",
    "    return max(1, min(score, 10))\n",
    "\n",
    "def extract_sentiment(text):\n",
    "    if not text:\n",
    "        return 5.0\n",
    "    t = str(text).lower()\n",
    "    score = 5.0\n",
    "    good = [\"growing\", \"leader\", \"expanding\", \"innovative\", \"strong\", \"profitable\", \"stable\"]\n",
    "    bad = [\"loss\", \"decline\", \"volatile\", \"uncertain\", \"risky\", \"unprofitable\"]\n",
    "    for w in good:\n",
    "        if w in t:\n",
    "            score += 0.5\n",
    "    for w in bad:\n",
    "        if w in t:\n",
    "            score -= 0.5\n",
    "    return max(1, min(score, 10))\n",
    "\n",
    "def compute_composite(ipo_doc, analysis):\n",
    "    fields = ipo_doc.get(\"extracted_fields\", {}) or {}\n",
    "    base = analysis.get(\"score\", 5)\n",
    "    retail = extract_retail_quota(fields.get(\"Investor Quota Split\"))\n",
    "    fund = extract_fundamental_score(fields.get(\"Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)\") or fields.get(\"Financial Performance (FY23‚ÄìFY25)\"))\n",
    "    sent = extract_sentiment(fields.get(\"Company Overview\"))\n",
    "    gmp = safe_float(ipo_doc.get(\"gmp_investorgain\")) or 0\n",
    "    issue = parse_issue_mid(ipo_doc)\n",
    "    gmp_strength = (gmp / issue * 100) if (gmp and issue) else 0\n",
    "    rq_score = min(retail / 10, 1) * 10\n",
    "    composite = 0.30*base + 0.25*rq_score + 0.20*fund + 0.15*(gmp_strength/10) + 0.10*sent\n",
    "    return round(min(composite, 10), 3), retail, fund, sent, gmp_strength\n",
    "\n",
    "def load_data():\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    ipos = list(client[DB_NAME][COL_IPOS].find({}))\n",
    "    analysis = list(client[DB_NAME][COL_ANALYSIS].find({}))\n",
    "    client.close()\n",
    "    ipos_by_name = {d[\"ipo\"]: d for d in ipos if \"ipo\" in d}\n",
    "    scored = {a[\"ipo\"]: a for a in analysis if \"ipo\" in a}\n",
    "    return ipos_by_name, scored\n",
    "\n",
    "# ---------- CANDIDATE PREP ----------\n",
    "def build_candidates(ipos_by_name, scored, hold_date):\n",
    "    cands = []\n",
    "    for name, ipo in ipos_by_name.items():\n",
    "        if name not in scored:\n",
    "            continue\n",
    "        analysis = scored[name]\n",
    "        if analysis.get(\"status\") != \"scored\" and \"score\" not in analysis:\n",
    "            continue\n",
    "        fields = ipo.get(\"extracted_fields\", {}) or {}\n",
    "        close = ipo.get(\"close_date\") or fields.get(\"IPO Dates\") or fields.get(\"Close Date\")\n",
    "        close_date = try_parse_date(str(close))\n",
    "        if not close_date or close_date > hold_date:\n",
    "            continue\n",
    "\n",
    "        issue_mid = parse_issue_mid(ipo)\n",
    "        if not issue_mid:\n",
    "            continue\n",
    "\n",
    "        lot, min_inv = parse_lot_and_min_invest(fields.get(\"Market Lot & Amounts\"))\n",
    "        if not min_inv:\n",
    "            min_inv = lot * issue_mid if lot else MIN_INVEST_MAINBOARD\n",
    "\n",
    "        composite, retail, fund, sent, gmp_strength = compute_composite(ipo, analysis)\n",
    "        if composite < 5:\n",
    "            continue\n",
    "\n",
    "        cands.append({\n",
    "            \"ipo\": name,\n",
    "            \"category\": ipo.get(\"category\", \"Mainboard\"),\n",
    "            \"composite\": composite,\n",
    "            \"retail_quota\": retail,\n",
    "            \"fund_score\": fund,\n",
    "            \"sentiment\": sent,\n",
    "            \"gmp_strength\": gmp_strength,\n",
    "            \"issue_mid\": issue_mid,\n",
    "            \"lot\": lot,\n",
    "            \"min_invest\": min_inv,\n",
    "            \"close_date\": close_date,\n",
    "        })\n",
    "    return cands\n",
    "\n",
    "# ---------- ALLOCATION ----------\n",
    "def allocate_balanced(candidates, budget):\n",
    "    \"\"\"Balanced allocator that penalizes over-concentration and uses all budget.\"\"\"\n",
    "    try:\n",
    "        import pulp\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è PuLP not installed, using fallback greedy mode.\")\n",
    "        return greedy_fill_full(candidates, budget)\n",
    "\n",
    "    prob = pulp.LpProblem(\"Balanced_IPO_Allocation\", pulp.LpMaximize)\n",
    "    lot_vars = {}\n",
    "\n",
    "    for c in candidates:\n",
    "        safe_name = re.sub(r\"\\W+\", \"_\", c[\"ipo\"])\n",
    "        max_possible = int(max(1, budget // c[\"min_invest\"]))\n",
    "        cap = min(DEFAULT_MAX_LOTS_PER_IPO, max_possible)\n",
    "        lot_vars[c[\"ipo\"]] = pulp.LpVariable(f\"lots_{safe_name}\", lowBound=0, upBound=cap, cat=\"Integer\")\n",
    "\n",
    "    # objective: maximize (score * lots) - diversification penalty\n",
    "    total_lots = pulp.lpSum(lot_vars.values())\n",
    "    objective = pulp.lpSum([c[\"composite\"] * lot_vars[c[\"ipo\"]] for c in candidates])\n",
    "    penalty = DIVERSIFICATION_WEIGHT * pulp.lpSum([(lot_vars[c[\"ipo\"]] ** 2) for c in candidates])\n",
    "    prob += objective - penalty\n",
    "\n",
    "    # budget constraint\n",
    "    prob += pulp.lpSum([c[\"min_invest\"] * lot_vars[c[\"ipo\"]] for c in candidates]) <= budget\n",
    "\n",
    "    prob.solve(pulp.PULP_CBC_CMD(msg=False, timeLimit=10))\n",
    "\n",
    "    allocation = []\n",
    "    total_invested = 0\n",
    "    for c in candidates:\n",
    "        v = int(pulp.value(lot_vars[c[\"ipo\"]]) or 0)\n",
    "        if v > 0:\n",
    "            invested = v * c[\"min_invest\"]\n",
    "            allocation.append({\n",
    "                \"ipo\": c[\"ipo\"],\n",
    "                \"lots\": v,\n",
    "                \"invested\": invested,\n",
    "                \"min_invest\": c[\"min_invest\"],\n",
    "                \"composite\": c[\"composite\"],\n",
    "                \"retail_quota\": c[\"retail_quota\"]\n",
    "            })\n",
    "            total_invested += invested\n",
    "    remaining = budget - total_invested\n",
    "    return allocation, remaining\n",
    "\n",
    "def greedy_fill_full(candidates, budget):\n",
    "    candidates = sorted(candidates, key=lambda x: x[\"composite\"]/x[\"min_invest\"], reverse=True)\n",
    "    allocation = []\n",
    "    remaining = budget\n",
    "    for c in candidates:\n",
    "        if remaining < min(x[\"min_invest\"] for x in candidates):\n",
    "            break\n",
    "        max_lots = min(DEFAULT_MAX_LOTS_PER_IPO, int(remaining // c[\"min_invest\"]))\n",
    "        if max_lots <= 0:\n",
    "            continue\n",
    "        invested = c[\"min_invest\"] * max_lots\n",
    "        allocation.append({\n",
    "            \"ipo\": c[\"ipo\"],\n",
    "            \"lots\": max_lots,\n",
    "            \"invested\": invested,\n",
    "            \"min_invest\": c[\"min_invest\"],\n",
    "            \"composite\": c[\"composite\"],\n",
    "            \"retail_quota\": c[\"retail_quota\"]\n",
    "        })\n",
    "        remaining -= invested\n",
    "    return allocation, remaining\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main():\n",
    "    print(\"üìä Balanced IPO Allocator (Retail)\\n\")\n",
    "    try:\n",
    "        budget = float(input(\"Enter total budget (‚Çπ): \").strip())\n",
    "        hold_date = datetime.strptime(input(\"Enter hold-until date (YYYY-MM-DD): \").strip(), \"%Y-%m-%d\").date()\n",
    "    except Exception as e:\n",
    "        print(\"Invalid input:\", e)\n",
    "        return\n",
    "\n",
    "    ipos_by_name, scored = load_data()\n",
    "    candidates = build_candidates(ipos_by_name, scored, hold_date)\n",
    "    if not candidates:\n",
    "        print(\"No eligible IPOs found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"‚úÖ Found {len(candidates)} eligible IPOs:\\n\")\n",
    "    for c in candidates:\n",
    "        print(f\"‚Ä¢ {c['ipo']} | {c['category']} | Score {c['composite']} | Min ‚Çπ{int(c['min_invest'])} | Retail {c['retail_quota']}%\")\n",
    "\n",
    "    allocation, remaining = allocate_balanced(candidates, budget)\n",
    "    if not allocation:\n",
    "        print(\"‚ùå No allocation possible with given budget.\")\n",
    "        return\n",
    "\n",
    "    total_invested = sum(a[\"invested\"] for a in allocation)\n",
    "\n",
    "    print(\"\\nüìà Optimized Allocation Plan:\")\n",
    "    for a in allocation:\n",
    "        print(f\"  - {a['ipo']}: ‚Çπ{int(a['invested'])} ({a['lots']} lot(s)) | Score {a['composite']} | Retail {a['retail_quota']}%\")\n",
    "    print(f\"\\nüíµ Total Invested: ‚Çπ{int(total_invested)}\")\n",
    "    print(f\"üí§ Remaining: ‚Çπ{int(remaining)}\")\n",
    "\n",
    "    # save results safely\n",
    "    rec = {\n",
    "        \"created_at\": datetime.utcnow().isoformat(),\n",
    "        \"budget\": budget,\n",
    "        \"hold_until\": hold_date.isoformat(),\n",
    "        \"allocation\": allocation,\n",
    "        \"total_invested\": total_invested,\n",
    "        \"leftover\": remaining,\n",
    "        \"count\": len(allocation)\n",
    "    }\n",
    "    rec = sanitize_for_mongo(rec)\n",
    "\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    client[DB_NAME][COL_RECOMMEND].insert_one(rec)\n",
    "    client.close()\n",
    "    print(\"\\n‚úÖ Saved recommendation to MongoDB successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fffc0525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä IPO Allocator ‚Äî Full explainable mode\n",
      "\n",
      "‚úÖ Found 6 eligible IPOs:\n",
      "\n",
      "‚Ä¢ PhysicsWallah | Mainboard | Composite 6.3 | Min ‚Çπ14933 | Retail 10.0%\n",
      "‚Ä¢ Emmvee Photovoltaic Power | Mainboard | Composite 6.171 | Min ‚Çπ14973 | Retail 10.0%\n",
      "‚Ä¢ Workmates Core2Cloud | SME | Composite 6.135 | Min ‚Çπ244800 | Retail 10.0%\n",
      "‚Ä¢ Tenneco Clean Air | Mainboard | Composite 6.089 | Min ‚Çπ14689 | Retail 10.0%\n",
      "‚Ä¢ Shining Tools | SME | Composite 6.028 | Min ‚Çπ273600 | Retail 10.0%\n",
      "‚Ä¢ Shreeji Global FMCG | SME | Composite 5.91 | Min ‚Çπ250000 | Retail 10.0%\n",
      "‚ö†Ô∏è PuLP not installed or failed ‚Äî using improved greedy filler.\n",
      "\n",
      "üìà Final Allocation Plan:\n",
      "  - PhysicsWallah: ‚Çπ74665 (5 lots) | min_unit=‚Çπ14933 | score 6.3\n",
      "  - Emmvee Photovoltaic Power: ‚Çπ74865 (5 lots) | min_unit=‚Çπ14973 | score 6.171\n",
      "  - Workmates Core2Cloud: ‚Çπ244800 (1 lots) | min_unit=‚Çπ244800 | score 6.135\n",
      "  - Tenneco Clean Air: ‚Çπ73445 (5 lots) | min_unit=‚Çπ14689 | score 6.089\n",
      "  - Shining Tools: ‚Çπ273600 (1 lots) | min_unit=‚Çπ273600 | score 6.028\n",
      "  - Shreeji Global FMCG: ‚Çπ250000 (1 lots) | min_unit=‚Çπ250000 | score 5.91\n",
      "\n",
      "üíµ Total Invested: ‚Çπ991375\n",
      "üí§ Remaining: ‚Çπ8625\n",
      "\n",
      "--- Explainability & Formulas ---\n",
      "\n",
      "Algorithm summary:\n",
      "  - We compute a composite score per IPO combining:\n",
      "      composite = 0.30*base_score + 0.25*rq_score + 0.20*fund_score + 0.15*(gmp_strength/10) + 0.10*sentiment_score\n",
      "    where rq_score = min(retail_pct/10,1)*10 (normalized 0-10).\n",
      "  - Primary solver: MILP (PuLP) maximizing sum(composite * lots) minus DIVERSIFICATION_WEIGHT * sum(lots^2).\n",
      "  - Fallback: improved greedy that:\n",
      "      1) gives 1 lot to each top candidate by composite/unit if affordable,\n",
      "      2) repeatedly fills top K candidates (round-robin) to use leftover,\n",
      "      3) finally uses any remaining budget on best composite/unit candidate.\n",
      "  - Unit = min_invest (usually lot * issue price or ‚Çπ15k for mainboard fallback).\n",
      "  - We skip any IPO with composite < 5 per your instruction.\n",
      "\n",
      "Parameters used:\n",
      "  - MIN_INVEST_MAINBOARD = 15000\n",
      "  - DEFAULT_MAX_LOTS_PER_IPO = 3\n",
      "  - DIVERSIFICATION_WEIGHT = 0.1\n",
      "  - TOP_FILL_K = 3\n",
      "\n",
      "Per-IPO reasons (why more / why less):\n",
      "\n",
      "üîé PhysicsWallah\n",
      "  Breakdown: base=5.8, retail%=10.0%, rq_score=10.0, fund=5.0, sentiment=5.5, gmp_str%=33.981\n",
      "  Reasons to invest more:\n",
      "   - Composite score 6.3 computed from base_score=5.8, retail_q=10.0%, fund=5.0, sentiment=5.5, gmp_str=33.981% using weights {'base': 0.3, 'retail': 0.25, 'fund': 0.2, 'gmp': 0.15, 'sentiment': 0.1}.\n",
      "   - High GMP strength 33.981% ‚Üí strong listing expectation.\n",
      "  Reasons to be cautious:\n",
      "   - Retail quota 10.0% is low; allotment probability may be limited.\n",
      "   - Fundamentals are weak/moderate.\n",
      "\n",
      "üîé Emmvee Photovoltaic Power\n",
      "  Breakdown: base=5.1, retail%=10.0%, rq_score=10.0, fund=6.5, sentiment=5.5, gmp_str%=19.417\n",
      "  Reasons to invest more:\n",
      "   - Composite score 6.171 computed from base_score=5.1, retail_q=10.0%, fund=6.5, sentiment=5.5, gmp_str=19.417% using weights {'base': 0.3, 'retail': 0.25, 'fund': 0.2, 'gmp': 0.15, 'sentiment': 0.1}.\n",
      "   - High GMP strength 19.417% ‚Üí strong listing expectation.\n",
      "   - Fundamentals show positive indicators.\n",
      "  Reasons to be cautious:\n",
      "   - Retail quota 10.0% is low; allotment probability may be limited.\n",
      "\n",
      "üîé Workmates Core2Cloud\n",
      "  Breakdown: base=4.9, retail%=10.0%, rq_score=10.0, fund=7.5, sentiment=5.0, gmp_str%=11.0\n",
      "  Reasons to invest more:\n",
      "   - Composite score 6.135 computed from base_score=4.9, retail_q=10.0%, fund=7.5, sentiment=5.0, gmp_str=11.0% using weights {'base': 0.3, 'retail': 0.25, 'fund': 0.2, 'gmp': 0.15, 'sentiment': 0.1}.\n",
      "   - High GMP strength 11.0% ‚Üí strong listing expectation.\n",
      "   - Fundamentals show positive indicators.\n",
      "  Reasons to be cautious:\n",
      "   - Retail quota 10.0% is low; allotment probability may be limited.\n",
      "   - SME IPO: higher risk & lower liquidity ‚Äî allocate small exposure.\n",
      "\n",
      "üîé Tenneco Clean Air\n",
      "  Breakdown: base=4.7, retail%=10.0%, rq_score=10.0, fund=7.5, sentiment=5.0, gmp_str%=11.905\n",
      "  Reasons to invest more:\n",
      "   - Composite score 6.089 computed from base_score=4.7, retail_q=10.0%, fund=7.5, sentiment=5.0, gmp_str=11.905% using weights {'base': 0.3, 'retail': 0.25, 'fund': 0.2, 'gmp': 0.15, 'sentiment': 0.1}.\n",
      "   - High GMP strength 11.905% ‚Üí strong listing expectation.\n",
      "   - Fundamentals show positive indicators.\n",
      "  Reasons to be cautious:\n",
      "   - Retail quota 10.0% is low; allotment probability may be limited.\n",
      "\n",
      "üîé Shining Tools\n",
      "  Breakdown: base=4.9, retail%=10.0%, rq_score=10.0, fund=7.0, sentiment=5.0, gmp_str%=10.526\n",
      "  Reasons to invest more:\n",
      "   - Composite score 6.028 computed from base_score=4.9, retail_q=10.0%, fund=7.0, sentiment=5.0, gmp_str=10.526% using weights {'base': 0.3, 'retail': 0.25, 'fund': 0.2, 'gmp': 0.15, 'sentiment': 0.1}.\n",
      "   - High GMP strength 10.526% ‚Üí strong listing expectation.\n",
      "   - Fundamentals show positive indicators.\n",
      "  Reasons to be cautious:\n",
      "   - Retail quota 10.0% is low; allotment probability may be limited.\n",
      "   - SME IPO: higher risk & lower liquidity ‚Äî allocate small exposure.\n",
      "\n",
      "üîé Shreeji Global FMCG\n",
      "  Breakdown: base=4.7, retail%=10.0%, rq_score=10.0, fund=6.5, sentiment=6.0, gmp_str%=6.667\n",
      "  Reasons to invest more:\n",
      "   - Composite score 5.91 computed from base_score=4.7, retail_q=10.0%, fund=6.5, sentiment=6.0, gmp_str=6.667% using weights {'base': 0.3, 'retail': 0.25, 'fund': 0.2, 'gmp': 0.15, 'sentiment': 0.1}.\n",
      "   - Fundamentals show positive indicators.\n",
      "  Reasons to be cautious:\n",
      "   - Retail quota 10.0% is low; allotment probability may be limited.\n",
      "   - SME IPO: higher risk & lower liquidity ‚Äî allocate small exposure.\n",
      "\n",
      "‚úÖ Saved recommendation to MongoDB (collection: ipo_portfolio_recommendations )\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime, date\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n",
    "DB_NAME = \"ipo_db\"\n",
    "COL_IPOS = \"ipos\"\n",
    "COL_ANALYSIS = \"ipo_analysis\"\n",
    "COL_RECOMMEND = \"ipo_portfolio_recommendations\"\n",
    "\n",
    "MIN_INVEST_MAINBOARD = 15000\n",
    "DEFAULT_MAX_LOTS_PER_IPO = 3   # soft cap for diversification initially\n",
    "DIVERSIFICATION_WEIGHT = 0.10  # penalty in MILP objective\n",
    "TOP_FILL_K = 3                 # when filling leftovers, prioritize top K IPOs\n",
    "\n",
    "# ---------- UTILITIES ----------\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(str(x).replace(\"‚Çπ\", \"\").replace(\",\", \"\").strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def try_parse_date(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    fmts = [\"%Y-%m-%d\", \"%d-%b-%Y\", \"%d %b %Y\", \"%d/%m/%Y\"]\n",
    "    for f in fmts:\n",
    "        try:\n",
    "            return datetime.strptime(s[:len(f)], f).date()\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        import dateutil.parser\n",
    "        return dateutil.parser.parse(s, dayfirst=True).date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def parse_lot_and_min_invest(text):\n",
    "    if not text:\n",
    "        return None, None\n",
    "    s = str(text)\n",
    "    m = re.search(r\"(?:Min[:\\s]*)?(\\d{1,6})\\s*shares?.*?‚Çπ\\s?([\\d,]+)\", s, flags=re.I)\n",
    "    if m:\n",
    "        lot = safe_float(m.group(1))\n",
    "        min_inv = safe_float(m.group(2))\n",
    "        return int(lot) if lot else None, float(min_inv) if min_inv else None\n",
    "    m2 = re.search(r\"‚Çπ\\s?([\\d,]+)\", s)\n",
    "    if m2:\n",
    "        return None, float(safe_float(m2.group(1)))\n",
    "    return None, None\n",
    "\n",
    "def parse_issue_mid(ipo_doc):\n",
    "    v = ipo_doc.get(\"issue_price\") or ipo_doc.get(\"extracted_fields\", {}).get(\"Price Band\")\n",
    "    if isinstance(v, dict):\n",
    "        mid = v.get(\"avg\") or v.get(\"mid\") or v.get(\"min\")\n",
    "        return safe_float(mid)\n",
    "    if not v:\n",
    "        return None\n",
    "    nums = re.findall(r\"\\d+\\.?\\d*\", str(v))\n",
    "    nums = [safe_float(n) for n in nums if safe_float(n) is not None]\n",
    "    return sum(nums)/len(nums) if nums else None\n",
    "\n",
    "def sanitize_for_mongo(obj):\n",
    "    \"\"\"Recursively convert datetime.date to ISO string and datetime to iso.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: sanitize_for_mongo(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [sanitize_for_mongo(x) for x in obj]\n",
    "    elif isinstance(obj, date):\n",
    "        return datetime(obj.year, obj.month, obj.day).isoformat()\n",
    "    elif isinstance(obj, datetime):\n",
    "        return obj.isoformat()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# ---------- SCORING COMPONENTS ----------\n",
    "def extract_retail_quota(text):\n",
    "    if not text:\n",
    "        return 10.0\n",
    "    m = re.search(r\"Retail\\s*:?(\\d+\\.?\\d*)%\", str(text), flags=re.I)\n",
    "    if m:\n",
    "        return safe_float(m.group(1))\n",
    "    return 10.0\n",
    "\n",
    "def extract_fundamental_score(text):\n",
    "    if not text:\n",
    "        return 5.0\n",
    "    score = 5.0\n",
    "    t = str(text).lower()\n",
    "    if \"profit\" in t or \"positive\" in t or \"growth\" in t:\n",
    "        score += 2\n",
    "    if \"loss\" in t or \"negative\" in t:\n",
    "        score -= 2\n",
    "    # ROE, D/E, EPS heuristics:\n",
    "    m = re.search(r\"roe[:\\s]*([-\\d.]+)\", t)\n",
    "    if m:\n",
    "        roe = safe_float(m.group(1))\n",
    "        if roe and roe > 10:\n",
    "            score += 1.5\n",
    "    m = re.search(r\"d/?e[:\\s]*([-\\d.]+)\", t)\n",
    "    if m:\n",
    "        de = safe_float(m.group(1))\n",
    "        if de and de > 1:\n",
    "            score -= 1\n",
    "    m = re.search(r\"eps[:\\s]*[-(‚Çπ]?([\\d.]+)\", t)\n",
    "    if m:\n",
    "        eps = safe_float(m.group(1))\n",
    "        if eps and eps > 0:\n",
    "            score += 1\n",
    "        else:\n",
    "            score -= 1\n",
    "    return max(1, min(score, 10))\n",
    "\n",
    "def extract_sentiment(text):\n",
    "    if not text:\n",
    "        return 5.0\n",
    "    t = str(text).lower()\n",
    "    score = 5.0\n",
    "    good = [\"growing\", \"leader\", \"expanding\", \"innovative\", \"strong\", \"profitable\", \"stable\"]\n",
    "    bad = [\"loss\", \"decline\", \"volatile\", \"uncertain\", \"risky\", \"unprofitable\"]\n",
    "    for w in good:\n",
    "        if w in t:\n",
    "            score += 0.5\n",
    "    for w in bad:\n",
    "        if w in t:\n",
    "            score -= 0.5\n",
    "    return max(1, min(score, 10))\n",
    "\n",
    "def compute_composite_and_breakdown(ipo_doc, analysis):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      composite (float),\n",
    "      breakdown: dict with base_score, retail_quota, rq_score, fund_score, sentiment, gmp_strength, formula_weights\n",
    "    \"\"\"\n",
    "    fields = ipo_doc.get(\"extracted_fields\", {}) or {}\n",
    "    base = analysis.get(\"score\", 5)  # from earlier scorer\n",
    "    retail = extract_retail_quota(fields.get(\"Investor Quota Split\"))\n",
    "    fund = extract_fundamental_score(fields.get(\"Valuation Ratios (EPS, ROE, ROCE, D/E, NAV)\") or fields.get(\"Financial Performance (FY23‚ÄìFY25)\"))\n",
    "    sent = extract_sentiment(fields.get(\"Company Overview\"))\n",
    "    gmp = safe_float(ipo_doc.get(\"gmp_investorgain\")) or 0\n",
    "    issue = parse_issue_mid(ipo_doc)\n",
    "    gmp_strength = (gmp / issue * 100) if (gmp and issue) else 0\n",
    "    # retail quota normalized to 0-10\n",
    "    rq_score = min(retail / 10, 1) * 10\n",
    "\n",
    "    # weights (documented to user later)\n",
    "    w_base = 0.30\n",
    "    w_rq = 0.25\n",
    "    w_fund = 0.20\n",
    "    w_gmp = 0.15\n",
    "    w_sent = 0.10\n",
    "\n",
    "    composite = w_base*base + w_rq*rq_score + w_fund*fund + w_gmp*(gmp_strength/10) + w_sent*sent\n",
    "    composite = round(min(composite, 10), 3)\n",
    "\n",
    "    breakdown = {\n",
    "        \"base_score\": base,\n",
    "        \"retail_quota_pct\": retail,\n",
    "        \"rq_score\": round(rq_score,3),\n",
    "        \"fund_score\": round(fund,3),\n",
    "        \"sentiment_score\": round(sent,3),\n",
    "        \"gmp_strength_pct\": round(gmp_strength,3),\n",
    "        \"weights\": {\"base\": w_base, \"retail\": w_rq, \"fund\": w_fund, \"gmp\": w_gmp, \"sentiment\": w_sent}\n",
    "    }\n",
    "    return composite, breakdown\n",
    "\n",
    "# ---------- DATA LOAD ----------\n",
    "def load_data():\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    ipos = list(client[DB_NAME][COL_IPOS].find({}))\n",
    "    analysis = list(client[DB_NAME][COL_ANALYSIS].find({}))\n",
    "    client.close()\n",
    "    ipos_by_name = {d[\"ipo\"]: d for d in ipos if \"ipo\" in d}\n",
    "    scored = {a[\"ipo\"]: a for a in analysis if \"ipo\" in a}\n",
    "    return ipos_by_name, scored\n",
    "\n",
    "# ---------- BUILD CANDIDATES ----------\n",
    "def build_candidates(ipos_by_name, scored, hold_date):\n",
    "    cands = []\n",
    "    for name, ipo in ipos_by_name.items():\n",
    "        if name not in scored:\n",
    "            continue\n",
    "        analysis = scored[name]\n",
    "        if analysis.get(\"status\") != \"scored\" and \"score\" not in analysis:\n",
    "            continue\n",
    "        fields = ipo.get(\"extracted_fields\", {}) or {}\n",
    "        close = ipo.get(\"close_date\") or fields.get(\"IPO Dates\") or fields.get(\"Close Date\")\n",
    "        close_date = try_parse_date(str(close))\n",
    "        if not close_date or close_date > hold_date:\n",
    "            continue\n",
    "\n",
    "        issue_mid = parse_issue_mid(ipo)\n",
    "        if not issue_mid:\n",
    "            continue\n",
    "\n",
    "        lot, min_inv = parse_lot_and_min_invest(fields.get(\"Market Lot & Amounts\"))\n",
    "        if not min_inv:\n",
    "            min_inv = (lot * issue_mid) if lot else MIN_INVEST_MAINBOARD\n",
    "\n",
    "        composite, breakdown = compute_composite_and_breakdown(ipo, analysis)\n",
    "        if composite < 5:\n",
    "            # skip per user instruction\n",
    "            continue\n",
    "\n",
    "        cands.append({\n",
    "            \"ipo\": name,\n",
    "            \"category\": ipo.get(\"category\", \"Mainboard\"),\n",
    "            \"composite\": composite,\n",
    "            \"breakdown\": breakdown,\n",
    "            \"issue_mid\": issue_mid,\n",
    "            \"lot\": int(lot) if lot else None,\n",
    "            \"min_invest\": float(min_inv),\n",
    "            \"close_date\": close_date,\n",
    "            \"gmp_investorgain\": ipo.get(\"gmp_investorgain\"),\n",
    "            \"analysis\": analysis\n",
    "        })\n",
    "    return cands\n",
    "\n",
    "# ---------- GREEDY-FILL (improved) ----------\n",
    "def greedy_fill_full(candidates, budget):\n",
    "    \"\"\"\n",
    "    Improved greedy:\n",
    "     - initial pass: allocate 1 lot to as many top candidates as possible (descending composite/min_invest)\n",
    "     - second pass: try to add additional lots to top K candidates in round-robin until can't\n",
    "     - final pass: try any candidate that can fit another lot\n",
    "    This aggressively uses budget to minimize leftover while respecting lot units.\n",
    "    \"\"\"\n",
    "    candidates = sorted(candidates, key=lambda x: x[\"composite\"]/x[\"min_invest\"], reverse=True)\n",
    "    allocation = []\n",
    "    remaining = budget\n",
    "    min_unit = min(c[\"min_invest\"] for c in candidates)\n",
    "\n",
    "    # initial one-lot diversification\n",
    "    for c in candidates:\n",
    "        if remaining >= c[\"min_invest\"]:\n",
    "            allocation.append({\"ipo\": c[\"ipo\"], \"lots\": 1, \"min_invest\": c[\"min_invest\"], \"invested\": c[\"min_invest\"], \"composite\": c[\"composite\"]})\n",
    "            remaining -= c[\"min_invest\"]\n",
    "\n",
    "    # second pass: fill top-K repeatedly (this prevents huge leftover)\n",
    "    top_k = candidates[:min(TOP_FILL_K, len(candidates))]\n",
    "    # keep adding 1 lot to each top_k in order while possible\n",
    "    added = True\n",
    "    while added and remaining >= min_unit:\n",
    "        added = False\n",
    "        for c in top_k:\n",
    "            if remaining >= c[\"min_invest\"]:\n",
    "                found = next((a for a in allocation if a[\"ipo\"] == c[\"ipo\"]), None)\n",
    "                if found:\n",
    "                    found[\"lots\"] += 1\n",
    "                    found[\"invested\"] += c[\"min_invest\"]\n",
    "                else:\n",
    "                    allocation.append({\"ipo\": c[\"ipo\"], \"lots\": 1, \"min_invest\": c[\"min_invest\"], \"invested\": c[\"min_invest\"], \"composite\": c[\"composite\"]})\n",
    "                remaining -= c[\"min_invest\"]\n",
    "                added = True\n",
    "            if remaining < min_unit:\n",
    "                break\n",
    "\n",
    "    # final pass: try to spend remaining on any candidate by composite/unit\n",
    "    while remaining >= min_unit:\n",
    "        affordable = [c for c in candidates if c[\"min_invest\"] <= remaining]\n",
    "        if not affordable:\n",
    "            break\n",
    "        pick = max(affordable, key=lambda x: x[\"composite\"]/x[\"min_invest\"])\n",
    "        found = next((a for a in allocation if a[\"ipo\"] == pick[\"ipo\"]), None)\n",
    "        if found:\n",
    "            found[\"lots\"] += 1\n",
    "            found[\"invested\"] += pick[\"min_invest\"]\n",
    "        else:\n",
    "            allocation.append({\"ipo\": pick[\"ipo\"], \"lots\": 1, \"min_invest\": pick[\"min_invest\"], \"invested\": pick[\"min_invest\"], \"composite\": pick[\"composite\"]})\n",
    "        remaining -= pick[\"min_invest\"]\n",
    "\n",
    "    # sort allocation by composite desc\n",
    "    allocation = sorted(allocation, key=lambda x: x[\"composite\"], reverse=True)\n",
    "    return allocation, remaining\n",
    "\n",
    "# ---------- MILP (balanced) ----------\n",
    "def allocate_balanced(candidates, budget):\n",
    "    \"\"\"Try PuLP MILP with diversification penalty; fallback to greedy_fill_full if PuLP absent.\"\"\"\n",
    "    try:\n",
    "        import pulp\n",
    "    except ImportError:\n",
    "        return None, None  # caller will pick greedy\n",
    "\n",
    "    prob = pulp.LpProblem(\"Balanced_IPO\", pulp.LpMaximize)\n",
    "    vars_map = {}\n",
    "    for c in candidates:\n",
    "        safe_name = re.sub(r\"\\W+\", \"_\", c[\"ipo\"])\n",
    "        max_possible = int(max(1, budget // c[\"min_invest\"]))\n",
    "        cap = min(DEFAULT_MAX_LOTS_PER_IPO, max_possible)\n",
    "        vars_map[c[\"ipo\"]] = pulp.LpVariable(f\"lots_{safe_name}\", lowBound=0, upBound=cap, cat=\"Integer\")\n",
    "\n",
    "    # objective: maximize sum(score * lots) - diversification_penalty\n",
    "    obj = pulp.lpSum([c[\"composite\"] * vars_map[c[\"ipo\"]] for c in candidates])\n",
    "    # diversification penalty uses squared lots to penalize concentration\n",
    "    penalty = DIVERSIFICATION_WEIGHT * pulp.lpSum([(vars_map[c[\"ipo\"]]**2) for c in candidates])\n",
    "    prob += obj - penalty\n",
    "\n",
    "    # budget constraint\n",
    "    prob += pulp.lpSum([c[\"min_invest\"] * vars_map[c[\"ipo\"]] for c in candidates]) <= budget\n",
    "\n",
    "    # solve\n",
    "    prob.solve(pulp.PULP_CBC_CMD(msg=False, timeLimit=10))\n",
    "\n",
    "    allocation = []\n",
    "    total_invested = 0.0\n",
    "    for c in candidates:\n",
    "        v = int(pulp.value(vars_map[c[\"ipo\"]]) or 0)\n",
    "        if v > 0:\n",
    "            invested = v * c[\"min_invest\"]\n",
    "            allocation.append({\"ipo\": c[\"ipo\"], \"lots\": v, \"invested\": invested, \"min_invest\": c[\"min_invest\"], \"composite\": c[\"composite\"]})\n",
    "            total_invested += invested\n",
    "    remaining = budget - total_invested\n",
    "    return allocation, remaining\n",
    "\n",
    "# ---------- EXPLAINABILITY ----------\n",
    "def explain_allocation(allocation, candidates_dict):\n",
    "    explain = {}\n",
    "    for a in allocation:\n",
    "        c = candidates_dict.get(a[\"ipo\"])\n",
    "        reasons_more = []\n",
    "        reasons_less = []\n",
    "        br = c[\"breakdown\"]\n",
    "        # add numeric breakdown\n",
    "        reasons_more.append(f\"Composite score {c['composite']} computed from base_score={br['base_score']}, retail_q={br['retail_quota_pct']}%, fund={br['fund_score']}, sentiment={br['sentiment_score']}, gmp_str={br['gmp_strength_pct']}% using weights {br['weights']}.\")\n",
    "        if br['gmp_strength_pct'] > 10:\n",
    "            reasons_more.append(f\"High GMP strength {br['gmp_strength_pct']}% ‚Üí strong listing expectation.\")\n",
    "        if br['retail_quota_pct'] >= 30:\n",
    "            reasons_more.append(\"High retail quota ‚Üí better allotment odds.\")\n",
    "        else:\n",
    "            reasons_less.append(f\"Retail quota {br['retail_quota_pct']}% is low; allotment probability may be limited.\")\n",
    "        if br['fund_score'] >= 6:\n",
    "            reasons_more.append(\"Fundamentals show positive indicators.\")\n",
    "        else:\n",
    "            reasons_less.append(\"Fundamentals are weak/moderate.\")\n",
    "        if \"sme\" in str(c.get(\"category\",\"\")).lower():\n",
    "            reasons_less.append(\"SME IPO: higher risk & lower liquidity ‚Äî allocate small exposure.\")\n",
    "        explain[a[\"ipo\"]] = {\"reasons_more\": reasons_more, \"reasons_less\": reasons_less, \"breakdown\": br}\n",
    "    return explain\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main():\n",
    "    print(\"üìä IPO Allocator ‚Äî Full explainable mode\\n\")\n",
    "    try:\n",
    "        budget = float(input(\"Enter total budget (‚Çπ): \").strip())\n",
    "        hold_date = datetime.strptime(input(\"Enter hold-until date (YYYY-MM-DD): \").strip(), \"%Y-%m-%d\").date()\n",
    "    except Exception as e:\n",
    "        print(\"Invalid input:\", e)\n",
    "        return\n",
    "\n",
    "    ipos_by_name, scored = load_data()\n",
    "    candidates = build_candidates(ipos_by_name, scored, hold_date)\n",
    "    if not candidates:\n",
    "        print(\"No eligible IPOs (score >=5 & within hold date). Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(f\"‚úÖ Found {len(candidates)} eligible IPOs:\\n\")\n",
    "    for c in candidates:\n",
    "        print(f\"‚Ä¢ {c['ipo']} | {c['category']} | Composite {c['composite']} | Min ‚Çπ{int(c['min_invest'])} | Retail {c['breakdown']['retail_quota_pct']}%\")\n",
    "\n",
    "    # Try MILP; if not possible or leftover too high, fallback to improved greedy that aggressively consumes budget\n",
    "    allocation, remaining = allocate_balanced(candidates, budget)\n",
    "    if allocation is None:\n",
    "        print(\"‚ö†Ô∏è PuLP not installed or failed ‚Äî using improved greedy filler.\")\n",
    "        allocation, remaining = greedy_fill_full(candidates, budget)\n",
    "    else:\n",
    "        # if remaining is too large ( > 1% budget ), try aggressive fill to reduce leftover\n",
    "        if remaining > 0.01 * budget:\n",
    "            g_alloc, g_rem = greedy_fill_full(candidates, budget)\n",
    "            # pick one with smaller leftover; if tie, pick one with larger total composite*lots\n",
    "            def used(a): return sum(x[\"invested\"] for x in a)\n",
    "            if (budget - g_rem) > (budget - remaining):\n",
    "                allocation, remaining = g_alloc, g_rem\n",
    "\n",
    "    total_invested = sum(a[\"invested\"] for a in allocation)\n",
    "    print(\"\\nüìà Final Allocation Plan:\")\n",
    "    for a in allocation:\n",
    "        print(f\"  - {a['ipo']}: ‚Çπ{int(a['invested'])} ({a['lots']} lots) | min_unit=‚Çπ{int(a['min_invest'])} | score {a['composite']}\")\n",
    "    print(f\"\\nüíµ Total Invested: ‚Çπ{int(total_invested)}\")\n",
    "    print(f\"üí§ Remaining: ‚Çπ{int(remaining)}\")\n",
    "\n",
    "    # explain\n",
    "    candidates_dict = {c[\"ipo\"]: c for c in candidates}\n",
    "    explain = explain_allocation(allocation, candidates_dict)\n",
    "\n",
    "    print(\"\\n--- Explainability & Formulas ---\")\n",
    "    print(\"\\nAlgorithm summary:\")\n",
    "    print(\"  - We compute a composite score per IPO combining:\")\n",
    "    print(\"      composite = 0.30*base_score + 0.25*rq_score + 0.20*fund_score + 0.15*(gmp_strength/10) + 0.10*sentiment_score\")\n",
    "    print(\"    where rq_score = min(retail_pct/10,1)*10 (normalized 0-10).\")\n",
    "    print(\"  - Primary solver: MILP (PuLP) maximizing sum(composite * lots) minus DIVERSIFICATION_WEIGHT * sum(lots^2).\")\n",
    "    print(\"  - Fallback: improved greedy that:\")\n",
    "    print(\"      1) gives 1 lot to each top candidate by composite/unit if affordable,\")\n",
    "    print(\"      2) repeatedly fills top K candidates (round-robin) to use leftover,\")\n",
    "    print(\"      3) finally uses any remaining budget on best composite/unit candidate.\")\n",
    "    print(\"  - Unit = min_invest (usually lot * issue price or ‚Çπ15k for mainboard fallback).\")\n",
    "    print(\"  - We skip any IPO with composite < 5 per your instruction.\\n\")\n",
    "\n",
    "    print(\"Parameters used:\")\n",
    "    print(f\"  - MIN_INVEST_MAINBOARD = {MIN_INVEST_MAINBOARD}\")\n",
    "    print(f\"  - DEFAULT_MAX_LOTS_PER_IPO = {DEFAULT_MAX_LOTS_PER_IPO}\")\n",
    "    print(f\"  - DIVERSIFICATION_WEIGHT = {DIVERSIFICATION_WEIGHT}\")\n",
    "    print(f\"  - TOP_FILL_K = {TOP_FILL_K}\\n\")\n",
    "\n",
    "    print(\"Per-IPO reasons (why more / why less):\")\n",
    "    for ipo, info in explain.items():\n",
    "        print(f\"\\nüîé {ipo}\")\n",
    "        br = info[\"breakdown\"]\n",
    "        print(f\"  Breakdown: base={br['base_score']}, retail%={br['retail_quota_pct']}%, rq_score={br['rq_score']}, fund={br['fund_score']}, sentiment={br['sentiment_score']}, gmp_str%={br['gmp_strength_pct']}\")\n",
    "        if info[\"reasons_more\"]:\n",
    "            print(\"  Reasons to invest more:\")\n",
    "            for r in info[\"reasons_more\"]:\n",
    "                print(\"   -\", r)\n",
    "        if info[\"reasons_less\"]:\n",
    "            print(\"  Reasons to be cautious:\")\n",
    "            for r in info[\"reasons_less\"]:\n",
    "                print(\"   -\", r)\n",
    "\n",
    "    # persist recommendation (sanitize dates)\n",
    "    rec = {\n",
    "        \"created_at\": datetime.utcnow().isoformat(),\n",
    "        \"budget\": budget,\n",
    "        \"hold_until\": hold_date.isoformat(),\n",
    "        \"allocation\": allocation,\n",
    "        \"explain\": explain,\n",
    "        \"total_invested\": total_invested,\n",
    "        \"leftover\": remaining\n",
    "    }\n",
    "    rec = sanitize_for_mongo(rec)\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    client[DB_NAME][COL_RECOMMEND].insert_one(rec)\n",
    "    client.close()\n",
    "    print(\"\\n‚úÖ Saved recommendation to MongoDB (collection:\", COL_RECOMMEND, \")\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
